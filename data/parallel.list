---
id=0
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=1
title=The life and times of a zookeeper 
author= Flavio P. Junqueira, Benjamin C. Reed  (Yahoo!)
journal= ACM Symposium on Principles of Distributed Computing (PODC, the highest conference of distributed computing, CCF B conference of Architecture)
year=2009
tags=zookeeper, single point of failure, server, real-time computing, Distributed computing, CAP theory, Paxos protocol
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=also published on 2009 ACM Symposium on Parallel Algorithms and Architectures ;    PODC 影响力论文奖 是分布式计算领域最高的荣誉，它认可的是经过时间考验的重要成就, 2002 年，Dijkstra 去世，这一年的 PODC 奖颁给了他，获奖论文是他 1974 年关于自稳定系统的论文。为了纪念他，PODC 决定从 2003 年把这个奖项改名为 Dijkstra 奖
---
id=2
title=ZooKeeper: wait-free coordination for internet-scale systems 
author= Patrick Hunt, Mahadev Konar, Flavio P. Junqueira, Benjamin Reed (Yahoo!)
journal=USENIX Annual Technical Conference  (ATC)
year=2010
tags=ZooKeeper, transactions per second, throughput, The Internet, State machine replication, single point of failure, server, real-time computing, Distributed computing, CAP theory, Paxos protocol, operating system, linearizability, cache, Distributed lock manager
star=****
problem=ZooKeeper, a service for coordinating processes of distributed applications
interest=Since ZooKeeper is part of critical infrastructure, ZooKeeper aims to provide a simple and high performance kernel for building more complex coordination primitives at the client. It incorporates elements from group messaging, shared registers, and distributed lock services in a replicated, centralized service. The interface exposed by Zoo-Keeper has the wait-free aspects of shared registers with an event-driven mechanism similar to cache invalidations of distributed file systems to provide a simple, yet powerful coordination service. 
hardness=
idea= The ZooKeeper interface enables a high-performance service implementation. In addition to the wait-free property, ZooKeeper provides a per client guarantee of FIFO execution of requests and linearizability for all requests that change the ZooKeeper state. These design decisions enable the implementation of a high performance processing pipeline with read requests being satisfied by local servers. 
future=
comment=We show for the target workloads, 2:1 to 100:1 read to write ratio, that ZooKeeper can handle tens to hundreds of thousands of transactions per second. This performance allows ZooKeeper to be used extensively by client applications
other=ZooKeeper is based on Paxos, but more.  Paxos 可能导致活锁，一种特殊的饥饿     https://blog.csdn.net/b0Q8cpra539haFS7/article/details/83422461
---
id=3
title=Theoretically Efficient Parallel Graph Algorithms Can Be Fast and Scalable
author= Laxman Dhulipala, Guy E. Blelloch, Julian Shun
journal=ACM Symposium on Parallelism in Algorithms and Architectures   (SPAA, CCF B Conference of Architecture area)
year=2018
tags=Theoretical analysis, parallel graph Algorithms, fast, Scalable, Terabyte, shared memory, scalability, parallel computing, multi-core processor, Hyperlink, distributed memory, computer science, auxiliary memory, external memory
star=***
problem=There has been significant recent interest in parallel graph processing due to the need to quickly analyze the large graphs available today. Many graph codes have been designed for distributed memory or external memory. 
interest=However, today even the largest publicly-available real-world graph (the Hyperlink Web graph with over 3.5 billion vertices and 128 billion edges) can fit in the memory of a single commodity multicore server. Nevertheless, most experimental work in the literature report results on much smaller graphs, and the ones for the Hyperlink graph use distributed or external memory.
hardness=it is natural to ask whether we can efficiently solve a broad class of graph problems on this graph in memory. 
idea=theoretically-efficient parallel graph algorithms can scale to the largest publicly-available graphs using a single machine with a terabyte of RAM, processing them in minutes. We give implementations of theoretically-efficient parallel algorithms for 13 important graph problems. We also present the optimizations and techniques that we used in our implementations, which were crucial in enabling us to process these large graphs quickly.
future=
comment=We show that the running times of our implementations outperform existing state-of-the-art implementations on the largest real-world graphs. For many of the problems that we consider, this is the first time they have been solved on graphs at this scale. We provide a publicly-available benchmark suite containing our implementations.
other=code is in    https://github.com/ldhulipala/gbbs
---
id=4
title=A Survey on Graph Processing Accelerators: Challenges and Opportunities
author= Chuang-Yi Gui, Long Zheng, Bingsheng He, et al.
journal=Journal of Computer Science and Technology
year=2019
tags=survey, graph Processing accelerator, Challenges, Opportunities for the future research, runtime scheduling, distributed computing, preprocessor, efficient energy use, data structure, computer engineering, parallel graph computation, graph layout reorganization, graph ordering, graph partitioning, index-aware ordering, degree-aware ordering, conflict-aware ordering, hardware acceleration, FPGA, ASIC, PIM, HMC, ReRAM
star=***
problem=we conduct a systematical survey regarding the design and implementation of graph processing accelerators
interest=
hardness=
idea=review the relevant techniques in three core components toward a graph processing accelerator: preprocessing, parallel graph computation, and runtime scheduling. We also examine the benchmarks and results in existing studies for evaluating a graph processing accelerator. Interestingly, we find that there is not an absolute winner for all three aspects in graph acceleration due to the diverse characteristics of graph processing and the complexity of hardware configurations.
future=
comment=
other=
---
id=5
title=A Proof of Correctness for Egalitarian Paxos
author=Iulian Moraru, David G. Andersen, Michael Kaminsky
journal=sosp
year=2013
tags=EPaxos, distributed protocol, Egalitarian Paxos, proof of Correctness, theory, distributed consensus algorithm, availability, uniform load balancing across all replicas, optimal commit latency in the wide-area when tolerating one and two failures
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=https://dsrg.pdos.csail.mit.edu/2014/01/10/epaxos/
---
id=6
title=eflops: algorithm and system co-design for a high performance distributed training platform
author=Jianbo Dong, et al. (Alibaba)
journal=HPCA
year=2020
tags=EFLOPS, algorithm, system, distributed training, DNN, topology-aware all-reduce algorithm, new network topology (BiGraph)
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=https://www.icloudnews.net/a/20200303/28394.html
---
