---
id=
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=0
title=DSSLP: A Distributed Framework for Semi-supervised Link Prediction
author=Dalong Zhang, et al.
journal=arXiv, Accepted by BigData as Industry paper
year=2020
tags=DSSLP, industry, Distributed Framework, Semi-supervised, link Prediction, k-hop neighborhood, mini-batch, model-split, inference, negative sample, dynamic sampling, distributed bacthed runtime sampling
star=***
problem=Link prediction is widely used in a variety of industrial applications, such as merchant recommendation, fraudulent transaction detection, and so on.
interest=
hardness=However, it’s a great challenge to train and deploy a link prediction model on industrial-scale graphs with billions of nodes and edges.
idea=a scalable and distributed framework for semi-supervised link prediction problem (named DSSLP), which is able to handle industrial-scale graphs. Instead of training model on the whole graph, DSSLP is proposed to train on the k-hops neighborhood of nodes in a mini-batch setting, which helps reduce the scale of the input graph and distribute the training procedure. In order to generate negative examples effectively, DSSLP contains a distributed batched runtime sampling module. It implements uniform and dynamic sampling approaches, and is able to adaptively construct positive and negative examples to guide the training process. Moreover, DSSLP proposes a model-split strategy to accelerate the speed of inference process of the link prediction task.
future=
comment=
other=
---
id=1
title=AGL: A Scalable System for Industrialpurpose Graph Machine Learning
author=Dalong Zhang, Xin Huang, et al.
journal=arXiv,  VLDB (submitting)
year=2020
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=2
title=GeniePath: Graph Neural Networks with Adaptive Receptive Paths
author=Ziqi Liuy, Chaochao Cheny, Longfei Liy, Jun Zhou, Xiaolong Li, Le Song, Yuan Qi
journal=AAAI
year=2019
tags=GeniePath, Graph Neural network (GNN), adaptive Receptive path
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=3
title=Towards Efficient Large-Scale Graph Neural Network Computing
author=Lingxiao Ma, Zhi Yang, Youshan Miao, Jilong Xue, Ming Wu, Lidong Zhou, Yafei Dai
journal=arXiv
year=2018
tags=NGra, Large-Scale, graph neural network (GNN), GPU
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=4
title=SpellGCN: Incorporating Phonological and Visual Similarities into Language Models for Chinese Spelling Check
author=Xingyi Cheng, Weidi Xu, Kunlong Chen, Shaohua Jiang, Feng Wang, Taifeng Wang, Wei Chu, Yuan Qi
journal=arXiv
year=2020
tags=spellgcn, NLP, graph, 多模态 (multimodal), Phonological Similarity, visual Similarity, language model, Chinese spelling check (CSC)
star=****
problem=
interest=
hardness=
idea=not only from context, but also from 错误拼写的发音(拼音输入法)和字形(手写，五笔输入法等). 对每个汉字构造两张图：发音图(相似发音存在边，weight)和字形图(相似字形)
future=
comment=much better than BERT. graph is used for improving word embedding here.
other=In graph (user-user), how about inegrating multimodal data (image, voice, etc.) as user feature, to improve graph tasks?
---
id=5
title=Deep Interaction Processes for Time-Evolving Graphs 
author=xiaofu chang, jianfeng wen, xuqin liu, yanming fang, le song, yuan qi
journal=ICLR
year=2020
tags=deep temporal point process, multiple time resolutions, dynamic continuous time-evolving graph, anti-fraud detection, DNN, LSTM, k-hops
star=****
problem=We present a principled deep neural approach that models continuous time-evolving graphs at multiple time resolutions based on a temporal point processframework.
interest=Time-evolving graphs are ubiquitous such as online transactions on an e-commerce platform and user interactions on social networks. 
hardness=While neural approaches have been proposed for graph modeling, most of them focus on static graphs. 
idea=a principled deep neural approach that models continuous time-evolving graphs at multiple time resolutions based on a temporal point process framework.  To model the dependency between latent dynamic representations of each node, we define a mixture of temporal cascades in which a node's neural representation depends on not only this node's previous representations but also the previous representations of related nodes that have interacted with this node. We generalize LSTM on this temporal cascade mixture and introduce novel time gates to model time intervals between interactions.
future=
comment=
other=基于历史来预测将来的行为，但是这可能存在问题。比如最近买了洗衣机，那么一年内应该是不会买洗衣机的。
---
id=6
title=KunPeng: Parameter Server based Distributed Learning Systems and Its Applications in Alibaba and Ant Financial
author=Jun Zhou, ..., Yuan Qi
journal=SIGKDD
year=2017
tags=KunPeng, Parameter Server, Distributed Learning system, Alibaba, Ant Financial
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
