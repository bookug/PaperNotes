---
id=
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=0
title=Benchmarking GPUs to tune dense linear algebra
author=Volkov Vasily
journal=
year=2008
tags=nvidia gpu, dense linear algebra
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=1
title=Optimization principles and application performance evaluation of a multithreaded GPU using CUDA
author=Shane Ryoo
journal=PPoPP
year=2008
tags=GPU computing, CUDA, Optimization principles, lessons, design, performance evaluation, languages, parallel computing
star=****
problem=
interest=
hardness=
idea=developers face the challenge of striking the right balance between each thread's resource usage and the number of simultaneously active threads. The resources to manage include the number of registers and the amount of on-chip memory used per thread, number of threads per multiprocessor, and global memory bandwidth. We also obtain increased performance by reordering accesses to off-chip memory to combine requests to the same or contiguous memory locations and apply classical optimizations to reduce the number of executed operations
future=
comment=
other=
---
id=2
title=Selective GPU caches to eliminate CPU-GPU HW cache coherence
author=Neha Agarwal
journal=IEEE International Symposium on High Performance Computer Architecture (HPCA)
year=2016
tags=CPU-GPU HW cache coherence, gpu caches, strategies for cache coherence
star=****
problem=Recent work suggests extending hardware cache coherence between CPUs and GPUs to help support programming models with tightly coordinated sharing between CPU and GPU threads.
interest=Cache coherence is ubiquitous in shared memory multiprocessors because it provides a simple, high performance memory abstraction to programmers. 
hardness=implementing hardware cache coherence is particularly challenging in systems with discrete CPUs and GPUs that may not be produced by a single vendor
idea=selective caching, wherein we disallow GPU caching of any memory that would require coherence updates to propagate between the CPU and GPU, thereby decoupling the GPU from vendor-specific CPU coherence protocols. We propose several architectural improvements to offset the performance penalty of selective caching: aggressive request coalescing, CPU-side coherent caching for GPU-uncacheable requests, and a CPU-GPU interconnect optimization to support variable-size transfers. Moreover, current GPU workloads access many read-only memory pages; we exploit this property to allow promiscuous GPU caching of these pages, relying on page-level protection, rather than hardware cache coherence, to ensure correctness.
future=
comment=
other=
---
id=3
title=3D GPU architecture using cache stacking: Performance, cost, power and thermal analysis
author=Ahmed Al Maashri
journal=IEEE International Conference on Computer Design
year=2009
tags=3D GPU architecture, cache stacking, 3D die stacking, performance evaluation
star=***
problem=Graphics Processing Units (GPUs) offer tremendous computational and processing power. The architecture requires high communication bandwidth and lower latency between computation units and caches
interest=3D die-stacking technology is a promising approach to meet such requirements
hardness=
idea=the impact of stacking caches using the 3D technology on GPU performance. We also investigate the benefits of using 3D stacked MRAM on GPUs. Our work includes cost, power, and thermal analysis of the proposed architectural designs
future=
comment=
other=
---
id=4
title=Cache coherence for GPU architectures
author=Inderpreet Singh
journal=IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)
year=2013
tags=cache coherence, gpu Architecture
star=****
problem=Introducing conventional directory protocols adds unnecessary coherence traffic overhead to existing GPU applications. Moreover, these protocols increase the verification complexity of the GPU memory system
interest=While scalable coherence has been extensively studied in the context of general purpose chip multiprocessors (CMPs), GPU architectures present a new set of challenges
hardness=
idea=a time-based coherence framework for GPUs, called Temporal Coherence (TC), that exploits globally synchronized counters in single-chip systems to develop a streamlined GPU coherence protocol. Synchronized counters enable all coherence transitions, such as invalidation of cache blocks, to happen synchronously, eliminating all coherence traffic and protocol races. We present an implementation of TC, called TC-Weak, which eliminates LCC's trade-off between stalling stores and increasing L1 miss rates to improve performance and reduce interconnect traffic.
future=
comment=
other= The efficiency of Dijkstra’s algorithm is based on the ordering of previously computed results.
---
id=5
title=All-pairs shortest-paths for large graphs on the GPU
author=
journal=siggraph
year=2008
tags=apsp, gpu, shortest path
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=6
title=A new GPU-based approach to the shortest path problem
author=
journal=
year=2013
tags=sssp,gpu, shortets path
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=7
title=PHAST: Hardware-accelerated shortest path trees
author=Daniel Delling, Andrew V. Goldberg
journal=IPDPS
year=2011
tags=parallel Hardware-accelerated shortest path trees, PHAST, shortets path, gpu, SSSP, low degree, Parallelism after Preprocessing , contraction hierarchy, precomputed distance, highly ranked high-degree vertices
star=***
problem=
interest=
hardness=
idea=uses preprocessing techniques using contraction hierarchies [id:41] of literature.list to expose more parallelism in SSSP calculation;   PHAST’s preprocessing step precomputes distances to highly ranked high-degree vertices using a Dijkstra-like traversal. At runtime, PHAST can then perform multiple searches in parallel from these highly ranked vertices.
future=
comment=work complexity is O(vlgv+e), fit for low-degree graphs(like meshes or road map), parallelism after Preprocessing;     In practice, contraction hierarchies (and therefore PHAST) work well on low-degree, high-diameter graphs such as road networks. However, for highly connected graphs (such as power-law graphs), the contraction hierarchy preprocessing step is expensive, as the number of shortcuts explodes as the dimensionality increases, while lower-degree graphs add extra parallelism without the large amounts of extra work.
other=also published in Journal of Parallel and Distributed Computing(JPDC, CCF B journal) 2013
---
id=8
title=Dijkstra's shortest path algorithm serial and parallel execution performance analysis
author=
journal=
year=2012
tags=Dijkstra, sssp, gpu, parallel
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=9
title=Blocked all-pairs shortest paths algorithm for hybrid CPU-GPU system
author=
journal=
year=2011
tags=apsp, hybrid cpu-gpu system
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=10
title=An empirical comparison of k-shortest simple path algorithms on multicores (survey)
author=
journal=ICPP
year=2018
tags=multicores, gpu, k-shortest path, survey, experimental paper
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=11
title=Optimal Path Maps on the GPU
author=
journal=
year=2019
tags=optimal path map, gpu, shortest path, OpenGL
star=**
problem=We introduce a new method for computing optimal path maps on the GPU using OpenGL shaders.
interest=
hardness=
idea=Our method explores GPU rasterization as a way to propagate optimal costs on a polygonal 2D environment, producing optimal path maps which can efficiently be queried at run-time. Our method is implemented entirely with GPU shaders, does not require pre-computation, addresses optimal path maps with multiple points and line segments as sources, and introduces a new optimal path map concept not addressed before: maps with weights at vertices representing possible changes in traversal speed. The produced maps offer new capabilities not explored by previous navigation representations and at the same time address paths with global optimality, a characteristic which has been mostly neglected in animated virtual environments. The proposed path maps partition the input environment into the regions sharing a same parent point along the shortest path to the closest source, taking into account possible speed changes at vertices.
future=
comment= The proposed approach is particularly suitable for the animation of multiple agents moving toward the entrances or exits of a virtual environment, a situation which is efficiently represented with the proposed path maps.
other=
---
id=12
title=Fast bidirectional shortest path on GPU
author=
journal=IEICE Electronic Express
year=2016
tags=bidirectional shortest path problem, GPGPU, early termination, shortest path of a single pair, parallel, bidirectional search, s-t shortest path
star=**
problem=a new algorithm to solve bidirectional shortets path problems using parallel architectures provided by general purpose computing on graphics processing units
interest=the bidirectional shortest path problems has important applications in VLSI floor planning and other areas.
hardness=
idea=performs parallel searches from the source and sink using Dijkstra's classic approach modified with pruning and early termination.
future=
comment=substantial speedup over a parallel method that performs a single parallel search on the GPGPU from the source to all other nodes but with early termination when targeted node is found.
other=this algorithm only finds the shortest path of a singel pair (s,t)
---
id=13
title=Comprehensive evaluation of a new GPU-based approach to the shortest path problem
author=Hector Ortega-Arranz
journal= International Journal of Parallel Programming
year=2015
tags=GPGPU, shortest path, Dijkstra, kernel characterization, nvidia platform comparison, optimization techniques, SSSP, Boost library, survey, experimental paper
star=***
problem=GPU SSSP algorithm implementation. The key issue to parallelize Dijkstra's algorithm is to identify as many nodes as possible that can be inserted in the following frontier set.
interest=The single-source shortest path (SSSP) problem arises in many different fields.
hardness=
idea=based on [id:30], The use of a proper choice of threadblock size; and the modification of the GPU L1 cache memory state of NVIDIA devices (like [id:61]). These optimizations lead to performance improvements of up to 23% with respect to the non-optimized versions. In addition, we have made a platform comparison of several NVIDIA boards in order to distinguish which one is better for each class of graphs, depending on their features.
future=Our future work includes the comparison with other non-GPU parallel implementations using OpenMP or MPI, in order to see what the threshold is where the use of a GPU is worthwhile in terms of efficiency and/or consumed energy.
comment=Our work significantly speeds up the computation of the SSSP, not only with respect to a CPU-based version, but also to other state-of-the-artGPUimplementations based on Dijkstra; we compare our results with an optimized sequential implementation of Dijkstra’s algorithm included in the reference Boost library, obtaining an improvement ratio of up to 19× for some graph families, using less memory space.   ;      We have observed that the algorithm due to Martín et al. [id:21] is not as profitable in GPUs as Crauser’s [id:30] for graphs with a small number of nodes and a low fan-out degree, behaving even worse than the sequential CPU Crauser version. This occurs due to the small threshold for converting reached nodes into frontier nodes of their algorithm, and due to the lowlevel of parallelism that can be extracted for these graphs.Our optimized GPU solution cannot beat the times of the Boost library in graphs with extremely low degrees for the same reason.
other=related offline index-based optimizations for s-t shortest path is not friendly to updates, which may be frequent in real life; offline indices for SSSP problem on large graphs are not practical
---
id=14
title=Accelerating GPU betweenness centrality
author=
journal=
year=2018
tags=gpu, betweenness centrality
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=15
title=SEP-graph: finding shortest execution paths for graph processing under a hybrid framework on GPU
author=Hao Wang, Liang Geng (contributed equally to this work)
journal=PPoPP
year=2019
tags=Sep-graph, shortest execution path, graph processing, hybrid framework, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=16
title=All-Pairs Shortest Path algorithms for planar graph for GPU-accelerated clusters
author=
journal= J. Parallel Distrib. Comput.
year=2015
tags=All-Pairs shortest path, apsp, planar graph, GPU-accelerated clusters
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=17
title=Dynamic Shortest Paths using JavaScript on GPUs
author=
journal=
year=2015
tags=dynamic, shortest path, JavaScript, GPU
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=18
title=Improved shortest path maps with GPU shaders
author=
journal=arXiv
year=2018
tags=improved shortest path maps, GPU shaders, OpenGL
star=**
problem=We present in this paper several improvements for computing shortest path maps using OpenGL shaders. 
interest=
hardness=
idea=The approach explores GPU rasterization as a way to propagate optimal costs on a polygonal 2D environment, producing shortest path maps which can efficiently be queried at run-time. Our improved method relies on Compute Shaders for improved performance, does not require any CPU pre-computation, and handles shortest path maps both with source points and with line segment sources. The produced path maps partition the input environment into regions sharing a same parent point along the shortest path to the closest source point or segment source.
future=
comment=Our method produces paths with global optimality, a characteristic which has been mostly neglected in animated virtual environments. The proposed approach is particularly suitable for the animation of multiple agents moving toward the entrances or exits of a virtual environment, a situation which is efficiently represented with the proposed path maps.
other=
---
id=19
title=CPU-GPU heterogeneous implementations of depth-based foreground detection
author=
journal=
year=2018
tags=CPU-GPU heterogeneous, depth-based foreground detection
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=20
title=BFS-4K: An Efficient Implementation of BFS for Kepler GPU Architectures
author=Federico Busato
journal=TPDS
year=2015
tags=Parallel graph algorithms, CUDA, GPU, BFS, Kepler GPU, BFS-4K, BFS4K
star=****
problem=Breadth-first search (BFS) is one of the most common graph traversal algorithms and the building block for a wide range of graph applications.
interest=With the advent of graphics processing units (GPUs), several works have been proposed to accelerate graph algorithms and, in particular, BFS on such many-core architectures.
hardness=Nevertheless, BFS has proven to be an algorithm for which it is hard to obtain better performance from parallelization. Indeed, the proposed solutions take advantage of the massively parallelism of GPUs but they are often asymptotically less efficient than the fastest CPU implementations.
idea=This paper presents BFS-4K, a parallel implementation of BFS for GPUs that exploits the more advanced features of GPU-based platforms (i.e., NVIDIA Kepler) and that achieves an asymptotically optimal work complexity. The paper presents different strategies implemented in BFS-4K to deal with the potential workload imbalance and thread divergence caused by any actual graph non-homogeneity.
future=
comment=The paper presents the experimental results conducted on several graphs of different size and characteristics to understand how the proposed techniques are applied and combined to obtain the best performance from the parallel BFS visits. Finally, an analysis of the most representative BFS implementations for GPUs at the state of the art and their comparison with BFS-4K are reported to underline the efficiency of the proposed solution.
other=compared with Harish, Edge Parall, Static Virtual Warp, Luo, Garland
---
id=21
title=CUDA Solutions for the SSSP Problem
author=Pedro J. Martin
journal=ICCS(CCF C Conference of network area)
year=2009
tags=dijkstra, cuda, sssp, GPU, shortest path, label-setting
star=**
problem=
interest=
hardness=
idea=They used the CUDA interface for these implementations and graphics processing unit (GPU) to run the parallel threads. Basically, each step of these implementations removes all those queued nodes, which are having weight equal to current minimum weight value and relax their outgoing edges in parallel on threads running for them. In each iteration, they create n threads one for each node. They have also shown the parallelization in finding the minimum weight and creating the list of nodes having minimum node weight.   ; two variants, the basic is called successors which simply select all minimum ones in each iteration, the other is called predecessors, which find predecessor vertices of each unsettled node v, which are in the current queue and can be used to relax v.
future=
comment=Provide parallel Dijkstra algorithm
other=
---
id=22
title=A New GPU-based Approach to the Shortest Path Problem 
author=Hector Ortega-Arranz
journal=HPCS
year=2013
tags=parallel Dijkstra, GPU, Kepler, NSSP, Parallel Algorithms, SSSP, shortest path
star=**
problem=
interest=
hardness=
idea=
future=
comment=Parallel Implementation of Dijkstra algorithm; outperform work [id:21] by 17%
other=
---
id=23
title=Efficient parallel implementation of single source shortest path algorithm on GPU using CUDA
author=Singh
journal=IJAER
year=2016
tags=Bellman-Ford, GPU, CUDA, SSSP, shortest path
star=**
problem=
interest=
hardness=
idea=
future=
comment=This paper has proposed the consistence and more efficient parallel implementations of algorithm proposed by Harish et al. employing just a single CUDA kernel to maintain two modification conditions. 
other=
---
id=24
title=A Quantitative Study of Irregular Programs on GPUs 
author=Burtscher
journal=IISWC
year=2012
tags=parallel graph algorithm, control-flow irregularity, memory-access irregularity, Bellman-Ford, GPU, sssp, shortest path
star=**
problem=
interest=
hardness=
idea=
future=
comment=Present an implementation of parallel Bellman-ford algorithm on GPU; defines two measures of irregularity called control-flow irregularity and memory-access irregularity, and investigates, using performance-counter measurements, how irregular GPU kernels differ from regular kernels with respect to these measures.
other=this paper claims: Even though it is less efficient than Dijkstra’s (O(VE), it is well suited to parallelization)
---
id=25
title=Locality-Based Relaxation: An Efficient Method for GPU-Based Computation of Shortest Paths
author=Mohsen Safari
journal=TTCS
year=2017
tags=Locality-Based Relaxation, GPU, SSSP, shortest path
star=**
problem=
interest=
hardness=
idea=
future=
comment=The proposed algorithm is based on the idea of locality-based relaxation, where instead of updating just the distance of a single vertex v, we update the distances of v’s neighboring vertices up to k steps.  
other=
---
id=26
title=Accelerating CUDA Graph Algorithms at Maximum Warp
author=Sungpack Hong
journal=PPoPP
year=2011
tags=cuda, parallel graph Algorithms, maximum warp,GPGPU, SSSP, STCON(s-t connectivity), virtual warp-centric programming model, heavily imbalanced workloads, graph irregularity, warp-granular task allocation, virtual warp Programming, static virtual warps
star=****
problem=
interest=Graphs are powerful data representations favored in many computational domains.
hardness=Modern GPUs have recently shown promising results in accelerating computationally challenging graph problems but their performance suffers heavily when the graph structure is highly irregular, as most real-world graphs tend to be.
idea=first observe that the poor performance is caused by work imbalance and is an artifact of a discrepancy between the GPU programming model and the underlying GPU architecture.We then propose a novel virtual warp-centric programming method that exposes the traits of underlying GPU architectures to users.     ;     The virtual warp-centric programming method addresses the problem of workload imbalance inside a warp. deferring outliers, dynamic workload distribution
future=
comment=Our method significantly improves the performance of applications with heavily imbalanced workloads, and enables trade-offs between workload imbalance and ALU underutilization for fine-tuning the performance. ; big speedup on irregular graphs, small on regular graphs     ;        the load balance strategy except for virtual warp,  is developed from merrill but more general to other algorithms. Besides, the idea of virtual warp is not so complicated.
other=the performance gap between GPUs and other multi-threaded CPU graph implementations is primarily due to the large difference in memory bandwidth.  ;   later GPU algorithms are in favor of using a whole warp for each task, this paper may logically partitioning a warp into multiple virtual warps. Using virtual warps leads to the possibility of execution path divergence among different virtual warps, which in turn serializes different instruction streams among the warps.  In essence, the virtual warp scheme can be viewed as a trade-off between executionpath divergence and ALU underutilization by varying a single parameter, the virtual warp size.  ; the version of dynamic virtual warp is in [id:193] of bookug.list
---
id=27
title=cuSTINGER: Supporting dynamic graph algorithms for GPUs
author=Oded Green(Nvidia Engineer), David A. Bader
journal=HPEC ( IEEE High Performance Extreme Computing Conference )
year=2016
tags=cuSTINGER, dynamic graph algorithm, data structure, graph stream, GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=28
title=Graph-Based Substructure Pattern Mining Using CUDA Dynamic Parallelism
author=
journal=IDEAL
year=2013
tags=frequent pattern Mining, CUDA, GPGPU, dynamic Parallelism
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=based on [id:417] of bookug.list
---
id=29
title=Parallel graph mining with gpus
author=
journal=BigMine
year=2014
tags=frequent pattern Mining, CUDA, GPGPU, dynamic Parallelism
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=based on [id:417] of bookug.list
---
id=30
title=A parallelization of Dijkstra’s shortest path algorithm (Crauser’s algorithm)
author=Crauser
journal= Mathematical Foundations of Computer Science
year=1998
tags=shortest path, parallelization, Dijkstra's algorithm, SSSP
star=***
problem=
interest=
hardness=
idea=The basic idea of this method is that in Dijkstra’s algorithm, queue may contain multiple nodes, which are settled, so simultaneously remove such nodes from queue and relax their outgoing edges. However, the problem is to identify them. To identify such nodes they have given number of criterians  ;    not only the minimum ones in queue, but also some bigger ones smaller than the threshold, which is decided by a precomputation phase calculating the minimum value of paths growing from the queue.
future=
comment=
other=
---
id=31
title=Programming Massively Parallel Processors - A Hands-on Approach  (CUDA)
author=David Blair Kirk
journal=Morgan Kaufmann 
year=2010
tags=CUDA paper, many-core, GPGPU, parallel computing
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=32
title=SIMD-X: Programming and Processing of Graph Algorithms on GPUs
author=Hang Liu, H. Howie Huang
journal=arXiv
year=2018
tags=SIMD-X, Graph Algorithms, GPU, graph library, system, control irregularity, memory access irregularity
star=***
problem=With high computation power and memory bandwidth, graphics processing units (GPUs) lend themselves to accelerate data-intensive analytics, especially when such applications fit the single instruction multiple data (SIMD) model.
interest=
hardness=However, graph algorithms such as breadth-first search and k-core, often fail to take full advantage of GPUs, due to irregularity in memory access and control flow.
idea=developed SIMD-X, for programming and processing of single instruction multiple, complex, data on GPUs.  Specifically, the new Active-Compute-Combine (ACC) model not only provides ease of programming to programmers, but more importantly creates opportunities for system-level optimizations. To this end, SIMD-X utilizes just-in-time task management which filters out inactive vertices at runtime and intelligently maps various tasks to different amount of GPU cores in pursuit of workload balancing. In addition, SIMD-X leverages push-pull based kernel fusion that, with the help of a new deadlock-free global barrier, reduces a large number of computation kernels to very few.     
future=
comment=Using SIMD-X, a user can program a graph algorithm in tens of lines of code, while achieving 3, 6, 24, 3 speedup over Gunrock, Galois, CuSha, and Ligra, respectively.   
other=In SSSP-based asynchronous BFS [id:58] of yuqizhou.list, the redundant check is the culprit to make SSSP severely slower than BFS.
---
id=33
title= XBFS: eXploring Runtime Optimizations for Breadth-First Search on GPUs
author=Anil Gaihre, Hang Liu
journal=HPDC (CCF B Conference of architecture area)
year=2019
tags=XBFS, BFS, Runtime Optimizations, Breadth-First Search, GPU, truly asynchronous BFS traversal, adaptive frontier queue generation, asynchronous Bottom-Up traversal, warp-centric dynamic workload balancing
star=****
problem=often exploits the static mechanisms to address the challenges that are dynamic in nature. Such a mismatch prevents us from achieving the optimal performance for offloading graph traversal on GPUs.
interest=Attracted by the enormous potentials of Graphics Processing Units (GPUs), an array of efforts has surged to deploy Breadth-First Search (BFS) on GPUs
hardness=
idea=First, XBFS adaptively exploits four either new or optimized frontier queue generation designs to accommodate various BFS levels that present dissimilar features. Second, inspired by the observation that the workload associated with each vertex is not proportional to its degree in bottom-up, we design three new strategies to better balance the workload. Third, XBFS introduces the first truly asynchronous bottom-up traversal which allows BFS to visit vertices for multiple levels at a single iteration with both theoretical soundness and practical benefits.
future=
comment=XBFS is, on average, 3.5×, 4.9×, 11.2× and 6.1× faster than the state-of-the-art Enterprise, Tigr, Gunrock and Ligra respectively
other=
---
id=34
title=Efficient Encoding and Reconstruction of HPC Datasets for Checkpoint/Restart
author=Hang Liu
journal=MSST
year=2019
tags=encoding, Reconstruction, HPC datasets, Checkpoint, restart
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=35
title= BFS: Data Centric Breadth-First Search on FPGAs
author=Hang Liu
journal=DAC
year=2019
tags=BFS, data Centric, FPGA, HPC
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=36
title= Software and Hardware Co-Optimized BFS on FPGAs
author=Zach Sherer, Hang Liu
journal=FPGA  (CCF B, topest in FPGA area)
year=2019
tags=Software, Hardware, Co-Optimized BFS, FPGA
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=37
title=Do Bitcoin Users Really Care About Anonymity? An Analysis of the Bitcoin Transaction Graph
author=Anil Gaihre, Yan Luo, Hang Liu
journal=IEEE BigData
year=2018
tags=Bitcoin, Anonymity, Bitcoin Transaction Graph
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=38
title=High-Performance Triangle Counting on GPUs
author=Yang Hu, Hang Liu
journal=Graph Challenge Champion
year=2018
tags=hpc, Triangle counting, GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=39
title=TriCore: Scalable Triangle Counting on GPUs
author=Yang Hu, Hang Liu, H. Howie Huang
journal=SC (CCF A Conference of architecture area)
year=2018
tags=TriCore, Triangle Counting, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=oriented from [id:38]
---
id=40
title= iSpan: Parallel Identification of Strongly Connected Components with Spanning Trees
author=Yuede Ji, Hang Liu, H. Howie Huang
journal=SC
year=2018
tags=iSpan, parallel Identification, Strongly connected Components(SCC), spanning tree
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=41
title=UKSM: Swift Memory Deduplication via Hierarchical and Adaptive Memory Region Distilling
author=Nai Xia, Hang Liu
journal=FAST (CCF A Conference of architecture area)
year=2018
tags=UKSM, swift Memory Deduplication, Hierarchical and Adaptive memory region distilling
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=42
title= Novel Techniques for Graph Algorithm Acceleration (Ph.D. Dissertation)
author=Hang Liu
journal=Ph.D. Dissertation
year=2017
tags=graph Algorithms Acceleration, GPU, FPGA
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=43
title=Fast segmented sort on GPUs
author=Kaixi Hou, Weifeng Liu
journal=ICS
year=2017
tags=segmented sort, GPU, shuffle
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=44
title=Medusa: Simplified graph processing on GPUs
author=J. Zhong, Bingsheng He
journal=TPDS
year=2014
tags=Medusa, GPU graph processing, Pregel model, multiple GPUs
star=****
problem=
interest=
hardness=
idea=
future=
comment=based on the Pregel programming model [id:241] of bookug.list which allows to exploit more than one GPU in a box by inserting specific primitives in a simple C/C++ code.
other=
---
id=45
title=Cusha: vertex-centric graph processing on GPUs
author=F. Khorasani
journal=Proc. 23rd Int. Symp.  High-Perform. Parallel Distrib. Comput.(HPDC)
year=2014
tags=Cusha, vertex-centric graph processing, GPU, pergel model, G-shared, CSR, Concatenate Windows, CUDA thread utilization
star=***
problem=
interest=
hardness=
idea=
future=
comment=introduced new data structures in order to alleviate the burden of uncoalesced global memory data accesses. It employs G-Shard, an alternative format to the classic CSR data structure. The authors also proposed a novel approach, named Concatenated Windows, that increases CUDA threads utilization for very large graphs.
other=
---
id=46
title=Graph Analytics on Modern Massively Parallel Systems (phd dissertation)
author=Flavio Vella
journal=Doctor of Philosophy in Computer Science (phd dissertation)
year=2017
tags=phd dissertation, Graph Analytics, Modern massively parallel systems, gpu, multi-core, many-core, distributed, reachability, betweenness centrality(BC), clustering coefficient, st-connectivity, bi-dimensional(2D) decomposition, multi-level parallelism, graph topology, weighted graph, unweighted graph,  inter-node communications
star=***
problem= the design of efficient and scalable graph algorithms is an extraordinary challenge due to irregular communication and memory access patterns, high synchronization costs, and lack of data locality
interest=
hardness=
idea=
future=
comment=
other=
---
id=47
title=Design and Analysis of Sequential and Parallel Single–Source Shortest–Paths Algorithms
author=Ulrich Meyer (U. Meyer)
journal=phd dissertation
year=2002
tags=single source shortest path(SSSP), all-pair shortest paths(APSP), one-pair shortest path(OPSP, single-pair, s-t), sequential algorithm, parallel computing, non-negative random weights, superlinear, average-case bounds, Approximate Vucket implementation(ABI-Dijkstra), sparse random graphs, WWW, telephone calls, social networks, label-setting, label-correcting, BSP model, LogP model, distributed memory machine (DMM),PRAM, theorectical analysis, in-criterion, out-criterion, average linear-time algorithm, SP-C, SP-S, arbitary directed graphs
star=***
problem=We study the performance of algorithms for the Single-Source Shortest-Paths (SSSP) problem on graphs with n nodes and m edges with nonnegative random weights.
interest=
hardness=All previously known SSSP algorithms for directed graphs required superlinear time
idea=We give the first SSSP algorithms that provably achieve linear (n+m) average-case execution time on arbitrary directed graphs with random edge weights. For independent edge weights, the linear-time bound holds with high probability, too. We develop a new sequential SSSP approach, which adaptively splits buckets of an approximate priority-queue data-structure, thus building a bucket hierarchy. The new SSSP approach comes in two versions, SP-S and SP-C, following either the label-setting (SP-S) or the label-correcting (SP-C) paradigm. Our method is the first that provably achieves linear O(n+m) average-case execution time on arbitrary directed graphs.Additionally, our result implies improved average-case bounds for the All-Pairs Shortest-Paths (APSP) problem on sparse graphs, and it yields the first theoretical average-case analysis for the “Approximate Bucket Implementation” of Dijkstra’s SSSP algorithm (ABI–Dijkstra). Furthermore, we give constructive proofs for the existence of graph classes with random edge weights on which ABI–Dijkstra and several other well-known SSSP algorithms require superlinear averagecase time. Besides the classical sequential (single processor) model of computation we also consider parallel computing: we give the currently fastest average-case linear-work parallel SSSP algorithms for large graph classes with random edge weights, e.g., sparse random graphs and graphs modeling the WWW, telephone calls or social networks.
future=
comment=worst-case analysis sometimes fails to bring out the advantages of algorithms that perform well in practice;   For arbitrary undirected networks with nonnegative edge costs, it is known that Single-Source Shortest-Paths problems can be solved in linear time in the worst case;  
other=many theoretical analysis of shortest path properties; many optimization techniques of Dijkstra's algorithm
---
id=48
title=Accelerating Graph Processing on a Shared-Memory FPGA System
author=Yu wang
journal=Phd dissertation, Carnegie Mellon University (CMU)
year=2018
tags=newhardware, FPGA, graph processing, Shared-Memory system
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=49
title=Heaps are better than buckets: Parallel shortest paths on unbalanced graphs
author=U. Meyer
journal= Proc. Euro-Par 2001 Parallel Processing, volume 2150 of LNCS
year=2001
tags=heap, bucket, shortest path, SSSP, unbalanced graphs, parallel algorithm
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=50
title=Single-source shortest-paths on arbitrary directed graphs in linear average-case time
author=U. Meyer
journal=Proc. 12th Ann. Symp. on Discrete Algorithms (ACM-SIAM)
year=2001
tags=shortest path, SSSP, arbitary directed graph, linear average-case time, average linear-time, random edge weights, adaptive bucket-splitting
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=extension of [id:33] of bookug.list, how the Δ-stepping idea can be augmented by adaptive bucket-splitting, thus yielding the first sequential SSSP algorithm with provably linear average-case time for arbitrary directed graphs with random edge weights.
---
id=51
title= Buckets strike back: Improved parallel shortest paths
author=U. Meyer
journal=IPDPS
year=2002
tags=parallel, distributed, bucket, shortest path, SSSP
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=52
title=Parallel shortest path for arbitrary graphs
author=U. Meyer
journal=Proc. Euro-Par 2000 Parallel Processing, volume 1900 of LNCS
year=2000
tags=shortest path, SSSP, parallel, arbitary graphs
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=53
title=An all pairs shortest path algorithm with expected time O(n^2+logn)
author=A. Moffat, T. Takaoka
journal=SIAM journal on Computing
year=1987
tags=shortest path, APSP, expected time, average time, theorectical anslysis, upper bound, O(n^2+lgn)
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=54
title=A study of different parallel implementations of single source shortest path algorithms  (survey)
author=Dhirendra Pratap Singh
journal=International Journal of Computer Applications
year=2012
tags=parallel implementation, SSSP, shortest path, survey, Dijkstra's algorithm, subgraph division, label-setting, label-correcting
star=***
problem=We present a study of parallel implementations of single source shortest path (SSSP) algorithms.
interest=In the last three decades number of parallel SSSP algorithms have been developed and implemented on the different type of machines.
hardness=
idea=We have divided some of these implementations into two groups, first are those where parallelization is achieved in the internal operations of sequential SSSP algorithm and second are where an actual graph is divided into sub-graphs, and serial SSSP algorithm executes parallel on separate processing units for each sub-graph.  
future=
comment=
other=These parallel implementations have used PRAM, CRAY super-computer, dynamically reconfigurable processor and Graphics processing unit as platform to run them.
---
id=55
title=Implementing parallel shortest-paths algorithms
author=M. Papaefthymiou
journal=DIMACS Series in Discrete Mathematics and Theoretical Computer Science
year=1994
tags=parallel algorithm, shortest path, SSSP, distributed computing, label-setting, label-correcting
star=***
problem=
interest=
hardness=
idea=An important property of this algorithm is that during any iteration, we can relax the edges of a graph in random order, but the result will be same. In “Implementing parallel shortest path algorithms [12]” they used this property to implement the parallel version of the bellman-ford algorithm on CM-5 parallel supercomputer in two steps. At first step they divided the edge set of graph G in P (number of processors) different disjoint subsets. Each processor is assigned a subset of edges, and this assignment never changes during the execution of the program. In second step execute a program of modified Bellman-ford’s algorithm in each processor.  This algorithm is divided into two parts a computation followed by a communication phase.
future=
comment=
other=
---
id=56
title=A parallel shortest path algorithm based on graph-partitioning and iterative correcting
author=Y. Tang
journal= IEEE International Conference on High Performance Computing and Communications  (HPCC, CCF C Conference of architecture area)
year=2008
tags=parallel algorithm, shortest path, SSSP, graph partitioning, iterative correcting, label-correcting, k-way METIS, Pregel model, local computing first, distributed, coarse-grained parallelism, IBM clusters
star=***
problem=
interest=
hardness=
idea=This algorithm is divided into two phases, a graph partitioning phase followed by a weight correcting phase. In first phase, they used k-way portioning algorithm (k-way METIS) to divide the graph. Graph is portioned into disjoint sub-graphs, where each sub-graph has roughly the same number of nodes and the number of edges crossing sub-graphs is minimal. Phase two contains two steps; first step is a computation step, after graph partitioning each sub-graph is assigned to one processor, and each process find temporary shortest paths in its assigned sub-graph locally. In the first iteration only one processor actually compute temporary shortest path in assigned sub-graph, which is having source node information. Second step is a communication step where after computing the shortest path in local sub-graphs the boundary information’s are exchanged between the adjacent sub-graphs. Now the number of processes having the information of the source node is increased. Algorithm continues iterating, and temporary shortest paths in each process keep correcting and updating with boundary information exchange. This algorithm continues until there is no message exchanged between the adjacent sub-graphs, and we will obtain the final shortest path.
future=
comment=
other=the experimental platform is IBM platform, 16 processors
---
id=57
title=A parallel priority queue with constant time operations
author=G. Brodal
journal=Journal of parallel and distributed computing
year=1998
tags=parallel priority queue, constant time operations, shortest path, SSSP, Dijkstra's algorithm, parallel data structure, label-setting
star=***
problem=
interest=First method tried to speed up the specific queue operation that handles a single element using a small number of processors. Second way is to support the simultaneous insertion and deletions of smallest elements.
hardness=Queue operations are one of the most important and time consuming part of Dijkstra’s algorithm.
idea=They have represented a parallel priority data structure that supports internal operations of the algorithm in O(1) time. Using this data structure, they implemented Dijkstra’s algorithm in O(n) time on a CREW PRAM. They used the adjacency list representation of a graph, which is sorted according to edge weight. In such a list, they have shown how perform the operations like determining a node of minimum weight distance and adding any number of new nodes or updating the distances of a node in constant time. The basic idea of this data structure is to use a pipeline structure; each processor takes the output of the processor before it, and does a constant time merge operation to select an element as its output to the next processor.
future=
comment=
other=another paper is: A parallel priority data structure with applications
---
id=58
title=Advanced shortest paths algorithms on a massively-multithreaded architecture
author=J. R. Crobak
journal=Parallel and Distributed Processing Symposium
year=2007
tags=bucket, Thorup's algorithm, label-setting, shortest path, SSSP, multithreaded, Component hierarchy(CH)
star=***
problem=Unlike the Dijkstra’s algorithm, Thorup’s algorithm does not visit the nodes in order of increasing distance from the source node; instead of that it identifies the vertices that can be visited in any order
interest=To avoid the sorting bottleneck of Dijkstra’s algorithm, they have used hierarchical bucketing structure for nodes on which internal operations are performed in constant time.
hardness=
idea=this algorithm and [id:55] summary the graph in a tree data-structure called the Component Hierarchy (CH). Each CH-node is called component, which represents a sub-graph of the graph G. Each component is identified by node v and a level i. Component (v, i) is the sub-graph of G having node v, the set of nodes reachable from v when traversing edges with weight < 2i and all edges adjacent to {v} U S of weight less than 2i. Algorithm use CH to identify the nodes that can be visited in arbitrary order.  ;   To identify the nodes which can be visited randomly, node set V is divided into disjoint subsets V1, V2, …, Vk, where all edges between subsets have weight at least a threshold
future=
comment=
other=
---
id=59
title=A performance analysis of hierarchical shortest path algorithms (experimental paper)
author=A. Fetterer
journal=
year=1997
tags=shortest path, SSSP, label-correcting, parallel, performance analysis, hierarchical shortest path algorithms
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=60
title=New parallel shortest path searching algorithm based on dynamically reconfigurable processor DAPDNA-2
author=H. Ishikawa
journal=
year=1997
tags= one-pair shortest path(OPSP), label-correcting, parallel, performance analysis, hierarchical shortest path algorithms, dynamically reconfigurable processor, DAPDNA-2
star=***
problem=
interest=
hardness=
idea=represented the graph in two different layers. Layer one will be represented by different disjoint sub-graphs of the graph, which are produced by partitioning of an actual graph. Layer two defines a boundary graph which is summarizing the sub-graphs.     The hierarchical algorithm is having three steps. The first step in the finding of shortest path is to compute the boundary nodes. In second and most important step which we can execute in parallel is computing the shortest path inside the sub-graphs and here two different cases are possible. If a sub-graph contains the source/destination nodes of the problem, then find the shortest path between source/destination nodes to boundary nodes in corresponding sub-graphs. For other, sub-graphs find the shortest path between boundary nodes. Third step is to create the boundary graph and update its node weight using all previously calculated shortest paths inside the sub-graphs. Now finally it will calculate the shortest path between source and destination in the boundary graph.
future=
comment=
other=
---
id=61
title=Optimizing an APSP implementation for NVIDIA GPUs using Kernel characterization criteria
author=H. Ortega
journal=The journal of Supercomputing
year=2014
tags=APSP, shortest path, Nvidia GPU, kernel characterization, L1 cache, parameter tuning, GPU setting, hpc
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=Most recent GPU architectures contain higher amounts of single processors at the cost of reducing clock frequency, in order to take advantage of the huge parallelism levels of the applications.  there is a threshold, related to the low application parallelism level, where previous CUDA architectures, working with higher clock frequencies, obtain better execution times.  Therefore, the faster architecture in this application domain is not always the most modern one, but depends on the features of the corresponding input set.
---
id=62
title=Parallel Implementation of Bellman-Ford Algorithm Using CUDA Architecture (experimental paper)
author=Ganesh G Surve, Medha A Shah
journal=International Conference on Electronics, Communication and Aerospace Technology (ICECA)
year=2017
tags=experimental paper, parallel Bellman-Ford, CUDA Architecture, GPGPU, shortest path, SSSP, Compute Unified Device Architecture, Graphics Processing Unit, Central Processing Unit, Application Programming Interface
star=**
problem=The large graphs involving millions of vertices are common in many real life applications and are challenging to process.
interest=Now a day there are number of application like routing in telephone network, travelling Information System, Data Mining, Robotic System and its data is represented in a graph and different graph contains negative weight of edges or negative edge cycle and are inefficient to process by another single source shortest path algorithm(e.g. Dijkstra’s, A*, etc.).
hardness=Data of these applications are growing every day, but we still need fast and real time response from them. At present, the serial graph algorithms have reached the time limitation as they used to take a large amount of time. Bellman-ford algorithm is the best solution to solving single source shortest path problem and which is considered to be an optimization problem in the graph theory.
idea=presents a high-performance implementation of the Bellman-Ford algorithm that exploits the architectural features of recent GPU architectures of NVIDIA to improve the performance and workload efficiency. Parallel Bellman-Ford optimizations to the implementation, which are oriented both algorithms and to the architecture. In this paper, we introduce new methods which achieve the parallelizing Bellman-Ford Algorithm and to implement some extended or new versions of this algorithm over NVIDIA GPU architecture using CUDA framework.
future=
comment=
other=just an experiment of [id:193] of bookug.list
---
id=63
title=A Modified Parallel Approach to Single Source Shortest Path Problem for Massively Dense Graphs Using CUDA
author=Sumit Kumar
journal=International Conference on Computer & Communication Technology (ICCCT)
year=2011
tags=SSSP, shortets path, dense graph, Complete graphs, Compute Unified Device Architecture (CUDA), Graphics Processing Unit (GPU), Negative Weighted Cycle (NWC), Parallel Processing, parallel Bellman-Ford
star=*
problem=
interest=
hardness=
idea=First, we modify the standard BELLMAN-FORD algorithm to remove its drawbacks and make it suitable for parallel implementation, and then implement it using CUDA. For dense graphs, our Algorithm gains a speedup of 10x – 12x over the previously proposed parallel algorithm. Our Algorithm also accept graphs with negative weighted edges and can detect any reachable Negative Weighted Cycle, which widens its scope to accept generalized problems.
future=
comment=
other=
---
id=64
title=A dynamic approach for workload partitioning on GPU architectures
author=Federico Busato, Nicola Bombieri
journal=TPDS
year=2017
tags=Computer society, IEEE, IEEEtran, journal, prefix-scan, load balacing, GPU, workload partitioning, static dynamic semi-dynamic 
star=****
problem=Workload partitioning and the subsequent work item-to-thread mapping are key aspects to face when implementing any efficient GPU application.
interest=Different techniques have been proposed to deal with such issues, ranging from the computationally simplest static to the most complex dynamic ones. Each of them finds the best use depending on the workload characteristics (static for more regular workloads, dynamic for irregular workloads).
hardness=Nevertheless, no one of them provides a sound tradeoff when applied in both cases. Static approaches lead to load unbalancing with irregular problems, while the computational overhead introduced by the dynamic or semi-dynamic approaches often worsens the overall application performance when run on regular problems.
idea=presents an efficient dynamic technique for workload partitioning and work item-to-thread mapping whose complexity is significantly reduced with respect to the other dynamic approaches in literature. The article shows how the partitioning and mapping algorithm has been implemented by fully taking advantage of the GPU device characteristics with the aim of minimizing the involved computational overhead. The article shows, compares, and analyses the experimental results obtained by applying the proposed approach and several static, dynamic, and semi-dynamic techniques at the state of the art to different benchmarks and over different GPU technologies (i.e., NVIDIA Fermi, Kepler, and Maxwell) to understand when and how each technique best applies.
future=
comment=
other=a development of Merrill et al. [id:3] of literature.list
---
id=65
title=cuRnet: an R package for graph traversing on GPU
author=V. Bonnici, Federico Busato
journal=BMC bioinformatics
year=2018
tags=cuRnet, R package, R language, graph traversal, GPU, data mining
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=66
title=Parallelizing single source shortest path with OpenSHMEM
author=F. Aderholdt
journal=Workshop on OpenSHMEM and Related technologies
year=2017
tags=parallel, shortest path, SSSP, OpenSHMEM model(single program multiple data, SPMD), distributed computing, serial Dijkstra and Bellman-Ford algorithms, Partitioned Global Address Space (PGAS) programming model
star=**
problem=
interest=
hardness=
idea=we discuss our experience parallelizing SSSP using OpenSHMEM. We start with the serial Dijkstra and Bellman-Ford algorithms, parallelize these algorithms, and adapt them to the Partitioned Global Address Space (PGAS) programming model. We implement the parallel algorithms using OpenSHMEM and introduce a series of optimizations to achieve higher scaling and performance characteristics. 
future=
comment= The implementation is evaluated on Titan with various graphs including synthetic Recursive Matrix (R-MAT) and small-world network graphs as well as real-world graphs from Facebook, Twitter, LiveJournal, and the road maps of California and Texas.
other=
---
id=67
title=Overcoming Limitations of GPGPU-Computing in Scientific Applications 
author=Connor Kenyon
journal=arXiv
year=2019
tags=GPGPU, Scientific Applications, hpc, Limitations
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=68
title=High-probability parallel transitive closure algorithms
author=J.D.Ullman, M.Yannakakis
journal=SIAM J. Comput.
year=1991
tags=high probability, parallel, transitive closure, BFS, auxiliary data structure
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=69
title=A randomized parallel algorithm for single-source shortest paths
author=P.N. Klein, S. Subramanian
journal=J. Algorithms
year=1997
tags=randomized, parallel, SSSP, weighted graph
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=extension of [id:68] from BFS to SSSP
---
id=70
title=A quantitative study of irregular programs on GPUs (LoneStar)
author=M. Burtscher
journal=IISWC
year=2012
tags=LonestarGPU Graph Library, Bellman-Ford, SSSP
star=***
problem=
interest=
hardness=
idea=naive implementation of Bellman-Ford to be parallelized for each edge on GPU
future=
comment=
other=
---
id=71
title=Lonestar: A suite of parallel irregular programs
author=M. Kulkarni, M. Burtscher
journal= IEEE International Symposium on Performance Analysis of Systems and Software
year=2009
tags=Lonestar, program suite, parallel, irregularity, LonestarGPU graph library
star=***
problem=
interest=
hardness=
idea=parallelizes over vertices, with one thread per vertex that updates distance labels for all adjacent vertices. In order to avoid race conditions, an atomic min is used for each of these updates.
future=
comment=
other=based on [id:70]
---
id=72
title=GPGPU based image segmentation livewire algorithm implementation (master dissertation)
author=D. L. Baggio
journal=Master’s thesis, Technological Institute of Aeronautics 
year=2007
tags=master dissertation, delta stepping, SSSP, GPU, image segmentation, parallel
star=***
problem=
interest=
hardness=
idea=based on [id:33] of bookug.list and parallelize it on GPU. 
future=
comment=Baggio tests his implementation on a fixed 2D grid (1024x1024 size) with possible edges emanating to neighbors on the grid. Utilizing an NVIDIA 8600 GT, their implementation remains inefficient; they achieve rates 8–17x times slower than Dijkstra’s method.
other=ANALYSIS: There are three main characteristics that make deltastepping difficult to implement efficiently on a GPU-like machine.  First, delta-stepping’s bucket implementation requires dynamic arrays that can be quickly resized in parallel. Dynamic arrays are poorly suited to the current programming model of GPUs, and implementing a custom memory management system for dynamic arrays (utilizing heaps) would be difficult and inefficient. Second, fine-grained renaming and moving vertices between buckets is difficult to parallelize, likely requiring atomics and thus losing concurrency.  Finally, efficient GPU implementations require exploiting the GPU’s three-layer memory hierarchy (global DRAM, per-block shared memory, and per-thread registers), but such a memory hierarchy is absent from the traditional deltastepping formulation.
---
id=73
title=Modern GPU Library
author=S. Baxter
journal= http://www.moderngpu.com
year=2013
tags=Modern GPU Library, hpc, sorted search
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=https://github.com/moderngpu/moderngpu
---
id=74
title=Ligra: a lightweight graph processing framework for shared memory
author=J. Shun
journal=PPoPP
year=2013
tags=Ligra, graph processing framework, shared memory, multi-core CPU, non-bulk-synchronous programming, queue management
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=75
title=Thrust: A productivity-oriented library for CUDA
author=N. Bell
journal=GPU Computing Gems
year=2011
tags=Thrust library, GPU computing, CUDA, radix sort, prefix-sum scan
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=76
title=Single-source shortest paths with the parallel boost graph library
author=N. Edmonds
journal=The Ninth DIMACS Implementation Challenge: The Shortest Path Problem
year=2006
tags=SSSP, shortest path, parallel boost graph library(parallel BGL
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=77
title=Merge Path-parallel merging made simple,
author=S. Odeh, O. Green
journal=IPDPS workshop
year=2012
tags=merge path, parallel computing, GPU, CUDA
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=78
title=Nvidia tensor core programmability, performance & precision
author=S. Markidis
journal=IPDPS workshop
year=2018
tags=Nvidia tensor core, GPU, Turing Architecture, math operation, programmability, performance, precision
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=79
title=Parallel thread execution ISA version 4.1 [Online]
author=Nvidia 
journal=
year=2014
tags=cache modifiers, Nvidia GPU, L1 cache open/close at run time, parallel thread, ISA, texture cache, __ldg function
star=***
problem=
interest=
hardness=
idea=Cache modifiers are a feature provided by Kepler GPU architectures that allows the L1 cache to be enabled or disabled at run time. This allows reducing the miss rate of cache accesses by skipping the cache use for those data not frequently used or too sparse in memory.
future=
comment=
other=https://docs.nvidia.com/cuda/parallel-thread-execution/
---
id=80
title= GPU Gems 3: Parallel Prefix Sum (Scan) With CUDA
author=J. D. O. Mark Harris
journal= Reading, MA, USA: Addison-Wesley
year=2008
tags=GPU Gems 3, prefix sum scan, CUDA, parallel, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=81
title=Fast sparse matrix-vector multiplication on gpus for graph applications
author=A. Ashari
journal=SC
year=2014
tags=CSR definition, compressed sparse row, sparse matrix-vector multiplication, GPU, graph application
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=82
title=Fast Fine-Grained Global Synchronization on GPUs
author=Kai Wang
journal=ASPLOS (CCF A)
year=2019
tags=Fine-Grained global Synchronization, GPU locking mechanism, SIMD, mutual exclusion, message passing, irregular workloads, no hardware modification, scratchpad memory lock operations, queue (enqueue and dequeue), non-blocking procedure calls, critical sections, client-server kernels, synchronization server
star=****
problem=
interest=
hardness=
idea=greatly reduce the use of slow global memory by distributing work to the faster local scratchpad memories;  message passing system implemented in global memory, employing optimizations that reduce the overhead of message passing operations and that promote coalesced memory accesses.
future=
comment=
other=
---
id=83
title=The world’s most advanced data center gpu
author=Volta
journal=
year=2017
tags=GPU, Volta architecture
star=****
problem=
interest=
hardness=
idea=
future=
comment=V100
other=https://devblogs.nvidia.com/parallelforall/inside-volta
---
id=84
title=GPUstore Harnessing GPU Computing for Storage Systems in the OS Kernel
author=Weibin Sun, Robert Ricci  (University of Utah)
journal=SYSTOR (CCF C Conference of architecture area)
year=2012
tags=GPUstore, GPU computing, storage system, OS kernel, Linux kernel, I/O request, computationally expensive component
star=***
problem=Many storage systems include computationally expensive components. Examples include encryption for confidentiality, checksums for integrity, and error correcting codes for reliability. As storage systems become larger, faster, and serve more clients, the demands placed on their computational components increase and they can become performance bottlenecks.
interest=Many of these computational tasks are inherently parallel: they can be run independently for different blocks, files, or I/O requests. This makes them a good fit for GPUs, a class of processor designed specifically for high degrees of parallelism: consumer-grade GPUs have hundreds of cores and are capable of running hundreds of thousands of concurrent threads.
hardness=However, because the software frameworks built for GPUs have been designed primarily for the longrunning, data-intensive workloads seen in graphics or highperformance computing, they are not well-suited to the needs of storage systems.
idea=GPUstore, a framework for integrating GPU computing into storage systems. GPUstore is designed to match the programming models already used these systems. We have prototyped GPUstore in the Linux kernel and demonstrate its use in three storage subsystems: file-level encryption, block-level encryption, and RAID 6 data recovery.
future=
comment=Comparing our GPU-accelerated drivers with the mature CPU-based implementations in the Linux kernel, we show performance improvements of up to an order of magnitude.
other=https://github.com/wbsun/kgpu
---
id=85
title=Scan Primitives for GPU Computing
author=Shubhabrata Sengupta, Mark Harris, Yao Zhang, John D. Owens
journal=Graphics hardware
year=2007
tags=scan Primitive, GPU computing, NVIDIA GPUs, CUDA API, quicksort, spmv
star=***
problem=We describe GPU implementations of these primitives, specifically an efficient formulation and implementation of segmented scan
interest=The scan primitives are powerful, general-purpose data-parallel primitives that are building blocks for a broad range of applications.
hardness=
idea=Using the scan primitives, we show novel GPU implementations of quicksort and sparse matrix-vector multiply, and analyze the performance of the scan primitives, several sort algorithms that use the scan primitives, and a graphical shallow-water fluid simulation using the scan framework for a tridiagonal matrix solver.
future=
comment=
other=
---
id=86
title=FPGA vs. GPU for sparse matrix vector multiply
author=Yan Zhang, Yasser H. Shalabi
journal=International Conference on Field-Programmable Technology
year=2009
tags=FPGA, GPU, spmv, sparse matrix
star=***
problem=
interest=Sparse matrix-vector multiplication (SpMV) is a common operation in numerical linear algebra and is the computational kernel of many scientific applications. It is one of the original and perhaps most studied targets for FPGA acceleration.
hardness=
idea=Despite this, GPUs, which have only recently gained both general-purpose programmability and native support for double precision floating-point arithmetic, are viewed by some as a more effective platform for SpMV and similar linear algebra computations. In this paper, we present an analysis comparing an existing GPU SpMV implementation to our own, novel FPGA implementation. In this analysis, we describe the challenges faced by any SpMV implementation, the unique approaches to these challenges taken by both FPGA and GPU implementations, and their relative performance for SpMV.
future=
comment=
other=
---
id=87
title=Efficient sparse matrix-vector multiplication on GPUs using the CSR storage format
author=     Joseph L. Greathouse,   Joseph L. Greathouse  (AMD research)
journal=SC
year=2014
tags=spmv, GPU, CSR, AMD, performance acceleration, CSR-Adaptive
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=88
title=Optimizing Sparse Matrix—Matrix Multiplication for the GPU
author=STEVEN DALTON, LUKE OLSON, NATHAN BELL
journal=ACM Transactions on Mathematical Software
year=2015
tags=sparse matrix, sparse matrix-matrix Multiplication (spmm), GPU, ESC ALGORITHM, two sparse matrices, sparse matrix-matrix multiplication (SpGEMM)
star=***
problem=Sparse matrix–matrix multiplication (SpGEMM) is a key operation in numerous areas from information to the physical sciences.
interest=
hardness=Implementing SpGEMM efficiently on throughput-oriented processors, such as the graphics processing unit (GPU), requires the programmer to expose substantial fine-grained parallelism while conserving the limited off-chip memory bandwidth
idea=Balancing these concerns, we decompose the SpGEMM operation into three highly parallel phases: expansion, sorting, and contraction, and introduce a set of complementary bandwidth-saving performance optimizations. Our implementation is fully general and our optimization strategy adaptively processes the SpGEMM workload row-wise to substantially improve performance by decreasing the work complexity and utilizing the memory hierarchy more effectively.  ;   framework: COO expansion, sort, contract (reduce)
future=
comment=
other=also see [id:37] of bookug.list
---
id=89
title=graph coloring on the GPU
author=Muhammad Osama, Minh Truong, Carl Yang
journal=IPDPSW
year=2019
tags=graph coloring, GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=90
title=LAGraph: A Community Effort to Collect Graph Algorithms Built on Top of the GraphBLAS
author=Tim Mattson, Timothy A. Davis, Manoj Kumar, Aydin Buluç, Scott McMillan, José E. Moreira, Carl Yang
journal=IPDPSW
year=2019
tags=LAGraph, graph Algorithms, GraphBLAS
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=LAGraph: a library of graph algorithms that rely on GraphBLAS [id:122] of yuqizhou.list
---
id=91
title=GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on the GPU
author=Carl Yang
journal=arXiv
year=2019
tags=GraphBLAST, linear Algebra, graph Framework, GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=The GPU version of GraphBLAS [id:122] of yuqizhou.list
---
id=92
title=Design Principles for Sparse Matrix Multiplication on the GPU
author=Carl Yang
journal=Euro-Par
year=2018
tags=sparse Matrix Multiplication, GPU, design Principles
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=93
title=Fast Sparse Matrix and Sparse Vector Multiplication Algorithm on the GPU
author=Carl Yang, Yangzihao Wang, John D. Owens
journal=IPDPSW
year=2015
tags=sparse matrix-vector multiplication, sparse vector, spmv, GPU, sparsematrix sparse-vector multiplication (SpMSpV), k-way merge, sparse-matrix sparse-matrix multiplication (SpGEMM), BFS, SSSP, dense representation, sparse representation
star=***
problem=We implement a promising algorithm for sparsematrix sparse-vector multiplication (SpMSpV) on the GPU.
interest=An efficient k-way merge lies at the heart of finding a fast parallel SpMSpV algorithm.
hardness=
idea=We examine the scalability of three approaches—no sorting, merge sorting, and radix sorting—in solving this problem.
future=
comment=For breadth-first search (BFS), we achieve a 1.26x speedup over state-of-the-art sparsematrix dense-vector (SpMV) implementations. The algorithm seems generalizeable for single-source shortest path (SSSP) and sparse-matrix sparse-matrix multiplication, and other core graph primitives such as maximal independent set and bipartite matching.
other=also see [id:37] of bookug.list
---
id=94
title= DistME: A Fast and Elastic Distributed Matrix Computation Engine using GPUs 
author=Donghyoung Han
journal=sigmod
year=2019
tags=DistME, Distributed matrix Computation engine, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=95
title=GPU-based Graph Traversal on Compressed Graphs
author=Mo Sha (National University of Singapore)
journal=sigmod
year=2019
tags=GPU, graph Traversal, Compressed graph
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=96
title=Fast BFS-Based Triangle Counting on GPUs
author=Leyuan Wang, John D. Owens
journal=arXiv
year=2019
tags=BFS-based triangle Counting (TC), GPU, subgraph matching
star=****
problem=In this paper, we propose a novel method to compute triangle counting on GPUs.
interest=Unlike previous formulations of graph matching, our approach is BFS-based by traversing the graph in an all-source-BFS manner and thus can be mapped onto GPUs in a massively parallel fashion.
hardness=
idea=Our implementation uses the Gunrock programming model and we evaluate our implementation in runtime and memory consumption compared with previous state-of-the-art work.We sustain a peak traversed-edges-per-second (TEPS) rate of nearly 10 GTEPS. Our algorithm is the most scalable and parallel among all existing GPU implementations and also outperforms all existing CPU distributed implementations.
future=
comment=This work specifically focuses on leveraging our implementation on the triangle counting problem for the Subgraph Isomorphism Graph Challenge 2019, demonstrating a geometric mean speedup over the 2018 champion of 3.84.
other=
---
id=97
title=Realtime Top-k Personalized PageRank over Large Graphs on GPUs (kPAR)
author=Jieming Shi
journal=vldb
year=2020
tags=Realtime, top-k, Personalized PageRank (PPR), large graph, GPU, adaptive forward push, inverted random walk, AFP, IRW, parallel Top-k PPR processing
star=****
problem=Given a graph G, a source node s ∈ G and a positive integer k, a top-k Personalized PageRank (PPR) query returns the k nodes with the highest PPR values with respect to s, where the PPR of a node v measures its relevance from the perspective of source s.
interest=Top-k PPR processing is a fundamental task in many important applications such as web search, social networks, and graph analytics.
hardness=This paper aims to answer such a query in realtime, i.e., within less than 100ms, on an Internet-scale graph with billions of edges. This is far beyond the current state of the art, due to the immense computational cost of processing a PPR query.
idea=We achieve this goal with a novel algorithm kPAR, which utilizes the massive parallel processing power of GPUs.  The main challenge in designing a GPU-based PPR algorithm lies in that a GPU is mainly a parallel computation device, whereas PPR processing involves graph traversals and value propagation operations, which are inherently sequen- tial and memory-bound. Existing scalable PPR algorithms are mostly described as single-thread CPU solutions that are resistant to parallelization. Further, they usually involve complex data structures which do not have efficient adaptations on GPUs. kPAR overcomes these problems via both novel algorithmic designs (namely, adaptive forward push and inverted random walks) and system engineering (e.g., load balancing) to realize the potential of GPUs. Meanwhile, kPAR provides rigorous guarantees on both result quality and worst-case efficiency.
future=We plan to consider PPR queries on multi-GPUs, as well as dynamic index updates.
comment=Extensive experiments show that kPAR is usually 10x faster than parallel adaptations of existing methods. Notably, on a billion-edge Twitter graph, kPAR answers a top-1000 PPR query in 42.4 milliseconds.
other=
---
id=98
title=A Throughput-Aware Analytical Performance Model for GPU Applications
author=Zhidan Hu
journal=Advanced Computer Architecture
year=2014
tags=GPU, Performance Analytical model, Throughput-Aware
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=99
title=GPUPerfML: A Performance Analytical Model Based on Decision Tree for GPU Architectures
author=Ran Zheng
journal=HPCC/SmartCity/DSS
year=2018
tags=GPU, Performance Analytical model, Decision tree, GPUPerfML
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=100
title=An Analytical Model for a GPU Architecture with Memory-level and Thread-level Parallelism Awareness
author=Sunpyo Hong, Hyesoon Kim
journal=ISCA (CCF A Conference of Architecture area)
year=2009
tags=Performance Analytical model, GPU Architecture, Memory-level Parallelism, Thread-level Parallelism Awareness, CUDA, Performance estimation, parallel memory request, memory warp Parallelism (MWP), computation warp Parallelism (CWP), arithmetic intensity
star=****
problem=Programming thousands of massively parallel threads is a big challenge for software engineers, but understanding the performance bottlenecks of those parallel programs on GPU architectures to improve application performance is even more difficult.
interest=GPU architectures are increasingly important in the multi-core era due to their high number of parallel processors
hardness=Current approaches rely on programmers to tune their applications by exploiting the design space exhaustively without fully understanding the performance characteristics of their applications.
idea=To provide insights into the performance bottlenecks of parallel applications on GPU architectures, we propose a simple analytical model that estimates the execution time of massively parallel programs.  The key component of our model is estimating the number of parallel memory requests (we call this the memory warp parallelism) by considering the number of running threads and memory bandwidth. Based on the degree of memory warp parallelism, the model estimates the cost of memory requests, thereby estimating the overall execution time of a program
future=
comment=
other=CWP is similar to arithmetic intensity in the GPGPU Community
---
id=101
title=Memory-level and Thread-level Parallelism Aware GPU Architecture Performance Analytical Model
author=Sunpyo Hong, Hyesoon Kim
journal=Citeseer
year=2009
tags=Performance Analytical model, GPU Architecture, Memory-level Parallelism, Thread-level Parallelism Awareness, CUDA, Performance estimation
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=full version of [id:100]
---
id=102
title=Program optimization space pruning for a multithreaded gpu 
author= Shane Ryoo, Christopher I. Rodrigues, Sam S. Stone, Sara S. Baghsorkhi, Sain-Zee Ueng
journal=2008 Symposium on Code Generation and Optimization  (CGO)
year=2008
tags=Performance Analytical model, GPU Architecture,  CUDA, Program Optimization space pruning, multithreaded gpu, GPGPU
star=***
problem=programmers might need to vary all the combinations to find the best performing configurations.
interest=
hardness=
idea=
future=
comment=
other=
---
id=103
title=Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks: An Analytical Approach based on Roofline Model
author=Chen Zhang, Peng Li, Guangyu Sun, Yijin Gua, Bingjun Xiao, and Jason Cong
journal=Proceedings of 23rd ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA, CCF B Conference of Architecture)
year=2015
tags=best paper nomination, Field-Programmable Gate Arrays (FPGA), FPGA-based Accelerator design, deep Convolutional Neural network (CNN, DNN), Analytical Approach, Roofline model
star=****
problem=
interest=
hardness=
idea=
future=
comment=首次提出基于Roofline模型的卷积神经网络（CNN）加速器设计方法，将计算单元、片上存储、带宽等资源进行抽象来构造设计空间，并可以根据优化目标探索空间以寻找最优方案。基于该方法的FPGA卷积神经网络加速器达到当时最好水平，该成果获得FPGA2015最佳论文提名，被MIT、斯坦福大学、剑桥大学、谷歌（TPU论文）、三星、英伟达等科研机构和公司引用800余次。后续工作将该方法扩展到RNN/LSTM等模型、访存压缩、FPGA集群等不同场景。
other=
---
id=104
title=Caffeine: Towards uniformed representation and acceleration for deep convolutional neural networks
author=C Zhang, G Sun, Z Fang, P Zhou, P Pan, J Cong
journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD, CCF A Conference of Architecture)
year=2019
tags=Caffe, TensorFlow, FPGA, DNN, CNN, Caffeine, uniformed representation and acceleration
star=****
problem=
interest=
hardness=
idea=
future=
comment=为提高基于FPGA的神经网络加速器芯片设计效率，提出一系列自动化设计方法，可以将深度学习框架（如Caffe、TensorFlow）输出的网络模型自动化部署到FPGA上并达到同时期最好水平，其中发表于TCAD的成果获得2019 Donald O. Pederson最佳论文奖。
other=
---
id=105
title=PM3: Power Modeling and Power Management for Processing-in-Memory
author=Chao Zhang, Tong Meng, Guangyu Sun
journal=High-Performance Computer Architecture  (HPCA, CCF A Conference of Architecture)
year=2018
tags=PM3, power Modeling, power Management, Processing-in-Memory
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=106
title=RC-VNM: Enabling Symmetric Row and Column Memory Accesses for In-Memory Databases
author=Peng Wang, Shuo Li, Guangyu Sun, Xiaoyang Wang, Yiran Chen, Hai Li, Jason Cong, Nong Xiao, Tao Zhang
journal=HPCA
year=2018
tags=RC-VNM, Symmetric row and column memory access, In-Memory database
star=****
problem=
interest=
hardness=
idea=
future=
comment=基于新型非易失存储器件（NVM）提出针对深度学习的体系架构，包括存内计算、行列对称访问等，可以显著提升处理能效，成果发表在HPCA、TC等顶级会议和期刊。
other=
---
id=107
title=RC-NVM: Dual-Addressing Non-Volatile Memory Architecture Supporting Both Row and Column Memory Accesses
author=S Li, N Xiao, P Wang, G Sun, X Wang, Y Chen, HH Li, J Cong, T Zhang
journal= IEEE Transactions on Computers (TC, CCF A journal of Architecture)
year=2019
tags=RC-NVM, Dual-Addressing, Non-Volatile memory Architecture, row and Column memory access
star=****
problem=
interest=
hardness=
idea=
future=
comment=基于新型非易失存储器件（NVM）提出针对深度学习的体系架构，包括存内计算、行列对称访问等，可以显著提升处理能效，成果发表在HPCA、TC等顶级会议和期刊。
other=homepage of Guangyu Sun     https://ceca.pku.edu.cn/people/faculty/sgy/index.htm
---
id=108
title=CRAT: Enabling Coordinated Register Allocation and Thread-level Parallelism Optimization for GPUs
author=Xiaolong Xie, Yun Liang, Xiuhong Li, Yudong Wu, Guangyu Sun, Tao Wang, Dongrui Fan
journal=TC
year=2018
tags=CRAT, Coordinated Register Allocation, Thread-level Parallelism, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=109
title=Optimizing Cache Bypassing and Warp Scheduling for GPUs
author=Yun Liang, Xiaolong Xie, Yu Wang, Guangyu Sun, Tao Wang
journal=TCAD
year=2018
tags=cache Bypassing, warp Scheduling, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=110
title=Enabling Coordinated Register Allocation and Thread-level Parallelism Optimization for GPUs
author=Xiaolong Xie, Yun Liang, Xiuhong Li, Yudong Wu, Guangyu Sun, Tao Wang, Dongrui Fan
journal=IEEE/ACM International Symposium on Microarchitecture (MICRO, CCF A Conference of Architecture)
year=2015
tags=Coordinated Register Allocation, Thread-level Parallelism, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=the journal version is in [id:108]
---
id=111
title=Coordinated static and dynamic cache Bypassing for GPUs
author=Xiaolong Xie, Yun Liang, Yu Wan, Guangyu Sun, Tao Wang
journal=HPCA
year=2015
tags=Coordinated static and dynamic, cache Bypassing, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=112
title= Optimizing GPU Energy Efficiency with 3D Die-stacking Graphics Memory and Reconfigurable Memory Interface
author=Jishen Zhao, Guangyu Sun, Gabriel H. Loh, and Yuan Xie
journal=ACM Transactions on Architecture and Code Optimization (TACO, CCF B journal of Architecture)
year=2013
tags=GPU Energy Efficiency, 3D Die-stacking Graphics memory, Reconfigurable memory Interface
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
