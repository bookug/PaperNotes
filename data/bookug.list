---
id=0
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=1
title=Lessons Learned from Exploring the Backtracking Paradigm on the GPU
author=    John Jenkins,Isha Arkatkar,John D. Owens,Alok Choudhary,Nagiza F. Samatova
journal= European Conference on Parallel and Distributed Computing(Euro-Par)
year=2011
tags=Shared Memory,Connectivity Query,Memory Operation,Frequent Itemset Mining,Candidate Path,backtrack,Maximal Clique Enumeration(MCE), k-d tree(KD-tree)
star=***
problem=how to parallelize backtracking paradigm
interest=backtracking paradigm(depth-first search) is common in graph algorithms
hardness=backtracking paradigm is hard to parallelize
idea=store candidate paths in stack instead of backtracking, warp-level parallelism on GPU, work stealing, output buffering, coarse-grain parallelization where multiple subtrees are explored in parallel, utilize both CPU and GPU
future=improve the load balance on GPU
comment=A deep consideration of backtracking paradigm and depth-first search for graph algorithms,inability to provide better performance of MCE than CPU,four lessons are remarkable
other=breadth-first search is easier to be parallelized compared to depth-first search, but it consumes too much memory;combination is an idea and dividing into many blocks is another
---
id=2
title= A Sparse Completely Positive Relaxation of the Modularity Maximization for Community Detection
author=Haoyang Liu
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=3
title=GPU acceleration of subgraph isomorphism search in large scale graph
author=Bo Yang, Kai Lu, Yinghui Gao, Xiaoping Wang, Kai Xu
journal=Journal of Central South University
year=2015
tags=subgraph isomorphism, backtrack paradigm, GPU, parallel
star=*
problem=how to apply TurboISO to GPU
interest=TurboISO is a fast CPU subgraph isomorphism algorithm, is it suitable for GPU?
hardness=TurboISO adopts backtrack paradigm which is hard to be parallelized
idea=parallelism in different candidate region, the independency property of the partial subtree embedding allows that the GPU region exploration algorithm can first divide the region exploration into expanding and backtracking of partial subtree embeddings and then conquer the partial subtree embedding and generate new ones in parallel
future=
comment=the key of this paper is to adopts some BFS expanding strategies in the DFS framework, the shortcoming is that lots of DFS operations still exist and will limit the overall performance; if dfs work is too little, then the size of candidates will be too large for GPUto run(memory and thread limits), if dfs work is too much, then the time cost of dfs is too high, though the size of candidates for BFS is reduced
other=backtrack paradigm is rarely used in parallel computing; much faster than vf2[id=58], but hard to implement
---
id=4
title=THE ENUMERATION OF MAXIMAL CLIQUES OF LARGE GRAPHS
author=E. A. Akkoyunlu
journal=SIAM J. Comput.
year=1973
tags=Graph Algorithm, Maximal Clique,Backtrack
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=the same idea as [id=5]
---
id=5
title=Finding All Cliques of an Undirected Graph
author=Coenraad Bron, Joep Kerbosch
journal=Commun. ACM
year=1973
tags=Graph Algorithm, Maximal Clique,Backtrack
star=****
problem=how to enumerate all maximal cliques in a graph
interest=widely used and its efficiency is very important in practice
hardness=A NP-hard problem
idea=use backtracking for search, with pruning strategies(pivot selection and vertex degeneracy ordering)
future=better pivot vertex selection, special optimization for special graphs
comment=classical and efficient work on maximal cliques enumeration,strict theoretical bound,work efficiently for many kinds of graphs including social network
other=different kinds of graphs have different kinds of optimizations; https://en.wikipedia.org/wiki/Bron%E2%80%93Kerbosch_algorithm#cite_note-1
---
id=6
title=Real-time KD-tree construction on graphics hardware
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=7
title=A Survey of General-Purpose Computation on Graphics Hardware
author=John D. Owens
journal=
year=2007
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=8
title=Efficient Gradient Boosted Decision Tree Training on GPUs
author=Zeyi Wen,Bingsheng He
journal=IEEE International Parallel and Distributed Processing Symposium(IPDPS)
year=2018
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=9
title=Gunrock: A High-Performance Graph Processing Library on the GPU
author=Yangzihao Wang , Andrew A. Davidson , Yuechao Pan , Yuduo Wu , Andy Riffel , John D. Owens
journal=Symposium on Principles and Practice of Parallel Programming(PPoPP)
year=2016
tags=GPU,Graph Algorithm,Graph Library,Graph Processing System,data-centric,bulk-synchronous,based on frontier,load balance, kernel fusion
star=*****
problem=
interest=
hardness=the irregularity of data access/control flow and the complexity of programming GPUs
idea=data-centric primitives(advance, filter, compute, intersection)
future=
comment=
other=
---
id=10
title= PowerGraph:DistributedGraph-ParallelComputationonNaturalGraphs
author=Joseph E. Gonzalez, Yucheng Low
journal=USENIX Symposium on Operating Systems Design and Implementation(OSDI)
year=2012
tags=Graph System
star=*****
problem=how to deal with natural graph(power-law distribution) in  distributed computing
interest=natural graph is widely encountered, the performance of distributed computing is very critical
hardness=high-degree nodes,heavy communication cost among machines
idea=divide partitions by vertex cut; GAS decomposition; delta caching, values of many vertices not change and no need to gather them
future=
comment=an efficient and promising work
other=
---
id=11
title=Hardware Acceleration in Commercial Databases: A Case Study of Spatial Operations
author=Nagender Bandi, Chengyu Sun
journal=VLDB
year=2004
tags=Hardware Acceleration,complex data types(spatial geometries, protein structures)
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=12
title=Shared Memory Parallel Subgraph Enumeration
author=Raphael Kimmig,Henning Meyerhenke,Darren Strash
journal=IEEE International Parallel and Distributed Processing Symposium(IPDPS) Workshops
year=2017
tags=subgraph enumeration, subgraph isomorphism,parallel combinatorial search,graph mining,network analysis,work-stealing
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=13
title=Efficient Subgraph Matching Using GPUs
author=Xiaojie Lin,Rui Zhang,Zeyi Wen
journal=Databases Theory and Applications - 25th Australasian Database Conference(ADC)
year=2014
tags=subgraph matching,GPU,relational join,comparison of several subgraph isomorphism algorithms
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=14
title=Query Workload-based RDF Graph Fragmentation and Allocation
author=Peng Peng, Lei Zou, Lei Chen,Dongyan Zhao
journal= International Conference on Extending Database Technology (EDBT, CCF B in Database area)
year=2016
tags=RDF,Graph Fragmentation, query workload, Graph Partition,communication cost, distributed environment, crossing match
star=***
problem= reduce the number of crossing matches and the communication cost during SPARQL query processing in distributed environment
interest=distributed computing is common and the communication cost is the bottleneck
hardness=high-degree nodes, complex model of distributed computing
idea= mine and select some frequent access patterns to reflect the characteristics of the workload,  Vertical fragmentation is for better throughput and horizontal fragmentation is for lower latency
future=
comment=find out all instances of a frequent pattern as fragments,place all instances of a query in several machines to lower latency of the single query(enable parallism of this query), place all instances in one machine to improve throughput(enable parallism of multiple queries); allocate closely related fragments in one machine to lower the communication cost of dealing with decomposed query
other=An improved version is in [id=16]; based on edge cut, may not work well on high-degree nodes
---
id=15
title=Processing SPARQL queries over distributed RDF graphs
author=Peng Peng, Lei Zou, Tamer, Lei Chen,Dongyan Zhao
journal=VLDB Journal
year=2016
tags=distributed environment,RDF, SPARQL,partial evaluation and assembly, local partial match, centralized and distributed
star=****
problem=how to answer SPARQL queries in a distributed environment
interest=RDF datasets with billions of tripels are common now
hardness=how to combine the results in different machines,how to reduce the communication cost
idea=given an arbitary partition(partition-agnostic), partial evaluation and join the results;centralized assembly is simple but the cost of the master machine will be too high, distributed assembly is complex(BSP, bulk synchronous parallel) but efficient and load balanced
future=handling SPARQL queries over linked open data (LOD),  multiple SPARQL query optimization in the context of distributed RDF graphs
comment=in practice specific partition for a specific kind of dataset is more efficient, though not so flexible
other=
---
id=16
title=Adaptive Distributed RDF Graph Fragmentation and Allocation based on Query Workload
author=Peng Peng, Lei Zou, Lei Chen,Dongyan Zhao
journal=IEEE Transactions on Knowledge and Data Engineering(TKDE)
year=2018
tags=Distributed RDF Database, Data Fragmentation, Data Allocation, Query Workload
star=****
problem=
interest=
hardness=
idea=allocate these fragments to various sites while balancing the fragments;  vertical, horizontal and mixed fragmentation
future=
comment=
other=The original work is in [id=14], the enhancement is that a mixed fragmentation strategy is proposed
---
id=17
title=Collaborative (CPU + GPU) Algorithms for Triangle Counting and Truss Decomposition on the Minsky Architecture
author=Ketan Date,Keven Feng
journal=High Performance Extreme Computing Conference (HPEC)
year=2017
tags=CPU,GPU,Triangle Counting,Truss Decomposition
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=various memory management on GPU
---
id=18
title=Fast and Adaptive List Intersections on the GPU
author=James Fox, Oded Green, Kasimir Gabert
journal=HPEC(not in CCF list)
year=2018
tags=GPU,List Intersection
star=***
problem=for  many  graph  based problems  it  is  necessary  to  find  intersections  for  a  very  large number  of  lists—these  lists  tend  to  vary  greatly  in  size  and are   difficult   to   efficiently   load-balance
interest=List intersections are ubiquitous and can be found in   wide   range   of   applications,   including   triangle   counting and  finding  the  maximal k-truss,  both  of  which  are  part  of the  HPEC  Static  Graph  Challenge
hardness=load imbalance due to the irregular property of graph
idea=assigns  a  different  number  of  threads  for  different intersections  in  order  to  effectively  utilize  the  resources  of  the GPU; search-based and merge-based; estimate the cost and split into sublists
future=
comment=less abstarct, not so novel; no use about shared memory; how to set the size of bin and how many threads to use for this bin; load imbalance still exists in a bin
other=the original idea is in [id=57]
---
id=19
title=Static Graph Challenge: Subgraph Isomorphism
author=
journal=HPEC workshop
year=2018
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=just a competition instead of a paper, named GraphChallenge
other=https://graphchallenge.mit.edu/
---
id=20
title=Multilevel Parallelism for the Exploration of Large-Scale Graphs
author=Massimo Bernaschi, Mauro Bisson
journal=IEEE Trans. Multi-Scale Computing Systems
year=2018
tags=GPU cluster,BC(Betweeness Centrality), BFS(Breadth-first search),Large graphs, graph algorithms, parallel algorithms, parallel programming, distributed programming, CUDA
star=**
problem=
interest=
hardness=
idea=
future=improve the heuristic to switch between the top-down and the bottom-up variant and to evaluate the advantages that technologies likeGPUDirectAsynccanprovideforreducingthe overhead of the communication among GPUs; explore the chance of using our BFS as a building block for the solution of other graphs problems.
comment=
other=
---
id=21
title=Experimental Evaluation of GPU Solutions to the Single Source Shortest Path Problem(SSSP)
author=
journal=
year=2017
tags=GPU,CUDA,Shortest Path
star=***
problem=
interest=
hardness=
idea=compare dijkstra(strict limitation, lowest work complexity), bellman-ford(lose limitation, highest work complexity) and the mixed version(delta stepping, split into buckets); diffrent system like BGL(Boost Graph Library), PGBL(Parallel Boost Graph Library), Gunrock and LoneStarGPU
future=
comment=
other=https://www.boost.org/doc/libs/1_63_0/libs/graph_parallel/doc/html/index.html
---
id=22
title=HyperX: A Scalable Hypergraph Framework
author=Wenkai Jiang, Jianzhong Qi, Jeffery Xu Yu
journal=IEEE Transactions on Knowledge and Data Engineering(TKDE)
year=2018
tags=Hypergraph, HyperX, graph framework, graph partitioning, label propagation partitioning
star=****
problem=support hypergraph computing
interest=not regular and hard to represent, but do occur in real case; Hypergraphs are generalizations of graphs where the (hyper)edges can connect any number of vertices. They are powerful tools for representing complex and non-pairwise relationship
hardness=existing graph computation frameworks cannot accommodate hypergraphs without converting them into graphs, because they do not offer APIs that support (hyper)edges directly. This graph conversion may create excessive replicas and result in very large graphs, causing difficulties in workload balancing 
idea=design a new optimization objective aimed to minimize the number of replicas and to achieve the balanced partitions, propose a novel label propagation algorithm to achieve the optimization running in parallel with several heuristics
future=open source HyperX and use it for other hypergraph processing tasks such as building similarity based regularization classifier for recommender systems and studying biochemical interactions.
comment=
other=
---
id=23
title=Learning with hypergraphs: Clustering, classification, and embedding
author=Dengyong Zhou, Jiayuan Huang
journal=Annual Conference on Neural Information Processing Systems(NIPS)
year=2006
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=24
title=Accelerating Dynamic Graph Analytics on GPUs
author=Mo Sha, Yuchen Li, Bingsheng He
journal=Proceedings of the VLDB Endowment
year=2017
tags=Dynamic Graph Analytics,GPU, stream updates, Graph Stream
star=****
problem=
interest=
hardness=dynamic 
idea=
future=
comment=
other=a technical report in detail can be acquired on arXiv
---
id=25
title=Towards GPU-Based Common-Sense Reasoning: Using Fast Subgraph Matching
author=Ha-Nguyen Tran, Erik Cambria, Amir Hussain
journal=Cognitive Computation
year=2016
tags=Common-Sense Reasoning, GPU, Subgraph Matching, CUDA
star=***
problem=transform reasoning to subgraph Isomorphism on Knowledge graph
interest=leverage the power of GPU to do reasoning, and not from scratch but using the existing work of subgraph matching
hardness=subgraph matching is a NP_hard problem
idea=edge-based subgraph Isomorphism on GPU, multi-level graph compression(finding similar nodes in Knowledge graphs and combine into one hyper-node) to place large graph on GPU
future=
comment=
other=use subgraph Isomorphism algorithm like [id=12] in literature.list; the graph compression strategy is similar to [id=5] in yuqizhou.list
---
id=26
title=Efficient Semantic Search over Structured Web Data: A GPU Approach
author=Ha-Nguyen Tran
journal=Computational Linguistics and Intelligent Text Processing
year=2017
tags=GPU, Reasoning, RDF, SPARQL
star=**
problem=
interest=
hardness=
idea=backward chaining
future=
comment=
other=
---
id=27
title=privacy-preserving ranked neighbor query over encrypted graph data in the cloud
author=Hong Zhu, Bin Wu
journal=security and communication networks
year=2016
tags=encrypted graph, randked neighbor query, cloud computing, searchable encryption
star=**
problem=how to rank neighbors in a encrypted scene
interest=
hardness=in cloud encryption is used to protect the privacy of users, but this means ranking is very hard to do
idea=
future=
comment=
other=
---
id=28
title=An Efficient Algorithm for Subgraph Isomorphism using Dynamic Programming on Directed Acyclic Graphs
author=
journal=
year=2018
tags=
star=
problem=
interest=
hardness=
idea= dynamic programming on directed acyclic graphs, the adaptive matching order with DAG-ordering, pruning by failing sets
future=
comment=
other=
---
id=29
title=Accelerating graph isomorphism queries in a graph database using the GPU
author=
journal=
year=2016
tags=GPU, subgraph isomorphism, graph database
star=
problem=performing subgraph isomorphism in a graph database using GPU
interest=
hardness=
idea=
future=
comment=the subgraph isomorphism algorithm is GpSM in [id=12] in literature.list
other=for graph database an index can be built to speed up the searching, which uses the features of the data graphs
---
id=30
title=Challenging the Time Complexity of Exact Subgraph Isomorphism for Huge and Dense Graphs with VF3
author=Carletti V
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI, CCF A journal of Artificial Intelligence)
year=2018
tags=Graphs, graph matching, graph isomorphism, subgraph isomorphism, graphs dataset,vf3
star=****
problem=
interest=able to manage huge and dense graphs
hardness=traditional algorithms only deals with small and sparse graphs; hard to prune in dense graphs
idea=
future=
comment=
other=it seems there is a former version in 2017;   vf2 is also published on TPAMI, and vf3 is the evolution of VF2Plus, which is also an evolution of VF2[id=58]; TPAMI is a famous journal with Impact Factor higher than 9; another paper is Introducing VF3: A New Algorithm for Subgraph Isomorphism
---
id=31
title=A Distributed Multi-GPU System for Fast Graph Processing
author=Zhihao Jia, Yongkee Kwon
journal=PVLDB
year=2017
tags=multi-GPU clusters, graph processing, distributed computing
star=****
problem=speed up graph processing using GPU cluster
interest=to leverage power of multi-GPUs to beat distributed or shared-memory systems
hardness=work assignment and communication among GPUs
idea=Lux system exploiting locality and  the aggregate memory bandwidth on GPUs, dynamic graph repartitioning strategy that enables well-balanced workload distribution with minimal overhead, a model choosing the number of nodes and GPUs for the best possible performance
future=
comment=not so novel but a general framework
other=GPUs communicate via NVLink; Five algorithms are tested, PR(PageRank), CC(connected components), SSSP(single-source shortest path), BC(betweenness centrality), CF(collaborative filtering)
---
id=32
title=Work-Efficient Parallel GPU Methods for Single-Source Shortest Paths
author=Andrew A. Davidson, Sean Baxter, Michael Garland, John D. Owens
journal=IPDPS(CCF B of high performance computing)
year=2014
tags=GPU computing, graph traversal, single-source shortest paths(SSSP), sparse graphs
star=****
problem=how to implement SSSP on GPU
interest=SSSp is frequently encountered in real life
hardness=dijkstra's algorithm is hard to parallize, while the work complexity of bellman-ford is too high
idea=Workfront Sweep, Near-Far and Bucketing; to balance the tradeoff between saving work and organizational overhead
future=dynamic method that switches between Workfront Sweep and Near-Far(begin with a Workfront Sweep method until the vertex queue becomes large enough to saturate the GPU, Now that there is sufficient parallelism, we would switch to our Near-Far Pile technique where work efficiency is more important. Finally, after most of the graph has been explored, and we return to a lack of sufficient parallelism, we would switch back again to Workfront Sweep to finish off the problem, similar to [id=36]);  lack of available parallelism on road network (low-degree graphs), combine our work-saving method with a PHAST-like pre-processing step to identify more vertices from which to start our SSSP sweeps
comment=reduce the work complexity remarkably; works for low-degree and scale-free graphs both
other=
---
id=33
title=Δ-stepping: a parallelizable shortest path algorithm
author=U. Meyer, P. Sanders
journal= European Symposium on Algorithms(ESA, CCF B Conference of computer science theory)
year=1998
tags=parallel, delta stepping, shortest path(SSSP)
star=****
problem=
interest=
hardness=
idea=
future=
comment=successful for coarse-grained parallel CPus; difficult to implement efficiently on a GPU-like machine(by [id=32]):bucket implementation requires dynamic arrays that can be quickly resized in parallel. Dynamic arrays are poorly suited to the current programming model of GPUs, and implementing a custom memory management system for dynamic arrays (utilizing heaps) would be difficult and inefficient;  fine-grained renaming and moving vertices between buckets is difficult to paral lelize, likely requiring atomics and thus losing concurrency; efficient GPU implementations require exploiting three-layer memory hierarchy(global DRAM, per-block shared memory, and per-thread registers) of GPU
other=delta stepping, the original idea
---
id=34
title=GPGPU based image segmentation livewire algorithm implementation
author=
journal=
year=2007
tags=GPGPU, image segmentation, delta-stepping, shortest path(SSSP)
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=a GPU version of delta-stepping for SSSP, see [id=33]
---
id=35
title=Implementing sparse matrix-vector multiplication on throughput-oriented processors
author= Nathan Bell, Michael Garland
journal=International Conference for High Performance Computing, Networking, Storage, and Analysis(SC, CCF A)
year=2009
tags=Graph Data Structure, GPU, DIA(Diagonal format), ELL(ELLPACK), CSR(Compressed Sparse Row), COO(Coordinate Format)
star=*****
problem=
interest=
hardness=
idea=ELLPACK format is well-suited to vector and SIMD architectures,  its efficiency rapidly degrades when the number of nonzeros per matrix row varies; the storage efficiency of the COO format is invariant to the distribution of nonzeros per row, and the use of segmented reduction makes its performance largely invariant as well; To obtain the advantages of both, we combine these into a hybrid ELL/COO format
future=
comment=not use CSR and COO when matrix is small because there is not enough work; CSR not benefit from coalescing memory access
other=discussion of possible implementations, advantages, and disadvantages of several formats for sparse matrices
---
id=36
title=Memory-scalable GPU spatial hierarchy construction
author=
journal=IEEE Transactions on Visualization and Computer Graphics(TVCG, CCF A Journal)
year=2011
tags=GPU, BFS,Memory bound, kd-tree, bounding volume hierarchy,partial BFS 
star=****
problem=While being able to exploit the massive parallelism on the GPU, the BFS order also consumes excessive GPU memory and threads
interest=
hardness=
idea=use the partial breadth-first search (PBFS) construction order to control memory consumption while maximizing performance; memory allocation strategies to effectively limit memory fragmentation
future=
comment=a novel idea to turn from BFS to DFS at some point
other=
---
id=37
title=Fast Sparse Matrix and Sparse Vector Multiplication Algorithm on the GPU
author=Carl Yang, Yangzihao Wang, John D. Owens
journal=IPDPS
year=2015
tags=GPU, SpMSpV, SpMV
star=
problem=
interest=
hardness=different from SpMV(sparse matrix, dense vector)
idea=
future=
comment=
other=
---
id=38
title=Efficient wait-free implementation of a concurrent priority queue
author=
journal=WDAG
year=1993
tags=concurrent priority queue, Data Structure
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=39
title=Comparative Performance Analysis of Intel Xeon Phi, GPU, and CPU: A Case Study from Microscopy Image Analysis
author=
journal=IPDPS
year=2014
tags=GPU, MIC(Many Integrated Core)
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=40
title=Efficiency of a Good But Not Linear Set Union Algorithm
author=
journal=Journal of the ACM(JACM, CCF A Journal)
year=1975
tags=set union, disjoint set, union find, data structure, algorithm, complexity, equivalence, partition, tree 
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=citation higher than 1500; the original paper of disjoint set
---
id=41
title=Parallelizing Union-Find in Constraint Handling Rules Using Confluence Analysis
author=
journal=International Conference on Logic Programming(ICLP)
year=2005
tags=union find, disjoint set, parallel
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=42
title=Wait-free parallel algorithms for the union-find problem
author=
journal=ACM symposium on Theory of computing(STOC, CCF A Conference of computer science)
year=1991
tags=union find, disjoint set, parallel algorithm, wait-free, asynchronous parallelism
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=citation higher than 120
---
id=43
title=A New Scalable Parallel DBSCAN Algorithm Using the Disjoint-Set Data Structure
author=
journal=SC
year=2012
tags=Density based clustering, Union-Find algorithm, Disjoint-set  data  structure
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=44
title=Experiments on Union-Find Algorithms for the Disjoint-Set Data Structure
author=
journal=International Symposium on Experimental Algorithms(SEA)
year=2010
tags=Union-Find Disjoint Set Experimental Algorithms 
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=45
title=Multi-core spanning forest algorithms using the disjoint-set data structure
author=
journal=IPDPS
year=2012
tags=Multi-core, spanning forrest, connected components, Disjoint sets
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=46
title=Template Skycube Algorithms for Heterogeneous Parallelism on Multicore and GPU Architectures
author=
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Heterogeneous Parallelism
star=****
problem=
interest=
hardness=
idea= a novel templating methodology to create portable, yet architecture-aware algorithms;  cache-conscious CPU optimizations
future=
comment=
other=
---
id=47
title=A Memory Bandwidth-Efficient Hybrid Radix Sort on GPUs
author=Elias Stehle, Hans-Arno Jacobsen
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Hybrid Radix Sort, memory bandwidth
star=****
problem=
interest=
hardness=
idea=proceeding from the most-significant to the least-significant digit allows our algorithm to drop the requirement  of  stable  sorting  passes(not LSB-based, reduce the number of sorting passes and the amount of memory transfers);   heterogeneous  sorting  algorithm that uses the CPU on powerful host systems to mitigate the overhead introduced with PCIe data transfers and sort arbitrarily large inputs, using pipeline to exploit the full-duplex communication of the PCIe bus
future=
comment=
other=
---
id=48
title=Scout: A GPU-Aware System for Interactive Spatio-temporal Data Visualization
author=Harshada Chavan, Mohamed F. Mokbel
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Data Visualization, Spatio-temporal
star=****
problem=
interest=
hardness=
idea=Spatio-temporal indices
future=
comment=only a specific area, not so novel, seems like a demo
other=
---
id=49
title=Parallelizing Sequential Graph Computations
author=
journal=SIGMOD
year=2017
tags=GRAPE, parallel model, graph computation, partial evaluation, incremental evaluation, scalability
star=*****
problem=
interest=auto-parallelization with minor changes to sequential algorithm and ensure the correctness
hardness=
idea=
future=
comment=
other=best paper award of SIGMOD 2017
---
id=50
title=SuRF: Practical Range Query Filtering with Fast Succinct Tries
author=
journal=SIGMOD
year=2018
tags=data structure, range query, bloom filter, reduce I/O, membership test
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=best paper award of SIGMOD 2018
---
id=51
title=Entity Matching with Active Monotone Classification
author=
journal= ACM SIGMOD Conference on Principles of DB Systems(PODS, CCF B, top theorectical conference in Database area)
year=2018
tags=entity matching, active learning, monotone classification, entity matching, computation theory, Approximation algorithms analysis
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=best paper award of PODS 2018
---
id=52
title=Query-based Workload Forecasting for Self-Driving Database Management Systems
author=
journal=SIGMOD
year=2018
tags=workload forecasting, dynamic workload, self-driving database system
star=****
problem=predict the workload in future and select the proper optimizations in a timely manner for a dynamic changing workload
interest=
hardness=
idea=
future=
comment=
other=
---
id=53
title=Cold Filter: A Meta-Framework for Faster and More Accurate Stream Processing
author=Yang Zhou, Tong Yang
journal=SIGMOD
year=2018
tags=data streams, Approximate algorithms, data structures, sketch, stream processing
star=****
problem=
interest=
hardness=
idea=Different from existing filters that mainly focus on hot items, our filter captures cold items in the first stage, and hot items in the second stage; each item enters one stage only once
future=
comment=
other=
---
id=54
title=TurboFlux: A Fast Continuous Subgraph Matching System for Streaming Graph Data
author=Kyongmin Kim, In Seo (same contribution)
journal=sigmod
year=2018
tags=dynamic graph, graph stream, continuous Subgraph matching
star=****
problem=answering continuous subgraph matching on dynamic graph
interest=subgraph matching is NP-hard and graph stream is hard to deal with
hardness=repeated subgraph matching for each edge update or expensive overheads in maintaining enormous intermediate results
idea=a concise representation of intermediate results, and its execution model allows fast incremental maintenance; an efficiently updatable graph for storing partial solutions(data-centric graph); edge transition model, which efficiently identifies which update operation can affect the current partial solutions
future=
comment=an amazing work which tries to solve the continuous subgraph matching problem on practical graph stream
other=
---
id=55
title=Speeding Up Set Intersections in Graph Algorithms using SIMD Instructions
author=Shuo Han, Lei Zou, Jeffery Xu Yu
journal=sigmod
year=2018
tags=set Intersections, graph algorithms, SIMD, subgraph matching, triangle counting, clique detection, graph ordering, graph processing
star=****
problem=
interest=set intersection is widely used in graph algorithms, occupying a large potion of time
hardness=
idea=a binary representation scheme(BSR) to encode adjacency-lists, a merge-based intersection algorithm(QFilter), the node ordering also affects the performance by influencing the compactness of BSR sets
future=
comment=
other=
---
id=56
title=Randomized Algorithms Accelerated over CPU-GPU for Ultra-High Dimensional Similarity Search
author=Yiqiu Wang, Anshumali Shrivastava
journal=sigmod
year=2018
tags=CPU-GPU, similarity search, locality sensitive hashing, reservoir sampling, GPGPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=57
title=Logarithmic Radix Binning and Vectorized Triangle Counting
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=58
title=A (Sub)Graph Isomorphism Algorithm for Matching Large Graphs (vf2)
author=
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI, CCF A journal of Artificial Intelligence)
year=2004
tags=vf2,graph-subgraph isomorphism,induced subgraph,depth-first search,Backtrack paradigm,backtracking,large graphs, attributed relational graphs
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=based on induced subgraph rather than embedding subgraph;the implementation is very critical; much better than [id=59]
---
id=59
title=An Algorithm for Subgraph Isomorphism
author=J. R. Ullmann
journal=Journal of the Association for Computing Machinery(JACM, CCF A Journal)
year=1976
tags=graph, graph isomorphism, directed graph isomorphism, digraph isomorphism, subgraph, subgraph isomorphism, clique, clique detection, isomorphism algorithm, tree search, search tree, game tree, parallel processing, array processing, special purpose computer, logic-in-memory arrays, asynchronous sequential circuits, Boolean matrices
star=*****
problem=
interest=
hardness=
idea=
future=
comment=based on Linear Algebra
other=
---
id=60
title=Taming verification hardness: an efficient algorithm for testing subgraph isomorphism(QuickSI)
author=
journal=VLDB
year=2008
tags=QuickSI
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=61
title= The transitive reduction of a directed graph
author=
journal=SIAM
year=1972
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=62
title=Efficient Subgraph Matching by Postponing Cartesian Products(CFL-Match)
author=Fei Bi, Lijun Chang, Xuemin Lin, Lu Qin, Wenjie Zhang
journal=SIGMOD
year=2016
tags=subgraph matching, subgraph isomorphism;core-forest;CFL-Match;CPI-index;core-forest-leaf decomposition
star=****
problem=unpromising results by Cartesian products from dissimilar vertices
interest=
hardness=
idea=core-forest-leaf decomposition, CPI index to prepare candidates for joining phase, matching order based on path with the minimum growing cost
future=k-core decomposition, extend to directed graphs with edge labels, consider parallel and distributed
comment=
other=
---
id=63
title=Comparing performance of graph matching algorithms on huge graphs
author=Vincenzo Carletti
journal=Pattern Recognition Letters (PRL, CCF C Conference of AI)
year=2018
tags=subgraph isomorphism;subgraph matching,pattern recognition
star=***
problem=
interest=
hardness=
idea=compare vf2, vf3, RI(these three are tree-based), LAD and PathLAD(these two are constraint programming) on all kinds of graphs
future=
comment=no one beats others totally; vf3 is generally better, and better tradeoff between time and memory cost;vf2 is best at small graphs; vf3 is the disputed winner for finding the first solution; vf3 and RI confirmed to be a step forward with respect to the other algorithms for finding all solutions; it is advisable to use vf3 for most subgraph isomorphism problems
other=associated with ICPR contest; the experimental result in vf3
---
id=64
title=Computers and Intractability: A Guide to the Theory of NP-Completeness
author=M. R. Garey , David S. Johnson
journal=W. H. Freeman
year=1979
tags=NP-hard,NPC,NP-completeness,algorithm complexity,Intractability
star=*****
problem=
interest=
hardness=
idea=
future=
comment=notice that NPC is decision problems, but NP-hard is not
other=
---
id=65
title=Accelerating Large Graph Algorithms on the GPU Using CUDA
author=Pawan Harish
journal=HiPC (CCF C Conference of high performance Computing, also called HPC)
year=2007
tags=gpu,cuda,bfs,breadth-first search,sssp, apsp
star=**
problem=
interest=
hardness=
idea=
future=
comment=an early but basic implementation of these algorithms on GPU
other=
---
id=66
title=Fast Online Set Intersection for Network Processing on FPGA
author=Yun R. Qu, Viktor K. Prasanna
journal=TPDS(CCF A)
year=2016
tags=set intersection,network processing, field-programmable gate array(FPGA)
star=****
problem=For real-time network processing, the major challenge of set intersection is the strict performance requirement. Sets have to be intersected at very high throughput to sustain line-rate processing
interest=very common  and useful operator
hardness=all the elements of the sets are presorted but only known during run-time
idea=divide a set into multiple groups, compare groups of difdferent sets using LA algorithm(merge-join) and use bitwise-and for elements in the same group ID(BA algorithm); tree-based parallel architecture; only encode at the begining and decode at last
future=
comment=assume the lists are all sorted in the same order; able to deal with many sets
other=
---
id=67
title=Worst-case Optimal Join Algorithms
author=Hung Q. Ngo, Ely Porat
journal=PODS(CCF B, but the highest conference in database theory)
year=2012
tags=join Algorithm analysis, theoretical bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=68
title=Skew Strikes Back: New Developments in the Theory of Join Algorithms 
author=Hung Q. Ngo
journal=SIGMOD
year=2013
tags=join Algorithm analysis, skew data, theoretical bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=a graph with N edges has power(N, 3/2) distinct triangles
---
id=69
title=Leapfrog Triejoin: A Simple, Worst-Case Optimal Join Algorithm
author=Todd L. Veldhuizen
journal=Computer Science(arXiv preprint)
year=2012
tags=Algorithms, Theory, worst-case optimal join
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other= We show that NPRR is not worst-case optimal for such classes, giving a counterexample where leapfrog triejoin runs in O(nlogn) tiem and NPPR runs in theta(power(n, 1.375)) time
---
id=70
title=Join processing for graph patterns: An old dog with new tricks
author=Dung Nguyen
journal=Proceedings of the GRADES
year=2015
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=71
title=A Worst-Case Optimal Multi-Round Algorithm for Parallel Computation of Conjunctive Queries
author=Bas Ketsman, Dan Suciu
journal=PODS
year=2017
tags=parallelism, Conjunctive queries, multi-round, Worst-Case Optimal
star=****
problem=study the optimal communication cost for computing a full conjunctive query Q over p distributed servers
interest=
hardness=
idea=
future=
comment=
other=
---
id=72
title=Graph pattern matching: from intractable to polynomial time
author=Wenfei Fan
journal=VLDB
year=2010
tags=graph simulation
star=****
problem=define the graph simulation problem instead of graph matching
interest=
hardness=
idea=
future=
comment=
other=
---
id=73
title=Distributed exact subgraph matching in small diameter dynamic graphs
author=Charith Wickramaarachchi 
journal=Big Data
year=2016
tags=distributed subgraph matching, small diameter, dynamic graph
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=74
title=Bloom Filters, Adaptivity, and the Dictionary Problem
author=Michael A. Bender
journal=IEEE Symposium on Foundations of Computer Science(FOCS, CCF A of computer science)
year=2018
tags=bloom filters, Adaptivity, Dictionary, algorithm and data structures
star=****
problem=the probability guarantee of an approximate membership query data structure(Bloom, quotient, cuckoo filter)
interest=
hardness=
idea=
future=
comment=
other=
---
id=75
title=A Faster Isomorphism Test for Graphs of Small Degree
author=
journal=FOCS
year=2018
tags=Isomorphism test, small degree graphs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=76
title=Nearly work-efficient parallel algorithm for digraph reachability
author=
journal=STOC
year=2018
tags=work-efficient parallel algorithm, digraph reachability, graph algorithms
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=77
title=The query complexity of graph isomorphism: bypassing distribution testing lower bounds
author=
journal=STOC
year=2018
tags=graph isomorphism, query complexity, lower bounds
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=78
title=Round Compression for Parallel Matching Algorithms
author=
journal=ACM Symposium on Theory of Computing(STOC, CCF A of computer science)
year=2018
tags=round Compression, parallel matching Algorithms
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=79
title=Parallel Graph Connectivity in Log Diameter Rounds
author=
journal=FOCS
year=2018
tags=parallel Algorithms, graph Algorithms, graph Connectivity, log diameter
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=80
title=An exponential lower bound for Individualization-Refinement algorithms for Graph Isomorphism
author=
journal=STOC
year=2018
tags=graph Isomorphism, Individualization-Refinement algorithms, exponential lower bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=81
title=SIMD- and Cache-Friendly Algorithm for Sorting an Array of Structures
author=Hiroshi Inoue, Kenjiro Taura
journal=VLDB
year=2015
tags=SIMD, Cache, multiway sorting, vectorized algorithm
star=****
problem=sorting an array of structures by efficiently exploiting the SIMD instructions and cache memory
interest=sorting is common in database and the power of simd and cache is common and widely used now;exist SIMD libraries focus on sorting integers
hardness=if packing key and index(64 bit), then the cache miss of random access in the final rearrangement is severe; if sorting the whole structure directly, then keys need to be read veery time and the movement of all structures is costly
idea=based on multiway mergesort, does the key encoding and record rearranging for each multiway merge stage, while the key-index approach does the encoding only at the beginning of the entire sorting operation and record rearrangement at the end
future=
comment=
other=
---
id=82
title=Finding, Counting and Listing all Triangles in Large Graphs, An Experimental Study
author=Thomas Schank, Dorothea Wagner
journal=International Workshop on Experimental & Efficient Algorithms
year=2001
tags=Triangle Counting, Triangle Listing, Complexity Analysis
star=****
problem=the complexity and efficiency of algorithms of counting and listing triangles in large graphs
interest=very common and useful
hardness=
idea=a clique of vertex num n has almost n*n*n triangles; a graph of edge num n has O(m^1.5) triangles
future=
comment=
other=
---
id=83
title=FPGA acceleration of semantic tree reasoning algorithms
author=
journal=Journal of Systems Architecture
year=
tags=FPGA acceleration Algorithms, semantic tree
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=84
title=TRIÈST: Counting Local and Global Triangles in Fully-Dynamic Streams with Fixed Memory Size
author=
journal=SIGKDD
year=2016
tags=Triangle counting, dynamic stream
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=85
title=High Performance Exact Triangle Counting on GPUs
author=Mauro Bisson
journal=TPDS
year=2017
tags=Triangle counting, Graph processing, GPU Computing, Parallel computing, Big Data, CUDA
star=****
problem=
interest=
hardness=
idea=based on node and CSR structure, matrix multiplication
future=
comment=
other=general triangle counting based on edge has complexity as O(|E|^1.5); naive methods will have 6 duplicates, but there are perfect strategy to eliminate all duplicates which just need a order definition and only save edges satisfying this order; use order of degree(only save edges from high degree to low degree) yield wonderful performance because high degree nodes are evenly divided and result in natural load balance
---
id=86
title=Space/Time Trade-offs in Hash Coding with Allowable Errors (Bloom Filter)
author=Burton H. Bloom
journal=Communications of the ACM
year=1970
tags=hash coding, hash addressing, scatter storage, searching, storage layout, retrieval trade-offs, retrieval efficiency, storage efficiency, bloom filter
star=*****
problem=reduce the hash area size(m) when allowing a small error(false positive) targeting at judging if an element is in a given set(size is n)
interest=it is a very common primitive to judge many times if an element is in a set(the total elements are much larger than this set)
hardness=how to keep a tradeoff between hash area and reject time, how to provide a theorectical guarantee on the falso positive error
idea=two methods that are different from the conventional error-free hash; use multiple hash functions to reduce the errors while keeping a small hash array
future=how to distinguish elements with high frequency and low frequency
comment=the first wonderful work to come up with the idea of bloom filter; it is very suitable for many judgements on a not-so-large set and many judgements are invalid(then needless to access the high-latency memory); it is widely used in GPU, FPGA and CPU cache; to yield an ideal performance, the size of hash array is required to be two times larger than the size of set
other=if use a single hash function to reduce the conflict rate to 0.01, we need to use a hash array whose size is 100 times of the number of elements; http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html ; 哈希函数的选择对性能的影响应该是很大的，一个好的哈希函数要能近似等概率的将字符串映射到各个Bit。选择k个不同的哈希函数比较麻烦，一种简单的方法是选择一个哈希函数，然后送入k个不同的参数; 对于给定的m、n，当 k = ln(2)* m/n 时出错的概率是最小的; https://blog.csdn.net/jiaomeng/article/details/1495500
---
id=87
title=HeavyKeeper: An Accurate Algorithm for Finding Top-k Elephant Flows
author=Junzhi Gong, Tong Yang
journal=USENIX Annual Technical Conference
year=2018
tags=data stream, top-k, data flow, network traffic, frequency
star=****
problem=
interest=
hardness=
idea=we adopt a new strategy, called count-with-exponential-decay, to achieve space-accuracy balance by actively removing small flows through decaying, while minimizing the impact on large flows, so as to achieve high precision in finding top-k elephant flows. Moreover, the proposed algorithm called HeavyKeeper incurs small, constant processing overhead per packet and thus supports high line rates
future=
comment=
other=
---
id=88
title=Optimizing N-Dimensional, Winograd-Based Convolution for Manycore CPUs
author=Zhen Jia
journal=PPoPP
year=2018
tags=N-dimensional, winograd, Convolution, manycore CPUs, high-performance computing, machine learning
star=****
problem=existing implementations are limited to 2D data and a single kernel size of 3 by 3.
interest=
hardness=
idea=
future=
comment=
other=winograd http://shuokay.com/2018/02/21/winograd/ ;
---
id=89
title=SuperNeurons: Dynamic GPU Memory Management for Training Deep Neural Networks
author=Linnan Wang, Jinmian He
journal=PPoPP
year=2018
tags=GPU, Neural network, Deep Learning(DL), dynamic GPU memory management, SuperNeurons, machine learning
star=****
problem=
interest=deeper and wider neural network can provide higher accuracy; free DL(Deep Learning) practitioners from adjusting bottom GPU architecture
hardness=mmeory capacity, long training time
idea=a dynamic GPU memory scheduling runtime to enable the network training far beyond the GPU DRAM capacity. SuperNeurons features 3 memory optimizations, Liveness Analysis, Unified Tensor Pool, and Cost-Aware Recomputation; together they effectively reduce the network-wide peak memory usage down to the maximal memory usage among layers. We also address the performance issues in these memory-saving techniques
future=
comment=
other=
---
id=90
title=Transparent GPU Memory Management for DNNs
author=Jungho Park
journal=PPoPP(demo)
year=2018
tags=GPU memory management, DNN, machine learning
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=91
title=Bridging the Gap between Deep Learning and Sparse Matrix Format Selection
author=Yue Zhao
journal=PPoPP
year=2018
tags=Deep Learning, Sparse Matrix Format Selection, Sparse Matrix Vector multiplication(SpMV), Machine Learning
star=****
problem=determining the best storage format for a matrix to maximize the performance of Sparse Matrix Vector Multiplication (SpMV). It describes how to effectively bridge the gap between deep learning and the special needs of the pillar HPC problem through a set of techniques on matrix representations, deep learning structure, and cross-architecture model migrations
interest=
hardness=
idea=
future=
comment=
other=
---
id=92
title=FlashR: Parallelize and Scale R for Machine Learning using SSDs
author=Da Zheng
journal=PPoPP
year=2018
tags=parallel algorithm, R language, Solid-state drives(SSD), Machine Learning
star=****
problem=R is one of the most popular programming languages for statistics and machine learning, but it is slow and unable to scale to large datasets.
interest=
hardness=
idea=FlashR accelerates and scales existing R code by parallelizing a large number of matrix functions in the R base package and scaling them beyond memory capacity with solid-state drives (SSDs). FlashR performs memory hierarchy aware execution to speed up parallelized R code by (i) evaluating matrix operations lazily, (ii) performing all operations in a DAG in a single execution and with only one pass over data to increase the ratio of computation to I/O, (iii) performing two levels of matrix partitioning and reordering computation on matrix partitions to reduce data movement in the memory hierarchy
future=
comment=
other=best paper candidate
---
id=93
title=Featherlight On-the-fly False-sharing Detection
author=Milind Chabbi
journal=PPoPP
year=2018
tags=False-sharing Detection, shared-memory parallism, CPU cacheline, performance monitoring units(PMU), debug registers
star=****
problem=Shared-memory parallel programs routinely suffer from false sharing—a performance degradation caused by different threads accessing different variables that reside on the same CPU cacheline and at least one variable is modified
interest=State-of-the-art tools detect false sharing via a heavyweight process of logging memory accesses and feeding the ensuing access traces to an offline cache simulator
hardness=
idea=achieves low overhead by exploiting two hardware features ubiquitous in commodity CPUs: the performance monitoring units (PMU) and debug registers. Additionally, Feather is a first-of-its-kind tool to detect false sharing in multi-process applications
future=
comment=
other=best paper candidate
---
id=94
title=Cache-Tries: Concurrent Lock-Free Hash Tries with Constant-Time Operations
author=Aleksandar Prokopec
journal=PPoPP
year=2018
tags=parallel algorithm, data structure, trie, lock-free, concurrent, hash, constant-time, cache-friendly
star=****
problem=operations on most existing concurrent hash tries run in O(logn) time
interest=
hardness=
idea=
future=
comment=
other=best paper candidate
---
id=95
title=Register Optimizations for Stencils on GPUs
author=Prashant Singh Rawat
journal=PPoPP
year=2018
tags=Compiler Optimization, register Optimization, register pressure, optimal schedule, heuristic algorithm, Stencils, GPU, Loop Unroll, CUDA, ILP(Instruction-level parallelism)
star=*****
problem=register pressure in complex high order Stencils(compute-intensive and much data sharing)
interest=卷积/模板运算非常普遍（偏微分方程，数学物理，计算化学，图像处理，信号处理，神经网络等），且卷积的结构和大小对 算法的精度有很大的影响。卷积运算中存在大量的数据共享，通常的做法是loop unroll 或者shared memory
hardness=logical induction and mathematical analysis, as well as the difficulity of using GPU
idea=在保证spill-free 的前提下，降低MAXLIVE 时间，即同一时刻寄存器最大使用量。这可以通过最大化各执行树之间的共享，并改善调度算法来实现; develop a statement reordering framework that models stencil computations as a DAG of trees with shared leaves, and adapts an optimal scheduling algorithm for minimizing register usage for expression trees(计算最优调度的复杂度太高，实际上是用启发式 算法来找一个较优的调度)
future=maybe apply the optimizations to more primitives
comment=a solid work that targets at the optimization of a specific primitive which is widely used
other=best paper candidate; nvcc is not opensourced and gpucc is just a front-end which also uses nvcc as backend, LLVM(low level virtue machine) is opensourced; the compiler optimization is more important and widely than code optimization, but more difficult; the prons and cons of kernel fusion and kernel fission; pattern-specific optimization techniques have demonstrably been more beneficial, as well as algorithms, protocols, chips, systems and so on
---
id=96
title=Practical Concurrent Traversals in Search Trees
author=
journal=PPoPP
year=2018
tags=Concurrent Traversal, search tree, optimistic concurrency-control scheme, validation
star=****
problem=Operations of concurrent objects often employ optimistic concurrency-control schemes that consist of a traversal followed by a validation step. The validation checks if concurrent mutations interfered with the traversal to determine if the operation should proceed or restart. A fundamental challenge is to discover a necessary and sufficient validation check that has to be performed to guarantee correctness.
interest=
hardness=
idea=a necessary and sufficient condition for validating traversals in search trees. The condition relies on a new concept of succinct path snapshots, which are derived from and embedded in the structure of the tree; a general lock-free membership test suitable for any search tree
future=
comment=
other=
---
id=97
title=LazyGraph: Lazy Data Coherency for Replicas in Distributed Graph-Parallel Computation
author=Lei Wang
journal=PPoPP
year=2018
tags=Lazy Data Coherency, Distributed Graph-parallel Computation, Execution Model, node replicas
star=****
problem=any changes to vertex data must be immediately communicated to all replicas of v, leading to frequent global synchronization and communications.
interest=
hardness=
idea=
future=
comment=
other=
---
id=98
title=PAM: Parallel Augmented Maps
author=Yihan Sun
journal=PPoPP
year=2018
tags=parallel algorithm, data structure, ordered map
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=99
title=Griffin: Uniting CPU and GPU in Information Retrieval Systems for Intra-Query Parallelism
author=Yang Liu
journal=PPoPP
year=2018
tags=
star=****
problem=previous work runs queries either on GPU or CPU, ignoring the fact that the best processor for a given query depends on the query’s characteristics, which may change as the processing proceeds.
interest=
hardness=
idea=dynamically combines GPU- and CPU-based algorithms to process individual queries according to their characteristics; leveraging a new compression scheme and exploiting an advanced merge-based intersection algorithm
future=
comment=
other=
---
id=100
title=Juggler: A Dependence-Aware Task-Based Execution Framework for GPUs
author=
journal=PPoPP
year=2018
tags=GP-GPU programming, task-based execution, data dependence, OpenMP 4.5
star=****
problem=the existence of data dependences across thread blocks may significantly impact the speedup by requiring global synchronization across multiprocessors (SMs) inside the GPU
interest=
hardness=
idea=a task-based execution scheme for GPU workloads with data dependences. The Juggler framework takes applications embedding OpenMP 4.5 tasks as input and executes them on the GPU via an efficient in-device runtime, hence eliminating the need for kernel-wide global synchronization
future=
comment=
other=
---
id=101
title=Interval-Based Memory Reclamation
author=Haosen Wen
journal=PPoPP
year=2018
tags=memory reclamation, concurrent data structures, safe reclamation, disconnected memory blocks
star=****
problem=a thread, before freeing a block, must ensure that no other threads are accessing that block; the required synchronization tends to be expensive.
interest=
hardness=In contrast with epoch-based reclamation, in which threads reserve all blocks created after a certain time, or pointerbased reclamation (e.g., hazard pointers), in which threads reserve individual blocks
idea=By comparing a thread’s reserved interval with the lifetime of a detached but not yet reclaimed block, the system can determine if the block is safe to free. Like hazard pointers, IBR avoids the possibility that a single stalled thread may reserve an unbounded number of blocks; unlike hazard pointers, it avoids a memory fence on most pointer-following operations.  It also avoids the need to explicitly “unreserve” a no-longer-needed pointer.
future=
comment=
other=
---
id=102
title=Efficient Parallel Lists Intersection and Index Compression Algorithms using Graphics Processing Units
author=Naiyong Ao, Fan Zhang, Di Wu
journal=VLDB
year=2011
tags=parallel Algorithm, list Intersection, index Compression, GPU, linear regression, machine learning, binary search
star=****
problem=
interest=
hardness=
idea=linear regression(x is the list index, y is the elements) and hash segmentation(hash into buckets, then in bucket do normal binary search) to speed up list intersection by contracting the search range; for index compression, propose a Linear Regression Compression schema which has an inherent parallel structure
future=
comment=
other=in web search a sentence is divided into several keywords and each keyword returns a sorted list of document IDs, the final job is to intersect these lists; d-gap compression: in the list of document IDs, if using variable byte encoding, then using the difference between two IDs instead of the IDs themselves is better
---
id=103
title=Improving Medium-Grain Partitioning for Scalable Sparse Tensor Decomposition
author=Seher Acer
journal=TPDS
year=2018
tags=tensor decomposition, CPD-ALS, CartHP, distributed-memory-parallel algorithm, sparse tensor, canonical polyadic decomposition, cartesian partitioning, load balancing, communication volume, hypergraph partitioning
star=****
problem=CPD-ALS does not utilize the sparsity pattern of the tensor to reduce the total communication volume
interest=tensor decomposition is widely used and High computational and memory costs of CPD-ALS necessitate the use of a distributed-memory-parallel algorithm for efficiency
hardness=
idea=
future=
comment=
other=
---
id=104
title=Developing User Perceived Value Based Pricing Models for Cloud Markets
author=Peijin Cong, Liying Li
journal=TPDS
year=2018
tags=Cloud computing, Dynamic Pricing Model, User Perceived Value, Profit Maximization, Augmented Lagrange Function
star=****
problem=existing pricing models rarely consider the dynamic interactions between user requests and the cloud service provider
interest=With the rapid deployment of cloud computing infrastructures, understanding the economics of cloud computing has become a pressing issue for cloud service providers
hardness=
idea=a dynamic pricing model based on the concept of user perceived value that accurately captures the real supply and demand relationship in the cloud service market. Subsequently, a profit maximization scheme is designed based on the dynamic pricing model that optimizes profit of the cloud service provider without violating service-level agreement. Finally, a dynamic closed loop control scheme is developed to adjust the cloud service price and multiserver configurations according to the dynamics of the cloud computing environment such as fluctuating electricity and rental fees
future=
comment=
other=
---
id=105
title=Competitiveness of a Non-Linear Block-Space GPU Thread Map for Simplex Domains
author=Matthieu Vernier
journal=TPDS
year=2018
tags=GPU thread mapping, block-space, simplex domains, GPU optimization
star=****
problem=unnecessary threads assign in a special problem domain; for example, only the lower triangle of a matrix is really used or symmetric
interest=
hardness=
idea=
future=
comment=
other=
---
id=106
title=Analysis and Design Techniques towards High-Performance and Energy-Efficient Dense Linear Solvers on GPUs
author=Ahmad Abdelfattah
journal=TPDS
year=2018
tags=Dense linear solvers, GPU computing, energy efficiency, matrix factorization, Algorithm
star=****
problem=existing hybrid CPU-GPU strategies have probolems of less efficiency and high energy consuming
interest=Graphics Processing Units (GPUs) are widely used in accelerating dense linear solvers. The matrix factorizations, which dominate the runtime for these solvers, are often designed using a hybrid scheme, where GPUs perform trailing matrix updates, while the CPUs perform the panel factorizations
hardness=
idea=This paper presents analysis and design techniques that overcome the shortcomings of the hybrid algorithms, and allow the design of high-performance and energy-efficient dense LU and Cholesky factorizations that use GPUs only.
future=
comment=
other=CuSOLVER by Nvidia is the existing algorithm that only uses GPU
---
id=107
title=Eunomia: Scaling Concurrent Search Trees under Contention Using HTM
author=Xin Wang
journal=TPDS
year=2018
tags=Hardware Transactional Memory(HTM), Concurrent Search Tree, Opportunistic Consistency, Concurrency Control
star=****
problem=with the assistance of HTM, can we construct a concurrent search tree structure that delivers high and scalable performance even under high contention
interest=hardware transactional memory (HTM) has recently been adopted to construct efficient concurrent search tree structures, such designs fail to deliver scalable performance under contention
hardness=
idea=First, based on the observation that most HTM conflicts happen in the leaf layer, we partition a monolithic HTM region into multiple parts and protect the atomicity of different parts using HTM respectively.  A version-based scheme is utilized to guarantee overall consistency at the boundary of different HTM regions. With this scheme, most conflicts only cause retry within the partitioned transaction pieces, instead of the entire monolithic transaction. Second, to eliminate false conflicts incurred by consecutive data layout and metadata accesses, Eunomia refactors the tree structure in a partitioned way, which dispatches concurrent requests to different segments. Third, to throttle the true conflicting requests, Eunomia adopts an efficient mechanism, which anticipates potential conflicts and avoids them accordingly. Finally, Eunomia adopts an adaptive contention control mechanism, which can detect various contention rates and achieve high performance under both high and low contention.
future=
comment=
other=https://en.wikipedia.org/wiki/Transactional_memory
---
id=108
title=Confluence: Speeding Up Iterative Distributed Operations by Key-Dependency-Aware Partitioning
author=Feng Liang
journal=TPDS
year=2018
tags=Spark, shuffle, key dependency, iterative distributed operation, partitioning, Map Reduce, Algorithm
star=****
problem=A typical shuffle operation randomly partitions data on many computers, generating possibly a significant amount of network traffic which often dominates a job’s completion time
interest=This traffic is particularly pronounced in iterative distributed operations where each iteration invokes a shuffle operation(like MapReduce)
hardness=
idea=If data generated by the current iteration are partitioned to the computers where they will be processed in the next iteration, unnecessary shuffle network traffic between the two iterations can be prevented
future=
comment=
other=there is a figure of MapReduce in this figure which explains the idea clearly
---
id=109
title=Organization and maintenance of large ordered indexes
author=Bayer, Rudolf and McCreight, Edward
journal=Software pioneers
year=2002
tags=B+ tree, large ordered indices, Bplus tree, the evolution of B-tree, Data structure
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=110
title=Argobots: A Lightweight Low-Level Threading and Tasking Framework
author=Sangmin Seo
journal=TPDS
year=2018
tags=Argobots, user-level thread, tasklet, OpenMP, MPI, I/O, interoperability, lightweight, context switch, stackable scheduler, concurrency, Framework
star=****
problem=Current state-of-the-art user-level threading and tasking models, however, either are too specific to applications or architectures or are not as powerful or flexible
interest=a number of user-level threading and taskingmodels have been proposed in the literature to address the shortcomings of OS-level threads, primarily with respect to cost and flexibility
hardness=
idea=Argobots offers a carefully designed execution model that balances generality of functionalitywith providing a rich set of controls to allow specialization by end users or high-level programmingmodels; We describe the design, implementation, and performance characterization of Argobots and present integrations with three high-levelmodels: OpenMP,MPI, and colocated I/O services
future=
comment=experiment and evaluation are the main parts of this paper
other=
---
id=111
title=An Auto-Tuner for OpenCL Work-Group Size on GPUs
author=Thanh Tuan Dao
journal=TPDS
year=2018
tags=GPU, auto-tuning, workload characterization, workgroup size, OpenCL, NVIDIA, AMD
star=****
problem=Tuning the kernel work-group size for GPUs is a challenging problem
interest=the most influential performance factors with regard to the work-group size include occupancy, coalesced global memory accesses, cache contention, and variation in the amount of workload in the kernel
hardness=
idea=using the performance counters provided by GPUs, we characterize a large body of OpenCL kernels to identify the performance factors that affect the choice of a good work-group size
future=maybe use Machine Learning for tuning parameters
comment=We show the effectiveness of our auto-tuner by evaluating it with a set of 54 OpenCL kernels on three different NVIDIA GPUs and one AMD GPU; find sub-optimal work-group size within a small time interval and the performance is very closed to the optimal one
other=nvidia cuda now also supports varied work group size
---
id=112
title=Easy PRAM-Based High-Performance Parallel Programming with ICE
author=Fady Ghanim
journal=TPDS
year=2018
tags=ICE, ease of programming, irregular programs, PRAM(parallel random-access machine/model), fine-grained parallelism, XMT, nested ICE, nested parallelism
star=****
problem= Unfortunately parallel programming technologies have advanced at a much slower pace except for regular programs
interest=Parallel machines have become more widely used.
hardness=For irregular programs, this advancement is inhibited by high synchronization costs, non-loop parallelism, non-array data structures, recursively expressed parallelism and parallelism that is too fine-grained to be exploitable.
idea=easy-to-program, since: (i) ICE is a synchronous, lock-step language so there is no need for programmer-specified synchronization; (ii) for a PRAM algorithm its ICE program amounts to directly transcribing it; and (iii) the PRAM algorithmic theory offers unique wealth of parallel algorithms and techniques
future=
comment=
other=
---
id=113
title=AIRA: A Framework for Flexible Compute Kernel Execution in Heterogeneous Platforms
author=Robert Lyerly
journal=TPDS
year=2018
tags=Heterogeneous architectures, compilers, runtimes, programming models, architecture selection, CPU-GPU
star=****
problem=
interest=Heterogeneous-ISA computing platforms have become ubiquitous, and will be used for diverse workloads which render static mappings of computation to processors inadequate
hardness=
idea=Dynamic mappings which adjust an application’s usage in consideration of platform workload can reduce application latency and increase throughput for heterogeneous platforms
future=
comment=
other=
---
id=114
title=MSGD: A Novel Matrix Factorization Approach for Large-scale Collaborative Filtering Recommender Systems on GPUs
author=Hao Li, Kenli Li
journal=TPDS
year=2018
tags=Collaborative filtering (CF), CUDA parallelization algorithm, Matrix factorization (MF), Multi-GPU implementation, Stochastic gradient descent (SGD).
star=****
problem=stochastic gradient descent (SGD) is one of the most famous approaches for MF. However, it is non-trivial to parallelize SGD for large-scale problems due to the dependence on the user and item pair, which can cause parallelization over-writing
interest=Real-time accurate recommendation of large-scale recommender systems is a challenging task. Matrix factorization (MF), as one of the most accurate and scalable techniques to predict missing ratings, has become popular in the collaborative filtering (CF) community
hardness=To remove the dependence on the user and item pair, we propose a multi-stream SGD (MSGD) approach, for which the update process is theoretically convergent
idea=divides the task into coarse sub-tasks that are mapped to independent thread blocks, and then be solved by those independent thread blocks. Each sub-task is divided into finer pieces that map to threads within the thread block, then be solved cooperatively by those threads in parallel.
future=
comment=
other=
---
id=115
title=Neurostream: Scalable and Energy Efficient Deep Learning with Smart Memory Cubes
author=Erfan Azarkhish
journal=TPDS
year=2018
tags=Hybrid memory cube, convolutional neural networks, large-scale deep learning, streaming floating-point
star=****
problem=
interest=High-performance computing systems aremoving towards 2.5D and 3Dmemory hierarchies, based onHigh Bandwidth Memory (HBM) and HybridMemory Cube (HMC) tomitigate themainmemory bottlenecks
hardness=
idea=Our co-design approach consists of a network ofSmart Memory Cubes (modular extensions to the standard HMC) each augmented with a many-core PIMplatformcalled NeuroCluster. NeuroClusters have amodular design based onNeuroStreamcoprocessors (forConvolutionintensive computations) and general-purpose RISC-V cores
future=
comment=a flexible processor-in-memory (PIM) solution for scalable and energy-efficient execution of deep convolutional networks (ConvNets), one of the fastest-growing workloads for servers and high-end embedded systems.
other=brain-inspired computing (BIC), near-memory computation
---
id=116
title=Toward High Mobile GPU Performance Through Collaborative Workload Offloading
author=Chao Wu
journal=TPDS
year=2018
tags=Mobile applications, distributed system, code offload, performance optimization, collaborative workload offloading
star=****
problem=the challenge of poor hardware support but fine-grained rendering details often makes user unsatisfied especially in calling for high frame rate scenarios, e.g., game
interest=The ever increasing of display resolution on mobile devices raises high demand for GPU rendering details
hardness=
idea=ButterFly, a novel system which collaboratively utilizes mobile GPUs to process high-quality rendering details for on-the-go mobile users
future=
comment=utilize mobile GPUs in the same wifi to provide better display
other=
---
id=117
title=Fast K-selection Algorithms for Graphics Processing Units
author=TOLU ALABI
journal=ACM Journal of Experimental Algorithmics
year=2012
tags=Algorithms, Design, Experimentation, Performance, Top-K, K-selection, Order Statistics, Multi-core, Graphics Processing Units, GPGPU, CUDA, radixSelect, bucketSelect, concurrent programming, parallel programming
star=****
problem=Finding the kth largest value in a list of n values
interest=
hardness=sort maybe done extra work
idea=sort&choose, radixSelect, bucketSelect
future=
comment=in sequential algorithm the k-selection problem has solutions running in O(n) time
other=https://github.com/yuxianzhi/Top-K; https://devtalk.nvidia.com/default/topic/814439/cuda-programming-and-performance/top-k-elements-selection-/
---
id=118
title=gem5-gpu: A Heterogeneous CPU-GPU Simulator
author=Jason Power
journal=Computer Architecture Letters
year=2015
tags=Modeling techniques, Simulators, Heterogeneous (hybrid) systems, General-purpose graphics processors, GPU
star=***
problem=gem5-gpu is a new simulator that models tightly integrated CPU-GPU systems
interest=It builds on gem5, a modular fullsystem CPU simulator, and GPGPU-Sim, a detailed GPGPU simulator.
hardness=GPGPU-Sim is unable to model the interactions between CPU and GPU
idea=
future=
comment=
other=
---
id=119
title=Parallel Spectral Graph Partitioning
author=Maxim Naumov
journal=NVIDIA Technical Report
year=2016
tags=Spectral graph, multi-level Partition scheme
star=****
problem=
interest=the behavior of our spectral scheme and popular multi-level schemes is starkly different for two classes of problems: (i) social network graphs that often have power law-like distribution of edges per node and (ii) meshes arising from discretization of partial differential equations 
hardness=
idea=a novel parallel spectral partitioning method that takes advantage of an Exploringcient implementation of a preconditioned eigenvalue solver and a k-means algorithm on the GPU
future=in our numerical experiments the multi-level schemes are almost always faster, we show that our spectral scheme can achieve a significantly higher quality of partitioning for the social network graphs
comment=the usage of spectral graph theory in graph partition
other=
---
id=120
title=A conjugate gradient method for the spectral partitioning of graphs
author=
journal=Parallel Computing
year=1997
tags=共轭梯度法(Conjugate Gradient Method),spectral graph theory, spectral partitioning 
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=121
title=An Improved Spectral Graph Partitioning Algorithm for Mapping Parallel Computations
author=Bruce Hendrickson
journal=SIAM Journal on Scientific Computing
year=1992
tags=Spectral graph Partitioning, parallel computing
star=****
problem=Efficient use of a distributed memory parallel computer requires that the computational load be balanced across processors in a way that minimizes interprocessor communication.
interest=
hardness=
idea=Our generalization of spectral graph bisection involves a novel use of multiple eigenvectors to allow for division of a computation into four or eight parts at each stage of a recursive decomposition. The resulting method is suitable for scientific computations like irregular finite elements or differences performed on hypercube or mesh architecture machines.
future=
comment=
other=
---
id=122
title=A Hybrid B+-tree as Solution for In-Memory Indexing on CPU-GPU Heterogeneous Computing Platforms
author=Amirhesam Shahvarani
journal=SIGMOD
year=2016
tags=Heterogeneous Computing, Indexing, In-memory Database, B+-tree, CPU-GPU
star=****
problem=An in-memory indexing tree is a critical component of many databases
interest=Modern many-core processors, such as GPUs, are offering tremendous amounts of computing power making them an attractive choice for accelerating indexing
hardness=the memory available to the accelerating co-processor is rather limited and expensive in comparison to the memory available to the CPU. This drawback is a barrier to exploit the computing power of co-processors for arbitrarily large index trees.
idea=the joint and simultaneous use of computing and memory resources of CPU-GPU systems
future=
comment=good paper, very solid
other=
---
id=123
title=Algebraic connectivity of graphs
author=MIROSLAV FIEDLER
journal=Czechoslovak mathematical journal 
year=1972
tags=Algebraic connectivity, spectral graph theory
star=*****
problem=
interest=
hardness=
idea=
future=
comment=the basic idea of spectral graph theory
other=
---
id=124
title=Laplacian of Graphs and Algebraic Connectivity
author=MIROSLAV FIEDLER
journal=Banach Center Publications
year=1989
tags=Laplacian of Graphs, spectral graph theory, Algebraic Connectivity
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=125
title=Lower bounds for the Partitioning of Graphs
author=W. E. Donath
journal=
year=
tags=spectral Graph theory
star=*****
problem=lower bound of the crossing edges in graph Partitioning Problem
interest=
hardness=
idea=
future=
comment=
other=
---
id=126
title=THE CONJUGATE GRADIENT METHOD IN EXTREMAL PROBLEMS
author=B. T. POLYAK
journal=
year=1967
tags=共轭梯度法(Conjugate Gradient Method), EXTREMAL problems, mathematical method, iterational algorithm, linear algebra
star=*****
problem=
interest=
hardness=
idea=proves the convergence of the method as applied to non-quadratic functionals, describe its extension to constrained problems, considers means for further accelerating the convergence, and describes experience in the practical application of the method for solving a variety of extremal problems.
future=
comment=
other=
---
id=127
title=Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering
author=
journal=RecSys
year=2011
tags=共轭梯度法(Conjugate Gradient Method),collaborative filtering
star=****
problem=The need for solving weighted ridge regression (WRR) problems arises in a number of collaborative filtering (CF) algorithms.
interest=
hardness=Often, there is not enough time to calculate the exact solution of the WRR problem, or it is not required.  idea=The conjugate gradient (CG) method is a state-of-the-art approach for the approximate solution of WRR problems.  In this paper, we investigate some applications of the CG method for new and existing implicit feedback CF models.
future=
comment=
other=
---
id=128
title=Similarity-Aware Spectral Sparsification by Edge Filtering
author=Zhuo Feng
journal=DAC
year=2018
tags=Spectral graph theory, graph partitioning, iterative methods
star=***
problem=
interest=
hardness=
idea=a similarity-aware spectral graph sparsification framework that leverages Exploringcient spectral otree edge embedding and filtering schemes to construct spectral sparsifiers with guaranteed spectral similarity (relative condition number) level.
future=
comment=
other=
---
id=129
title=Accelerating graph isomorphism queries in a graph database using GPU
author=
journal=
year=
tags=graph mining, graph isomorphism, GPU, graph database
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=130
title=parallel graph mining with GPUs
author=
journal=
year=
tags=Parallel Frequent Graph Mining, Graphics Processing Unit(GPU), frequent pattern, graph database
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
