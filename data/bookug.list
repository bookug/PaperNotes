---
id=0
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=1
title=Lessons Learned from Exploring the Backtracking Paradigm on the GPU
author=    John Jenkins,Isha Arkatkar,John D. Owens,Alok Choudhary,Nagiza F. Samatova
journal= European Conference on Parallel and Distributed Computing(Euro-Par)
year=2011
tags=Shared Memory,Connectivity Query,Memory Operation,Frequent Itemset Mining,Candidate Path,backtrack,Maximal Clique Enumeration(MCE), k-d tree(KD-tree)
star=***
problem=how to parallelize backtracking paradigm
interest=backtracking paradigm(depth-first search) is common in graph algorithms
hardness=backtracking paradigm is hard to parallelize
idea=store candidate paths in stack instead of backtracking, warp-level parallelism on GPU, work stealing, output buffering, coarse-grain parallelization where multiple subtrees are explored in parallel, utilize both CPU and GPU
future=improve the load balance on GPU
comment=A deep consideration of backtracking paradigm and depth-first search for graph algorithms,inability to provide better performance of MCE than CPU,four lessons are remarkable
other=breadth-first search is easier to be parallelized compared to depth-first search, but it consumes too much memory;combination is an idea and dividing into many blocks is another
---
id=2
title= A Sparse Completely Positive Relaxation of the Modularity Maximization for Community Detection
author=Haoyang Liu
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=3
title=GPU acceleration of subgraph isomorphism search in large scale graph
author=Bo Yang, Kai Lu, Yinghui Gao, Xiaoping Wang, Kai Xu
journal=Journal of Central South University
year=2015
tags=subgraph isomorphism, backtrack paradigm, GPU, parallel
star=*
problem=how to apply TurboISO to GPU
interest=TurboISO is a fast CPU subgraph isomorphism algorithm, is it suitable for GPU?
hardness=TurboISO adopts backtrack paradigm which is hard to be parallelized
idea=parallelism in different candidate region, the independency property of the partial subtree embedding allows that the GPU region exploration algorithm can first divide the region exploration into expanding and backtracking of partial subtree embeddings and then conquer the partial subtree embedding and generate new ones in parallel
future=
comment=the key of this paper is to adopts some BFS expanding strategies in the DFS framework, the shortcoming is that lots of DFS operations still exist and will limit the overall performance; if dfs work is too little, then the size of candidates will be too large for GPUto run(memory and thread limits), if dfs work is too much, then the time cost of dfs is too high, though the size of candidates for BFS is reduced
other=backtrack paradigm is rarely used in parallel computing; much faster than vf2[id:58], but hard to implement
---
id=4
title=THE ENUMERATION OF MAXIMAL CLIQUES OF LARGE GRAPHS
author=E. A. Akkoyunlu
journal=SIAM J. Comput.
year=1973
tags=Graph Algorithm, Maximal Clique,Backtrack
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=the same idea as [id:5]
---
id=5
title=Finding All Cliques of an Undirected Graph
author=Coenraad Bron, Joep Kerbosch
journal=Commun. ACM
year=1973
tags=Graph Algorithm, Maximal Clique,Backtrack
star=****
problem=how to enumerate all maximal cliques in a graph
interest=widely used and its efficiency is very important in practice
hardness=A NP-hard problem
idea=use backtracking for search, with pruning strategies(pivot selection and vertex degeneracy ordering)
future=better pivot vertex selection, special optimization for special graphs
comment=classical and efficient work on maximal cliques enumeration,strict theoretical bound,work efficiently for many kinds of graphs including social network
other=different kinds of graphs have different kinds of optimizations; https://en.wikipedia.org/wiki/Bron%E2%80%93Kerbosch_algorithm#cite_note-1
---
id=6
title=Real-time KD-tree construction on graphics hardware
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=7
title=A Survey of General-Purpose Computation on Graphics Hardware
author=John D. Owens
journal=
year=2007
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=8
title=Efficient Gradient Boosted Decision Tree Training on GPUs
author=Zeyi Wen,Bingsheng He
journal=IEEE International Parallel and Distributed Processing Symposium(IPDPS)
year=2018
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=9
title=Gunrock: A High-Performance Graph Processing Library on the GPU
author=Yangzihao Wang , Andrew A. Davidson , Yuechao Pan , Yuduo Wu , Andy Riffel , John D. Owens
journal=Symposium on Principles and Practice of Parallel Programming(PPoPP)
year=2016
tags=GPU,Graph Algorithm,Graph Library,Graph Processing System,data-centric,bulk-synchronous,based on frontier,load balance, kernel fusion
star=*****
problem=
interest=
hardness=the irregularity of data access/control flow and the complexity of programming GPUs
idea=data-centric primitives(advance, filter, compute, intersection)
future=
comment=
other=
---
id=10
title= PowerGraph:DistributedGraph-ParallelComputationonNaturalGraphs
author=Joseph E. Gonzalez, Yucheng Low
journal=USENIX Symposium on Operating Systems Design and Implementation(OSDI)
year=2012
tags=Graph System
star=*****
problem=how to deal with natural graph(power-law distribution) in  distributed computing
interest=natural graph is widely encountered, the performance of distributed computing is very critical
hardness=high-degree nodes,heavy communication cost among machines
idea=divide partitions by vertex cut; GAS decomposition; delta caching, values of many vertices not change and no need to gather them
future=
comment=an efficient and promising work
other=
---
id=11
title=Hardware Acceleration in Commercial Databases: A Case Study of Spatial Operations
author=Nagender Bandi, Chengyu Sun
journal=VLDB
year=2004
tags=Hardware Acceleration,complex data types(spatial geometries, protein structures)
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=12
title=Shared Memory Parallel Subgraph Enumeration
author=Raphael Kimmig,Henning Meyerhenke,Darren Strash
journal=IEEE International Parallel and Distributed Processing Symposium(IPDPS) Workshops
year=2017
tags=subgraph enumeration, subgraph isomorphism,parallel combinatorial search,graph mining,network analysis,work-stealing
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=13
title=Efficient Subgraph Matching Using GPUs
author=Xiaojie Lin,Rui Zhang,Zeyi Wen
journal=Databases Theory and Applications - 25th Australasian Database Conference(ADC)
year=2014
tags=subgraph matching,GPU,relational join,comparison of several subgraph isomorphism algorithms
star=***
problem=the join process of STwigs are very time-consuming
interest=
hardness=
idea=use hash instead of binary search to join two relation tables of STwigs; indicate a constant time though with random access
future=
comment=
other=
---
id=14
title=Query Workload-based RDF Graph Fragmentation and Allocation
author=Peng Peng, Lei Zou, Lei Chen,Dongyan Zhao
journal= International Conference on Extending Database Technology (EDBT, CCF B in Database area)
year=2016
tags=RDF,Graph Fragmentation, query workload, Graph Partition,communication cost, distributed environment, crossing match
star=***
problem= reduce the number of crossing matches and the communication cost during SPARQL query processing in distributed environment
interest=distributed computing is common and the communication cost is the bottleneck
hardness=high-degree nodes, complex model of distributed computing
idea= mine and select some frequent access patterns to reflect the characteristics of the workload,  Vertical fragmentation is for better throughput and horizontal fragmentation is for lower latency
future=
comment=find out all instances of a frequent pattern as fragments,place all instances of a query in several machines to lower latency of the single query(enable parallism of this query), place all instances in one machine to improve throughput(enable parallism of multiple queries); allocate closely related fragments in one machine to lower the communication cost of dealing with decomposed query
other=An improved version is in [id:16]; based on edge cut, may not work well on high-degree nodes
---
id=15
title=Processing SPARQL queries over distributed RDF graphs
author=Peng Peng, Lei Zou, Tamer, Lei Chen,Dongyan Zhao
journal=VLDB Journal
year=2016
tags=distributed environment,RDF, SPARQL,partial evaluation and assembly, local partial match, centralized and distributed
star=****
problem=how to answer SPARQL queries in a distributed environment
interest=RDF datasets with billions of tripels are common now
hardness=how to combine the results in different machines,how to reduce the communication cost
idea=given an arbitary partition(partition-agnostic), partial evaluation and join the results;centralized assembly is simple but the cost of the master machine will be too high, distributed assembly is complex(BSP, bulk synchronous parallel) but efficient and load balanced
future=handling SPARQL queries over linked open data (LOD),  multiple SPARQL query optimization in the context of distributed RDF graphs
comment=in practice specific partition for a specific kind of dataset is more efficient, though not so flexible
other=
---
id=16
title=Adaptive Distributed RDF Graph Fragmentation and Allocation based on Query Workload
author=Peng Peng, Lei Zou, Lei Chen,Dongyan Zhao
journal=IEEE Transactions on Knowledge and Data Engineering(TKDE)
year=2018
tags=Distributed RDF Database, Data Fragmentation, Data Allocation, Query Workload
star=****
problem=
interest=
hardness=
idea=allocate these fragments to various sites while balancing the fragments;  vertical, horizontal and mixed fragmentation
future=
comment=
other=The original work is in [id:14], the enhancement is that a mixed fragmentation strategy is proposed
---
id=17
title=Collaborative (CPU + GPU) Algorithms for Triangle Counting and Truss Decomposition on the Minsky Architecture
author=Ketan Date,Keven Feng
journal=High Performance Extreme Computing Conference (HPEC)
year=2017
tags=CPU,GPU,Triangle Counting,Truss Decomposition
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=various memory management on GPU
---
id=18
title=Fast and Adaptive List Intersections on the GPU
author=James Fox, Oded Green, Kasimir Gabert
journal=HPEC(not in CCF list)
year=2018
tags=GPU,List Intersection
star=***
problem=for  many  graph  based problems  it  is  necessary  to  find  intersections  for  a  very  large number  of  lists—these  lists  tend  to  vary  greatly  in  size  and are   difficult   to   efficiently   load-balance
interest=List intersections are ubiquitous and can be found in   wide   range   of   applications,   including   triangle   counting and  finding  the  maximal k-truss,  both  of  which  are  part  of the  HPEC  Static  Graph  Challenge
hardness=load imbalance due to the irregular property of graph
idea=assigns  a  different  number  of  threads  for  different intersections  in  order  to  effectively  utilize  the  resources  of  the GPU; search-based and merge-based; estimate the cost and split into sublists
future=
comment=less abstarct, not so novel; no use about shared memory; how to set the size of bin and how many threads to use for this bin; load imbalance still exists in a bin
other=the original idea is in [id:57]
---
id=19
title=Static Graph Challenge: Subgraph Isomorphism
author=
journal=HPEC workshop
year=2018
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=just a competition instead of a paper, named GraphChallenge
other=https://graphchallenge.mit.edu/
---
id=20
title=Multilevel Parallelism for the Exploration of Large-Scale Graphs
author=Massimo Bernaschi, Mauro Bisson
journal=IEEE Trans. Multi-Scale Computing Systems
year=2018
tags=GPU cluster,BC(Betweeness Centrality), BFS(Breadth-first search),Large graphs, graph algorithms, parallel algorithms, parallel programming, distributed programming, CUDA
star=**
problem=
interest=
hardness=
idea=
future=improve the heuristic to switch between the top-down and the bottom-up variant and to evaluate the advantages that technologies likeGPUDirectAsynccanprovideforreducingthe overhead of the communication among GPUs; explore the chance of using our BFS as a building block for the solution of other graphs problems.
comment=
other=
---
id=21
title=Experimental Evaluation of GPU Solutions to the Single Source Shortest Path Problem(SSSP)
author=
journal=
year=2017
tags=GPU,CUDA,Shortest Path
star=***
problem=
interest=
hardness=
idea=compare dijkstra(strict limitation, lowest work complexity), bellman-ford(lose limitation, highest work complexity) and the mixed version(delta stepping, split into buckets); diffrent system like BGL(Boost Graph Library), PGBL(Parallel Boost Graph Library), Gunrock and LoneStarGPU
future=
comment=
other=https://www.boost.org/doc/libs/1_63_0/libs/graph_parallel/doc/html/index.html
---
id=22
title=HyperX: A Scalable Hypergraph Framework
author=Wenkai Jiang, Jianzhong Qi, Jeffery Xu Yu
journal=IEEE Transactions on Knowledge and Data Engineering(TKDE)
year=2018
tags=Hypergraph, HyperX, graph framework, graph partitioning, label propagation partitioning
star=****
problem=support hypergraph computing
interest=not regular and hard to represent, but do occur in real case; Hypergraphs are generalizations of graphs where the (hyper)edges can connect any number of vertices. They are powerful tools for representing complex and non-pairwise relationship
hardness=existing graph computation frameworks cannot accommodate hypergraphs without converting them into graphs, because they do not offer APIs that support (hyper)edges directly. This graph conversion may create excessive replicas and result in very large graphs, causing difficulties in workload balancing 
idea=design a new optimization objective aimed to minimize the number of replicas and to achieve the balanced partitions, propose a novel label propagation algorithm to achieve the optimization running in parallel with several heuristics
future=open source HyperX and use it for other hypergraph processing tasks such as building similarity based regularization classifier for recommender systems and studying biochemical interactions.
comment=
other=
---
id=23
title=Learning with hypergraphs: Clustering, classification, and embedding
author=Dengyong Zhou, Jiayuan Huang
journal=Annual Conference on Neural Information Processing Systems(NIPS)
year=2006
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=24
title=Accelerating Dynamic Graph Analytics on GPUs(GPMA)
author=Mo Sha, Yuchen Li, Bingsheng He
journal=Proceedings of the VLDB Endowment
year=2017
tags=Dynamic Graph Analytics,GPU, stream updates, Graph Stream, GPMA,CSR,B+ tree, PMA on GPU
star=****
problem=in many applications such as social networks, cyber security, and fraud detection, their representative graphs evolve frequently and one has to perform a rebuild of the graph structure on GPUs to incorporate the updates
interest=As graph analytics often involves compute-intensive operations, GPUs have been extensively used to accelerate the processing
hardness=rebuilding the graphs(like the traditional CSR structure) becomes the bottleneck of processing high-speed graph streams
idea=a GPU-based dynamic graph storage scheme to support existing graph algorithms easily. Furthermore, we propose parallel update algorithms to support Erikcient stream updates so that the maintained graph is immediately available for high-speed analytic processing on GPUs; the intuition is add holes to CSR, the holes can not be too large or too small ,just like the node of B-tree, split and coalesce on some specific cases; as for updates, some heuristic methods are used, in the input buffer insertions and deletions are separated, operations to the same node are separated(otherwise will cause lock), if we can decide that some insertions will cause the adjustion of substructure then we can reorganize this part first
future=
comment=novel ideas and practical; how to support tc and sm on such structures?; no framework or primitive that can support all graph algorithms on GPUs well
other=a technical report in detail can be acquired on arXiv; an implementation of PMA on GPU
---
id=25
title=Towards GPU-Based Common-Sense Reasoning: Using Fast Subgraph Matching
author=Ha-Nguyen Tran, Erik Cambria, Amir Hussain
journal=Cognitive Computation
year=2016
tags=Common-Sense Reasoning, GPU, Subgraph Matching, CUDA
star=***
problem=transform reasoning to subgraph Isomorphism on Knowledge graph
interest=leverage the power of GPU to do reasoning, and not from scratch but using the existing work of subgraph matching
hardness=subgraph matching is a NP-hard problem
idea=edge-based subgraph Isomorphism on GPU, multi-level graph compression(finding similar nodes in Knowledge graphs and combine into one hyper-node) to place large graph on GPU
future=
comment=
other=use subgraph Isomorphism algorithm like [id:12] in literature.list; the graph compression strategy is similar to [id:5] in yuqizhou.list
---
id=26
title=Efficient Semantic Search over Structured Web Data: A GPU Approach
author=Ha-Nguyen Tran
journal=Computational Linguistics and Intelligent Text Processing
year=2017
tags=GPU, Reasoning, RDF, SPARQL
star=**
problem=
interest=
hardness=
idea=backward chaining
future=
comment=
other=use subgraph Isomorphism algorithm like [id:12] in literature.list
---
id=27
title=privacy-preserving ranked neighbor query over encrypted graph data in the cloud
author=Hong Zhu, Bin Wu
journal=security and communication networks
year=2016
tags=encrypted graph, randked neighbor query, cloud computing, searchable encryption
star=**
problem=how to rank neighbors in a encrypted scene
interest=
hardness=in cloud encryption is used to protect the privacy of users, but this means ranking is very hard to do
idea=
future=
comment=
other=
---
id=28
title=An Efficient Algorithm for Subgraph Isomorphism using Dynamic Programming on Directed Acyclic Graphs
author=
journal=
year=2018
tags=
star=
problem=
interest=
hardness=
idea= dynamic programming on directed acyclic graphs, the adaptive matching order with DAG-ordering, pruning by failing sets
future=
comment=
other=
---
id=29
title=Accelerating graph isomorphism queries in a graph database using the GPU
author=
journal=
year=2016
tags=GPU, subgraph isomorphism, graph database
star=
problem=performing subgraph isomorphism in a graph database using GPU
interest=
hardness=
idea=
future=for graph database an index can be built to speed up the searching, which uses the features of the data graphs
comment=the subgraph isomorphism algorithm is GpSM in [id:12] in literature.list
other=the same paper with [id:129]
---
id=30
title=Challenging the Time Complexity of Exact Subgraph Isomorphism for Huge and Dense Graphs with VF3
author=Carletti V
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI, CCF A journal of Artificial Intelligence)
year=2018
tags=Graphs, graph matching, graph isomorphism, subgraph isomorphism, graphs dataset,vf3
star=****
problem=
interest=able to manage huge and dense graphs
hardness=traditional algorithms only deals with small and sparse graphs; hard to prune in dense graphs
idea=
future=
comment=
other=it seems there is a former version in 2017;   vf2 is also published on TPAMI, and vf3 is the evolution of VF2Plus, which is also an evolution of VF2[id:58]; TPAMI is a famous journal with Impact Factor higher than 9; another paper is Introducing VF3: A New Algorithm for Subgraph Isomorphism
---
id=31
title=A Distributed Multi-GPU System for Fast Graph Processing
author=Zhihao Jia, Yongkee Kwon
journal=PVLDB
year=2017
tags=multi-GPU clusters, graph processing, distributed computing
star=****
problem=speed up graph processing using GPU cluster
interest=to leverage power of multi-GPUs to beat distributed or shared-memory systems
hardness=work assignment and communication among GPUs
idea=Lux system exploiting locality and  the aggregate memory bandwidth on GPUs, dynamic graph repartitioning strategy that enables well-balanced workload distribution with minimal overhead, a model choosing the number of nodes and GPUs for the best possible performance
future=
comment=not so novel but a general framework
other=GPUs communicate via NVLink; Five algorithms are tested, PR(PageRank), CC(connected components), SSSP(single-source shortest path), BC(betweenness centrality), CF(collaborative filtering)
---
id=32
title=Work-Efficient Parallel GPU Methods for Single-Source Shortest Paths
author=Andrew A. Davidson, Sean Baxter, Michael Garland, John D. Owens
journal=IPDPS(CCF B of high performance computing)
year=2014
tags=GPU computing, graph traversal, single-source shortest paths(SSSP), sparse graphs
star=****
problem=how to implement SSSP on GPU
interest=SSSp is frequently encountered in real life
hardness=dijkstra's algorithm is hard to parallize, while the work complexity of bellman-ford is too high
idea=Workfront Sweep, Near-Far and Bucketing; to balance the tradeoff between saving work and organizational overhead
future=dynamic method that switches between Workfront Sweep and Near-Far(begin with a Workfront Sweep method until the vertex queue becomes large enough to saturate the GPU, Now that there is sufficient parallelism, we would switch to our Near-Far Pile technique where work efficiency is more important. Finally, after most of the graph has been explored, and we return to a lack of sufficient parallelism, we would switch back again to Workfront Sweep to finish off the problem, similar to [id:36]);  lack of available parallelism on road network (low-degree graphs), combine our work-saving method with a PHAST-like pre-processing step to identify more vertices from which to start our SSSP sweeps
comment=reduce the work complexity remarkably; works for low-degree and scale-free graphs both
other=
---
id=33
title=Δ-stepping: a parallelizable shortest path algorithm
author=U. Meyer, P. Sanders
journal= European Symposium on Algorithms(ESA, CCF B Conference of computer science theory)
year=1998
tags=parallel, delta stepping, shortest path(SSSP)
star=****
problem=
interest=
hardness=
idea=
future=
comment=successful for coarse-grained parallel CPus; difficult to implement efficiently on a GPU-like machine(by [id:32]):bucket implementation requires dynamic arrays that can be quickly resized in parallel. Dynamic arrays are poorly suited to the current programming model of GPUs, and implementing a custom memory management system for dynamic arrays (utilizing heaps) would be difficult and inefficient;  fine-grained renaming and moving vertices between buckets is difficult to paral lelize, likely requiring atomics and thus losing concurrency; efficient GPU implementations require exploiting three-layer memory hierarchy(global DRAM, per-block shared memory, and per-thread registers) of GPU
other=delta stepping, the original idea
---
id=34
title=GPGPU based image segmentation livewire algorithm implementation
author=
journal=
year=2007
tags=GPGPU, image segmentation, delta-stepping, shortest path(SSSP)
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=a GPU version of delta-stepping for SSSP, see [id:33]
---
id=35
title=Implementing sparse matrix-vector multiplication on throughput-oriented processors
author= Nathan Bell, Michael Garland
journal=International Conference for High Performance Computing, Networking, Storage, and Analysis(SC, CCF A)
year=2009
tags=Graph Data Structure, GPU, DIA(Diagonal format), ELL(ELLPACK), CSR(Compressed Sparse Row), COO(Coordinate Format)
star=*****
problem=
interest=
hardness=
idea=ELLPACK format is well-suited to vector and SIMD architectures,  its efficiency rapidly degrades when the number of nonzeros per matrix row varies; the storage efficiency of the COO format is invariant to the distribution of nonzeros per row, and the use of segmented reduction makes its performance largely invariant as well; To obtain the advantages of both, we combine these into a hybrid ELL/COO format
future=
comment=not use CSR and COO when matrix is small because there is not enough work; CSR not benefit from coalescing memory access
other=discussion of possible implementations, advantages, and disadvantages of several formats for sparse matrices
---
id=36
title=Memory-scalable GPU spatial hierarchy construction
author=
journal=IEEE Transactions on Visualization and Computer Graphics(TVCG, CCF A Journal)
year=2011
tags=GPU, BFS,Memory bound, kd-tree, bounding volume hierarchy,partial BFS 
star=****
problem=While being able to exploit the massive parallelism on the GPU, the BFS order also consumes excessive GPU memory and threads
interest=
hardness=
idea=use the partial breadth-first search (PBFS) construction order to control memory consumption while maximizing performance; memory allocation strategies to effectively limit memory fragmentation
future=
comment=a novel idea to turn from BFS to DFS at some point
other=
---
id=37
title=Fast Sparse Matrix and Sparse Vector Multiplication Algorithm on the GPU
author=Carl Yang, Yangzihao Wang, John D. Owens
journal=IPDPS
year=2015
tags=GPU, SpMSpV, SpMV
star=
problem=
interest=
hardness=different from SpMV(sparse matrix, dense vector)
idea=
future=
comment=
other=
---
id=38
title=Efficient wait-free implementation of a concurrent priority queue
author=
journal=WDAG
year=1993
tags=concurrent priority queue, Data Structure
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=39
title=Comparative Performance Analysis of Intel Xeon Phi, GPU, and CPU: A Case Study from Microscopy Image Analysis
author=
journal=IPDPS
year=2014
tags=GPU, MIC(Many Integrated Core)
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=40
title=Efficiency of a Good But Not Linear Set Union Algorithm
author=
journal=Journal of the ACM(JACM, CCF A Journal)
year=1975
tags=set union, disjoint set, union find, data structure, algorithm, complexity, equivalence, partition, tree 
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=citation higher than 1500; the original paper of disjoint set
---
id=41
title=Parallelizing Union-Find in Constraint Handling Rules Using Confluence Analysis
author=
journal=International Conference on Logic Programming(ICLP)
year=2005
tags=union find, disjoint set, parallel
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=42
title=Wait-free parallel algorithms for the union-find problem
author=
journal=ACM symposium on Theory of computing(STOC, CCF A Conference of computer science)
year=1991
tags=union find, disjoint set, parallel algorithm, wait-free, asynchronous parallelism
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=citation higher than 120
---
id=43
title=A New Scalable Parallel DBSCAN Algorithm Using the Disjoint-Set Data Structure
author=
journal=SC
year=2012
tags=Density based clustering, Union-Find algorithm, Disjoint-set  data  structure
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=44
title=Experiments on Union-Find Algorithms for the Disjoint-Set Data Structure
author=
journal=International Symposium on Experimental Algorithms(SEA)
year=2010
tags=Union-Find Disjoint Set Experimental Algorithms 
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=45
title=Multi-core spanning forest algorithms using the disjoint-set data structure
author=
journal=IPDPS
year=2012
tags=Multi-core, spanning forrest, connected components, Disjoint sets
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=46
title=Template Skycube Algorithms for Heterogeneous Parallelism on Multicore and GPU Architectures
author=
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Heterogeneous Parallelism
star=****
problem=
interest=
hardness=
idea= a novel templating methodology to create portable, yet architecture-aware algorithms;  cache-conscious CPU optimizations
future=
comment=
other=
---
id=47
title=A Memory Bandwidth-Efficient Hybrid Radix Sort on GPUs
author=Elias Stehle, Hans-Arno Jacobsen
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Hybrid Radix Sort, memory bandwidth
star=****
problem=
interest=
hardness=
idea=proceeding from the most-significant to the least-significant digit allows our algorithm to drop the requirement  of  stable  sorting  passes(not LSB-based, reduce the number of sorting passes and the amount of memory transfers);   heterogeneous  sorting  algorithm that uses the CPU on powerful host systems to mitigate the overhead introduced with PCIe data transfers and sort arbitrarily large inputs, using pipeline to exploit the full-duplex communication of the PCIe bus
future=
comment=
other=
---
id=48
title=Scout: A GPU-Aware System for Interactive Spatio-temporal Data Visualization
author=Harshada Chavan, Mohamed F. Mokbel
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Data Visualization, Spatio-temporal
star=****
problem=
interest=
hardness=
idea=Spatio-temporal indices
future=
comment=only a specific area, not so novel, seems like a demo
other=
---
id=49
title=Parallelizing Sequential Graph Computations
author=
journal=SIGMOD
year=2017
tags=GRAPE, parallel model, graph computation, partial evaluation, incremental evaluation, scalability
star=*****
problem=
interest=auto-parallelization with minor changes to sequential algorithm and ensure the correctness
hardness=
idea=
future=
comment=
other=best paper award of SIGMOD 2017
---
id=50
title=SuRF: Practical Range Query Filtering with Fast Succinct Tries
author=
journal=SIGMOD
year=2018
tags=data structure, range query, bloom filter, reduce I/O, membership test
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=best paper award of SIGMOD 2018
---
id=51
title=Entity Matching with Active Monotone Classification
author=
journal= ACM SIGMOD Conference on Principles of DB Systems(PODS, CCF B, top theorectical conference in Database area)
year=2018
tags=entity matching, active learning, monotone classification, entity matching, computation theory, Approximation algorithms analysis
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=best paper award of PODS 2018
---
id=52
title=Query-based Workload Forecasting for Self-Driving Database Management Systems
author=
journal=SIGMOD
year=2018
tags=workload forecasting, dynamic workload, self-driving database system
star=****
problem=predict the workload in future and select the proper optimizations in a timely manner for a dynamic changing workload
interest=
hardness=
idea=
future=
comment=
other=
---
id=53
title=Cold Filter: A Meta-Framework for Faster and More Accurate Stream Processing
author=Yang Zhou, Tong Yang
journal=SIGMOD
year=2018
tags=data streams, Approximate algorithms, data structures, sketch, stream processing
star=****
problem=
interest=
hardness=
idea=Different from existing filters that mainly focus on hot items, our filter captures cold items in the first stage, and hot items in the second stage; each item enters one stage only once
future=
comment=
other=
---
id=54
title=TurboFlux: A Fast Continuous Subgraph Matching System for Streaming Graph Data
author=Kyongmin Kim, In Seo (same contribution), Wook-Shin Han(the teacher)
journal=sigmod
year=2018
tags=dynamic graph, graph stream, continuous Subgraph matching
star=****
problem=answering continuous subgraph matching on dynamic graph
interest=subgraph matching is NP-hard and graph stream is hard to deal with
hardness=repeated subgraph matching for each edge update or expensive overheads in maintaining enormous intermediate results
idea=a concise representation of intermediate results, and its execution model allows fast incremental maintenance; an efficiently updatable graph for storing partial solutions(data-centric graph); edge transition model, which efficiently identifies which update operation can affect the current partial solutions
future=
comment=an amazing work which tries to solve the continuous subgraph matching problem on practical graph stream
other=
---
id=55
title=Speeding Up Set Intersections in Graph Algorithms using SIMD Instructions
author=Shuo Han, Lei Zou, Jeffery Xu Yu
journal=sigmod
year=2018
tags=set Intersections, graph algorithms, SIMD, subgraph matching, triangle counting, clique detection, graph ordering, graph processing, bitmap
star=****
problem=
interest=set intersection is widely used in graph algorithms, occupying a large potion of time
hardness=
idea=a binary representation scheme(BSR) to encode adjacency-lists, a merge-based intersection algorithm(QFilter), the node ordering also affects the performance by influencing the compactness of BSR sets
future=
comment=
other=similar idea to [id:66]
---
id=56
title=Randomized Algorithms Accelerated over CPU-GPU for Ultra-High Dimensional Similarity Search
author=Yiqiu Wang, Anshumali Shrivastava
journal=sigmod
year=2018
tags=CPU-GPU, similarity search, locality sensitive hashing, reservoir sampling, GPGPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=57
title=Logarithmic Radix Binning and Vectorized Triangle Counting
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=58
title=A (Sub)Graph Isomorphism Algorithm for Matching Large Graphs (vf2)
author=
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI, CCF A journal of Artificial Intelligence)
year=2004
tags=vf2,graph-subgraph isomorphism,induced subgraph,depth-first search,Backtrack paradigm,backtracking,large graphs, attributed relational graphs
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=based on induced subgraph rather than embedding subgraph;the implementation is very critical; much better than [id:59]
---
id=59
title=An Algorithm for Subgraph Isomorphism
author=J. R. Ullmann
journal=Journal of the Association for Computing Machinery(JACM, CCF A Journal)
year=1976
tags=graph, graph isomorphism, directed graph isomorphism, digraph isomorphism, subgraph, subgraph isomorphism, clique, clique detection, isomorphism algorithm, tree search, search tree, game tree, parallel processing, array processing, special purpose computer, logic-in-memory arrays, asynchronous sequential circuits, Boolean matrices
star=*****
problem=
interest=
hardness=
idea=
future=
comment=based on Linear Algebra
other=
---
id=60
title=Taming verification hardness: an efficient algorithm for testing subgraph isomorphism   (QuickSI)
author=Haichuan Shang, Ying zhang, xuemin lin, Jeffery Xu Yu
journal=VLDB
year=2008
tags=QuickSI
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=61
title= The transitive reduction of a directed graph
author=
journal=SIAM
year=1972
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=62
title=Efficient Subgraph Matching by Postponing Cartesian Products (CFL-Match)
author=Fei Bi, Lijun Chang, Xuemin Lin, Lu Qin, Wenjie Zhang
journal=SIGMOD
year=2016
tags=subgraph matching, subgraph isomorphism, core-forest, CFL-Match, CPI-index, core-forest-leaf decomposition
star=****
problem=unpromising results by Cartesian products from dissimilar vertices
interest=
hardness=
idea=core-forest-leaf decomposition, CPI index to prepare candidates for joining phase, matching order based on path with the minimum growing cost
future=k-core decomposition, extend to directed graphs with edge labels, consider parallel and distributed
comment=too complicated and not widely used
other=
---
id=63
title=Comparing performance of graph matching algorithms on huge graphs
author=Vincenzo Carletti
journal=Pattern Recognition Letters (PRL, CCF C Conference of AI)
year=2018
tags=subgraph isomorphism;subgraph matching,pattern recognition
star=***
problem=
interest=
hardness=
idea=compare vf2, vf3, RI(these three are tree-based), LAD and PathLAD(these two are constraint programming) on all kinds of graphs
future=
comment=no one beats others totally; vf3 is generally better, and better tradeoff between time and memory cost;vf2 is best at small graphs; vf3 is the disputed winner for finding the first solution; vf3 and RI confirmed to be a step forward with respect to the other algorithms for finding all solutions; it is advisable to use vf3 for most subgraph isomorphism problems
other=associated with ICPR contest; the experimental result in vf3
---
id=64
title=Computers and Intractability: A Guide to the Theory of NP-Completeness
author=M. R. Garey , David S. Johnson
journal=W. H. Freeman
year=1979
tags=NP-hard,NPC,NP-completeness,algorithm complexity,Intractability
star=*****
problem=
interest=
hardness=
idea=
future=
comment=notice that NPC is decision problems, but NP-hard is not
other=
---
id=65
title=Accelerating Large Graph Algorithms on the GPU Using CUDA
author=Pawan Harish
journal=HiPC (CCF C Conference of high performance Computing, also called HPC)
year=2007
tags=gpu,cuda,bfs,breadth-first search,sssp, apsp
star=**
problem=
interest=
hardness=
idea=
future=
comment=an early but basic implementation of these algorithms on GPU
other=
---
id=66
title=Fast Online Set Intersection for Network Processing on FPGA
author=Yun R. Qu, Viktor K. Prasanna
journal=TPDS(CCF A)
year=2016
tags=set intersection,network processing, field-programmable gate array(FPGA), bitmap
star=****
problem=For real-time network processing, the major challenge of set intersection is the strict performance requirement. Sets have to be intersected at very high throughput to sustain line-rate processing
interest=very common  and useful operator
hardness=all the elements of the sets are presorted but only known during run-time
idea=divide a set into multiple groups, compare groups of difdferent sets using LA algorithm(merge-join) and use bitwise-and for elements in the same group ID(BA algorithm); tree-based parallel architecture; only encode at the begining and decode at last
future=
comment=assume the lists are all sorted in the same order; able to deal with many sets
other=
---
id=67
title=Worst-case Optimal Join Algorithms
author=Hung Q. Ngo, Ely Porat
journal=PODS(CCF B, but the highest conference in database theory)
year=2012
tags=join Algorithm analysis, theoretical bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=68
title=Skew Strikes Back: New Developments in the Theory of Join Algorithms 
author=Hung Q. Ngo
journal=SIGMOD
year=2013
tags=join Algorithm analysis, skew data, theoretical bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=a graph with N edges has power(N, 3/2) distinct triangles
---
id=69
title=Leapfrog Triejoin: A Simple, Worst-Case Optimal Join Algorithm
author=Todd L. Veldhuizen
journal=Computer Science(arXiv preprint)
year=2012
tags=Algorithms, Theory, worst-case optimal join
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other= We show that NPRR is not worst-case optimal for such classes, giving a counterexample where leapfrog triejoin runs in O(nlogn) tiem and NPPR runs in theta(power(n, 1.375)) time
---
id=70
title=Join processing for graph patterns: An old dog with new tricks
author=Dung Nguyen
journal=Proceedings of the GRADES
year=2015
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=71
title=A Worst-Case Optimal Multi-Round Algorithm for Parallel Computation of Conjunctive Queries
author=Bas Ketsman, Dan Suciu
journal=PODS
year=2017
tags=parallelism, Conjunctive queries, multi-round, Worst-Case Optimal
star=****
problem=study the optimal communication cost for computing a full conjunctive query Q over p distributed servers
interest=
hardness=
idea=
future=
comment=
other=
---
id=72
title=Graph pattern matching: from intractable to polynomial time
author=Wenfei Fan
journal=VLDB
year=2010
tags=graph simulation
star=****
problem=define the graph simulation problem instead of graph matching
interest=
hardness=
idea=
future=
comment=
other=
---
id=73
title=Distributed exact subgraph matching in small diameter dynamic graphs
author=Charith Wickramaarachchi 
journal=Big Data
year=2016
tags=distributed subgraph matching, small diameter, dynamic graph
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=74
title=Bloom Filters, Adaptivity, and the Dictionary Problem
author=Michael A. Bender
journal=IEEE Symposium on Foundations of Computer Science(FOCS, CCF A of computer science)
year=2018
tags=bloom filters, Adaptivity, Dictionary, algorithm and data structures
star=****
problem=the probability guarantee of an approximate membership query data structure(Bloom, quotient, cuckoo filter)
interest=
hardness=
idea=
future=
comment=
other=
---
id=75
title=A Faster Isomorphism Test for Graphs of Small Degree
author=
journal=FOCS
year=2018
tags=Isomorphism test, small degree graphs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=76
title=Nearly work-efficient parallel algorithm for digraph reachability
author=
journal=STOC
year=2018
tags=work-efficient parallel algorithm, digraph reachability, graph algorithms
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=77
title=The query complexity of graph isomorphism: bypassing distribution testing lower bounds
author=
journal=STOC
year=2018
tags=graph isomorphism, query complexity, lower bounds
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=78
title=Round Compression for Parallel Matching Algorithms
author=
journal=ACM Symposium on Theory of Computing(STOC, CCF A of computer science)
year=2018
tags=round Compression, parallel matching Algorithms
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=79
title=Parallel Graph Connectivity in Log Diameter Rounds
author=
journal=FOCS
year=2018
tags=parallel Algorithms, graph Algorithms, graph Connectivity, log diameter
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=80
title=An exponential lower bound for Individualization-Refinement algorithms for Graph Isomorphism
author=
journal=STOC
year=2018
tags=graph Isomorphism, Individualization-Refinement algorithms, exponential lower bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=81
title=SIMD- and Cache-Friendly Algorithm for Sorting an Array of Structures
author=Hiroshi Inoue, Kenjiro Taura
journal=VLDB
year=2015
tags=SIMD, Cache, multiway sorting, vectorized algorithm
star=****
problem=sorting an array of structures by efficiently exploiting the SIMD instructions and cache memory
interest=sorting is common in database and the power of simd and cache is common and widely used now;exist SIMD libraries focus on sorting integers
hardness=if packing key and index(64 bit), then the cache miss of random access in the final rearrangement is severe; if sorting the whole structure directly, then keys need to be read veery time and the movement of all structures is costly
idea=based on multiway mergesort, does the key encoding and record rearranging for each multiway merge stage, while the key-index approach does the encoding only at the beginning of the entire sorting operation and record rearrangement at the end
future=
comment=
other=an improvement of [id:192]
---
id=82
title=Finding, Counting and Listing all Triangles in Large Graphs, An Experimental Study
author=Thomas Schank, Dorothea Wagner
journal=International Workshop on Experimental & Efficient Algorithms
year=2001
tags=Triangle Counting, Triangle Listing, Complexity Analysis
star=****
problem=the complexity and efficiency of algorithms of counting and listing triangles in large graphs
interest=very common and useful
hardness=
idea=a clique of vertex num n has almost n*n*n triangles; a graph of edge num n has O(m^1.5) triangles
future=
comment=
other=
---
id=83
title=FPGA acceleration of semantic tree reasoning algorithms
author=
journal=Journal of Systems Architecture
year=
tags=FPGA acceleration Algorithms, semantic tree
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=84
title=TRIÈST: Counting Local and Global Triangles in Fully-Dynamic Streams with Fixed Memory Size
author=
journal=SIGKDD
year=2016
tags=Triangle counting, dynamic stream
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=85
title=High Performance Exact Triangle Counting on GPUs
author=Mauro Bisson
journal=TPDS
year=2017
tags=Triangle counting, Graph processing, GPU Computing, Parallel computing, Big Data, CUDA, bitmap
star=****
problem=
interest=
hardness=
idea=based on node and CSR structure, matrix multiplication
future=
comment=
other=general triangle counting based on edge has complexity as O(|E|^1.5); naive methods will have 6 duplicates, but there are perfect strategy to eliminate all duplicates which just need a order definition and only save edges satisfying this order; use order of degree(only save edges from high degree to low degree) yield wonderful performance because high degree nodes are evenly divided and result in natural load balance
---
id=86
title=Space/Time Trade-offs in Hash Coding with Allowable Errors (Bloom Filter)
author=Burton H. Bloom
journal=Communications of the ACM
year=1970
tags=hash coding, hash addressing, scatter storage, searching, storage layout, retrieval trade-offs, retrieval efficiency, storage efficiency, bloom filter
star=*****
problem=reduce the hash area size(m) when allowing a small error(false positive) targeting at judging if an element is in a given set(size is n)
interest=it is a very common primitive to judge many times if an element is in a set(the total elements are much larger than this set)
hardness=how to keep a tradeoff between hash area and reject time, how to provide a theorectical guarantee on the falso positive error
idea=two methods that are different from the conventional error-free hash; use multiple hash functions to reduce the errors while keeping a small hash array
future=how to distinguish elements with high frequency and low frequency
comment=the first wonderful work to come up with the idea of bloom filter; it is very suitable for many judgements on a not-so-large set and many judgements are invalid(then needless to access the high-latency memory); it is widely used in GPU, FPGA and CPU cache; to yield an ideal performance, the size of hash array is required to be two times larger than the size of set
other=if use a single hash function to reduce the conflict rate to 0.01, we need to use a hash array whose size is 100 times of the number of elements; http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html ; 哈希函数的选择对性能的影响应该是很大的，一个好的哈希函数要能近似等概率的将字符串映射到各个Bit。选择k个不同的哈希函数比较麻烦，一种简单的方法是选择一个哈希函数，然后送入k个不同的参数; 对于给定的m、n，当 k = ln(2)* m/n 时出错的概率是最小的; https://blog.csdn.net/jiaomeng/article/details/1495500
---
id=87
title=HeavyKeeper: An Accurate Algorithm for Finding Top-k Elephant Flows
author=Junzhi Gong, Tong Yang
journal=USENIX Annual Technical Conference
year=2018
tags=data stream, top-k, data flow, network traffic, frequency
star=****
problem=
interest=
hardness=
idea=we adopt a new strategy, called count-with-exponential-decay, to achieve space-accuracy balance by actively removing small flows through decaying, while minimizing the impact on large flows, so as to achieve high precision in finding top-k elephant flows. Moreover, the proposed algorithm called HeavyKeeper incurs small, constant processing overhead per packet and thus supports high line rates
future=
comment=
other=
---
id=88
title=Optimizing N-Dimensional, Winograd-Based Convolution for Manycore CPUs
author=Zhen Jia
journal=PPoPP
year=2018
tags=N-dimensional, winograd, Convolution, manycore CPUs, high-performance computing, machine learning
star=****
problem=existing implementations are limited to 2D data and a single kernel size of 3 by 3.
interest=
hardness=
idea=
future=
comment=
other=winograd http://shuokay.com/2018/02/21/winograd/ ;
---
id=89
title=SuperNeurons: Dynamic GPU Memory Management for Training Deep Neural Networks
author=Linnan Wang, Jinmian He
journal=PPoPP
year=2018
tags=GPU, Neural network, Deep Learning(DL), dynamic GPU memory management, SuperNeurons, machine learning
star=****
problem=
interest=deeper and wider neural network can provide higher accuracy; free DL(Deep Learning) practitioners from adjusting bottom GPU architecture
hardness=mmeory capacity, long training time
idea=a dynamic GPU memory scheduling runtime to enable the network training far beyond the GPU DRAM capacity. SuperNeurons features 3 memory optimizations, Liveness Analysis, Unified Tensor Pool, and Cost-Aware Recomputation; together they effectively reduce the network-wide peak memory usage down to the maximal memory usage among layers. We also address the performance issues in these memory-saving techniques
future=
comment=
other=
---
id=90
title=Transparent GPU Memory Management for DNNs
author=Jungho Park
journal=PPoPP(demo)
year=2018
tags=GPU memory management, DNN, machine learning
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=91
title=Bridging the Gap between Deep Learning and Sparse Matrix Format Selection
author=Yue Zhao
journal=PPoPP
year=2018
tags=Deep Learning, Sparse Matrix Format Selection, Sparse Matrix Vector multiplication(SpMV), Machine Learning
star=****
problem=determining the best storage format for a matrix to maximize the performance of Sparse Matrix Vector Multiplication (SpMV). It describes how to effectively bridge the gap between deep learning and the special needs of the pillar HPC problem through a set of techniques on matrix representations, deep learning structure, and cross-architecture model migrations
interest=
hardness=
idea=
future=
comment=
other=
---
id=92
title=FlashR: Parallelize and Scale R for Machine Learning using SSDs
author=Da Zheng
journal=PPoPP
year=2018
tags=parallel algorithm, R language, Solid-state drives(SSD), Machine Learning
star=****
problem=R is one of the most popular programming languages for statistics and machine learning, but it is slow and unable to scale to large datasets.
interest=
hardness=
idea=FlashR accelerates and scales existing R code by parallelizing a large number of matrix functions in the R base package and scaling them beyond memory capacity with solid-state drives (SSDs). FlashR performs memory hierarchy aware execution to speed up parallelized R code by (i) evaluating matrix operations lazily, (ii) performing all operations in a DAG in a single execution and with only one pass over data to increase the ratio of computation to I/O, (iii) performing two levels of matrix partitioning and reordering computation on matrix partitions to reduce data movement in the memory hierarchy
future=
comment=
other=best paper candidate
---
id=93
title=Featherlight On-the-fly False-sharing Detection
author=Milind Chabbi
journal=PPoPP
year=2018
tags=False-sharing Detection, shared-memory parallism, CPU cacheline, performance monitoring units(PMU), debug registers
star=****
problem=Shared-memory parallel programs routinely suffer from false sharing—a performance degradation caused by different threads accessing different variables that reside on the same CPU cacheline and at least one variable is modified
interest=State-of-the-art tools detect false sharing via a heavyweight process of logging memory accesses and feeding the ensuing access traces to an offline cache simulator
hardness=
idea=achieves low overhead by exploiting two hardware features ubiquitous in commodity CPUs: the performance monitoring units (PMU) and debug registers. Additionally, Feather is a first-of-its-kind tool to detect false sharing in multi-process applications
future=
comment=
other=best paper candidate
---
id=94
title=Cache-Tries: Concurrent Lock-Free Hash Tries with Constant-Time Operations
author=Aleksandar Prokopec
journal=PPoPP
year=2018
tags=parallel algorithm, data structure, trie, lock-free, concurrent, hash, constant-time, cache-friendly
star=****
problem=operations on most existing concurrent hash tries run in O(logn) time
interest=
hardness=
idea=
future=
comment=
other=best paper candidate
---
id=95
title=Register Optimizations for Stencils on GPUs
author=Prashant Singh Rawat
journal=PPoPP
year=2018
tags=Compiler Optimization, register Optimization, register pressure, optimal schedule, heuristic algorithm, Stencils, GPU, Loop Unroll, CUDA, ILP(Instruction-level parallelism)
star=*****
problem=register pressure in complex high order Stencils(compute-intensive and much data sharing)
interest=卷积/模板运算非常普遍（偏微分方程，数学物理，计算化学，图像处理，信号处理，神经网络等），且卷积的结构和大小对 算法的精度有很大的影响。卷积运算中存在大量的数据共享，通常的做法是loop unroll 或者shared memory
hardness=logical induction and mathematical analysis, as well as the difficulity of using GPU
idea=在保证spill-free 的前提下，降低MAXLIVE 时间，即同一时刻寄存器最大使用量。这可以通过最大化各执行树之间的共享，并改善调度算法来实现; develop a statement reordering framework that models stencil computations as a DAG of trees with shared leaves, and adapts an optimal scheduling algorithm for minimizing register usage for expression trees(计算最优调度的复杂度太高，实际上是用启发式 算法来找一个较优的调度)
future=maybe apply the optimizations to more primitives
comment=a solid work that targets at the optimization of a specific primitive which is widely used
other=best paper candidate; nvcc is not opensourced and gpucc is just a front-end which also uses nvcc as backend, LLVM(low level virtue machine) is opensourced; the compiler optimization is more important and widely than code optimization, but more difficult; the prons and cons of kernel fusion and kernel fission; pattern-specific optimization techniques have demonstrably been more beneficial, as well as algorithms, protocols, chips, systems and so on
---
id=96
title=Practical Concurrent Traversals in Search Trees
author=
journal=PPoPP
year=2018
tags=Concurrent Traversal, search tree, optimistic concurrency-control scheme, validation
star=****
problem=Operations of concurrent objects often employ optimistic concurrency-control schemes that consist of a traversal followed by a validation step. The validation checks if concurrent mutations interfered with the traversal to determine if the operation should proceed or restart. A fundamental challenge is to discover a necessary and sufficient validation check that has to be performed to guarantee correctness.
interest=
hardness=
idea=a necessary and sufficient condition for validating traversals in search trees. The condition relies on a new concept of succinct path snapshots, which are derived from and embedded in the structure of the tree; a general lock-free membership test suitable for any search tree
future=
comment=
other=
---
id=97
title=LazyGraph: Lazy Data Coherency for Replicas in Distributed Graph-Parallel Computation
author=Lei Wang
journal=PPoPP
year=2018
tags=Lazy Data Coherency, Distributed Graph-parallel Computation, Execution Model, node replicas
star=****
problem=any changes to vertex data must be immediately communicated to all replicas of v, leading to frequent global synchronization and communications.
interest=
hardness=
idea=
future=
comment=
other=
---
id=98
title=PAM: Parallel Augmented Maps
author=Yihan Sun
journal=PPoPP
year=2018
tags=parallel algorithm, data structure, ordered map
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=99
title=Griffin: Uniting CPU and GPU in Information Retrieval Systems for Intra-Query Parallelism
author=Yang Liu
journal=PPoPP
year=2018
tags=
star=****
problem=previous work runs queries either on GPU or CPU, ignoring the fact that the best processor for a given query depends on the query’s characteristics, which may change as the processing proceeds.
interest=
hardness=
idea=dynamically combines GPU- and CPU-based algorithms to process individual queries according to their characteristics; leveraging a new compression scheme and exploiting an advanced merge-based intersection algorithm
future=
comment=
other=
---
id=100
title=Juggler: A Dependence-Aware Task-Based Execution Framework for GPUs
author=
journal=PPoPP
year=2018
tags=GP-GPU programming, task-based execution, data dependence, OpenMP 4.5
star=****
problem=the existence of data dependences across thread blocks may significantly impact the speedup by requiring global synchronization across multiprocessors (SMs) inside the GPU
interest=
hardness=
idea=a task-based execution scheme for GPU workloads with data dependences. The Juggler framework takes applications embedding OpenMP 4.5 tasks as input and executes them on the GPU via an efficient in-device runtime, hence eliminating the need for kernel-wide global synchronization
future=
comment=
other=
---
id=101
title=Interval-Based Memory Reclamation
author=Haosen Wen
journal=PPoPP
year=2018
tags=memory reclamation, concurrent data structures, safe reclamation, disconnected memory blocks
star=****
problem=a thread, before freeing a block, must ensure that no other threads are accessing that block; the required synchronization tends to be expensive.
interest=
hardness=In contrast with epoch-based reclamation, in which threads reserve all blocks created after a certain time, or pointerbased reclamation (e.g., hazard pointers), in which threads reserve individual blocks
idea=By comparing a thread’s reserved interval with the lifetime of a detached but not yet reclaimed block, the system can determine if the block is safe to free. Like hazard pointers, IBR avoids the possibility that a single stalled thread may reserve an unbounded number of blocks; unlike hazard pointers, it avoids a memory fence on most pointer-following operations.  It also avoids the need to explicitly “unreserve” a no-longer-needed pointer.
future=
comment=
other=
---
id=102
title=Efficient Parallel Lists Intersection and Index Compression Algorithms using Graphics Processing Units
author=Naiyong Ao, Fan Zhang, Di Wu
journal=VLDB
year=2011
tags=parallel Algorithm, list Intersection, index Compression, GPU, linear regression, machine learning, binary search
star=****
problem=
interest=
hardness=
idea=linear regression(x is the list index, y is the elements) and hash segmentation(hash into buckets, then in bucket do normal binary search) to speed up list intersection by contracting the search range; for index compression, propose a Linear Regression Compression schema which has an inherent parallel structure
future=
comment=
other=in web search a sentence is divided into several keywords and each keyword returns a sorted list of document IDs, the final job is to intersect these lists; d-gap compression: in the list of document IDs, if using variable byte encoding, then using the difference between two IDs instead of the IDs themselves is better
---
id=103
title=Improving Medium-Grain Partitioning for Scalable Sparse Tensor Decomposition
author=Seher Acer
journal=TPDS
year=2018
tags=tensor decomposition, CPD-ALS, CartHP, distributed-memory-parallel algorithm, sparse tensor, canonical polyadic decomposition, cartesian partitioning, load balancing, communication volume, hypergraph partitioning
star=****
problem=CPD-ALS does not utilize the sparsity pattern of the tensor to reduce the total communication volume
interest=tensor decomposition is widely used and High computational and memory costs of CPD-ALS necessitate the use of a distributed-memory-parallel algorithm for efficiency
hardness=
idea=
future=
comment=
other=
---
id=104
title=Developing User Perceived Value Based Pricing Models for Cloud Markets
author=Peijin Cong, Liying Li
journal=TPDS
year=2018
tags=Cloud computing, Dynamic Pricing Model, User Perceived Value, Profit Maximization, Augmented Lagrange Function
star=****
problem=existing pricing models rarely consider the dynamic interactions between user requests and the cloud service provider
interest=With the rapid deployment of cloud computing infrastructures, understanding the economics of cloud computing has become a pressing issue for cloud service providers
hardness=
idea=a dynamic pricing model based on the concept of user perceived value that accurately captures the real supply and demand relationship in the cloud service market. Subsequently, a profit maximization scheme is designed based on the dynamic pricing model that optimizes profit of the cloud service provider without violating service-level agreement. Finally, a dynamic closed loop control scheme is developed to adjust the cloud service price and multiserver configurations according to the dynamics of the cloud computing environment such as fluctuating electricity and rental fees
future=
comment=
other=
---
id=105
title=Competitiveness of a Non-Linear Block-Space GPU Thread Map for Simplex Domains
author=Matthieu Vernier
journal=TPDS
year=2018
tags=GPU thread mapping, block-space, simplex domains, GPU optimization
star=****
problem=unnecessary threads assign in a special problem domain; for example, only the lower triangle of a matrix is really used or symmetric
interest=
hardness=
idea=
future=
comment=
other=
---
id=106
title=Analysis and Design Techniques towards High-Performance and Energy-Efficient Dense Linear Solvers on GPUs
author=Ahmad Abdelfattah
journal=TPDS
year=2018
tags=Dense linear solvers, GPU computing, energy efficiency, matrix factorization, Algorithm
star=****
problem=existing hybrid CPU-GPU strategies have probolems of less efficiency and high energy consuming
interest=Graphics Processing Units (GPUs) are widely used in accelerating dense linear solvers. The matrix factorizations, which dominate the runtime for these solvers, are often designed using a hybrid scheme, where GPUs perform trailing matrix updates, while the CPUs perform the panel factorizations
hardness=
idea=This paper presents analysis and design techniques that overcome the shortcomings of the hybrid algorithms, and allow the design of high-performance and energy-efficient dense LU and Cholesky factorizations that use GPUs only.
future=
comment=
other=CuSOLVER by Nvidia is the existing algorithm that only uses GPU
---
id=107
title=Eunomia: Scaling Concurrent Search Trees under Contention Using HTM
author=Xin Wang
journal=TPDS
year=2018
tags=Hardware Transactional Memory(HTM), Concurrent Search Tree, Opportunistic Consistency, Concurrency Control
star=****
problem=with the assistance of HTM, can we construct a concurrent search tree structure that delivers high and scalable performance even under high contention
interest=hardware transactional memory (HTM) has recently been adopted to construct efficient concurrent search tree structures, such designs fail to deliver scalable performance under contention
hardness=
idea=First, based on the observation that most HTM conflicts happen in the leaf layer, we partition a monolithic HTM region into multiple parts and protect the atomicity of different parts using HTM respectively.  A version-based scheme is utilized to guarantee overall consistency at the boundary of different HTM regions. With this scheme, most conflicts only cause retry within the partitioned transaction pieces, instead of the entire monolithic transaction. Second, to eliminate false conflicts incurred by consecutive data layout and metadata accesses, Eunomia refactors the tree structure in a partitioned way, which dispatches concurrent requests to different segments. Third, to throttle the true conflicting requests, Eunomia adopts an efficient mechanism, which anticipates potential conflicts and avoids them accordingly. Finally, Eunomia adopts an adaptive contention control mechanism, which can detect various contention rates and achieve high performance under both high and low contention.
future=
comment=
other=https://en.wikipedia.org/wiki/Transactional_memory
---
id=108
title=Confluence: Speeding Up Iterative Distributed Operations by Key-Dependency-Aware Partitioning
author=Feng Liang
journal=TPDS
year=2018
tags=Spark, shuffle, key dependency, iterative distributed operation, partitioning, Map Reduce, Algorithm
star=****
problem=A typical shuffle operation randomly partitions data on many computers, generating possibly a significant amount of network traffic which often dominates a job’s completion time
interest=This traffic is particularly pronounced in iterative distributed operations where each iteration invokes a shuffle operation(like MapReduce)
hardness=
idea=If data generated by the current iteration are partitioned to the computers where they will be processed in the next iteration, unnecessary shuffle network traffic between the two iterations can be prevented
future=
comment=
other=there is a figure of MapReduce in this figure which explains the idea clearly
---
id=109
title=Organization and maintenance of large ordered indexes
author=Bayer, Rudolf and McCreight, Edward
journal=Software pioneers
year=2002
tags=B+ tree, large ordered indices, Bplus tree, the evolution of B-tree, Data structure
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=110
title=Argobots: A Lightweight Low-Level Threading and Tasking Framework
author=Sangmin Seo
journal=TPDS
year=2018
tags=Argobots, user-level thread, tasklet, OpenMP, MPI, I/O, interoperability, lightweight, context switch, stackable scheduler, concurrency, Framework
star=****
problem=Current state-of-the-art user-level threading and tasking models, however, either are too specific to applications or architectures or are not as powerful or flexible
interest=a number of user-level threading and taskingmodels have been proposed in the literature to address the shortcomings of OS-level threads, primarily with respect to cost and flexibility
hardness=
idea=Argobots offers a carefully designed execution model that balances generality of functionalitywith providing a rich set of controls to allow specialization by end users or high-level programmingmodels; We describe the design, implementation, and performance characterization of Argobots and present integrations with three high-levelmodels: OpenMP,MPI, and colocated I/O services
future=
comment=experiment and evaluation are the main parts of this paper
other=
---
id=111
title=An Auto-Tuner for OpenCL Work-Group Size on GPUs
author=Thanh Tuan Dao
journal=TPDS
year=2018
tags=GPU, auto-tuning, workload characterization, workgroup size, OpenCL, NVIDIA, AMD
star=****
problem=Tuning the kernel work-group size for GPUs is a challenging problem
interest=the most influential performance factors with regard to the work-group size include occupancy, coalesced global memory accesses, cache contention, and variation in the amount of workload in the kernel
hardness=
idea=using the performance counters provided by GPUs, we characterize a large body of OpenCL kernels to identify the performance factors that affect the choice of a good work-group size
future=maybe use Machine Learning for tuning parameters
comment=We show the effectiveness of our auto-tuner by evaluating it with a set of 54 OpenCL kernels on three different NVIDIA GPUs and one AMD GPU; find sub-optimal work-group size within a small time interval and the performance is very closed to the optimal one
other=nvidia cuda now also supports varied work group size
---
id=112
title=Easy PRAM-Based High-Performance Parallel Programming with ICE
author=Fady Ghanim
journal=TPDS
year=2018
tags=ICE, ease of programming, irregular programs, PRAM(parallel random-access machine/model), fine-grained parallelism, XMT, nested ICE, nested parallelism
star=****
problem= Unfortunately parallel programming technologies have advanced at a much slower pace except for regular programs
interest=Parallel machines have become more widely used.
hardness=For irregular programs, this advancement is inhibited by high synchronization costs, non-loop parallelism, non-array data structures, recursively expressed parallelism and parallelism that is too fine-grained to be exploitable.
idea=easy-to-program, since: (i) ICE is a synchronous, lock-step language so there is no need for programmer-specified synchronization; (ii) for a PRAM algorithm its ICE program amounts to directly transcribing it; and (iii) the PRAM algorithmic theory offers unique wealth of parallel algorithms and techniques
future=
comment=
other=
---
id=113
title=AIRA: A Framework for Flexible Compute Kernel Execution in Heterogeneous Platforms
author=Robert Lyerly
journal=TPDS
year=2018
tags=Heterogeneous architectures, compilers, runtimes, programming models, architecture selection, CPU-GPU
star=****
problem=
interest=Heterogeneous-ISA computing platforms have become ubiquitous, and will be used for diverse workloads which render static mappings of computation to processors inadequate
hardness=
idea=Dynamic mappings which adjust an application’s usage in consideration of platform workload can reduce application latency and increase throughput for heterogeneous platforms
future=
comment=
other=
---
id=114
title=MSGD: A Novel Matrix Factorization Approach for Large-scale Collaborative Filtering Recommender Systems on GPUs
author=Hao Li, Kenli Li
journal=TPDS
year=2018
tags=Collaborative filtering (CF), CUDA parallelization algorithm, Matrix factorization (MF), Multi-GPU implementation, Stochastic gradient descent (SGD).
star=****
problem=stochastic gradient descent (SGD) is one of the most famous approaches for MF. However, it is non-trivial to parallelize SGD for large-scale problems due to the dependence on the user and item pair, which can cause parallelization over-writing
interest=Real-time accurate recommendation of large-scale recommender systems is a challenging task. Matrix factorization (MF), as one of the most accurate and scalable techniques to predict missing ratings, has become popular in the collaborative filtering (CF) community
hardness=To remove the dependence on the user and item pair, we propose a multi-stream SGD (MSGD) approach, for which the update process is theoretically convergent
idea=divides the task into coarse sub-tasks that are mapped to independent thread blocks, and then be solved by those independent thread blocks. Each sub-task is divided into finer pieces that map to threads within the thread block, then be solved cooperatively by those threads in parallel.
future=
comment=
other=
---
id=115
title=Neurostream: Scalable and Energy Efficient Deep Learning with Smart Memory Cubes
author=Erfan Azarkhish
journal=TPDS
year=2018
tags=Hybrid memory cube, convolutional neural networks, large-scale deep learning, streaming floating-point
star=****
problem=
interest=High-performance computing systems aremoving towards 2.5D and 3Dmemory hierarchies, based onHigh Bandwidth Memory (HBM) and HybridMemory Cube (HMC) tomitigate themainmemory bottlenecks
hardness=
idea=Our co-design approach consists of a network ofSmart Memory Cubes (modular extensions to the standard HMC) each augmented with a many-core PIMplatformcalled NeuroCluster. NeuroClusters have amodular design based onNeuroStreamcoprocessors (forConvolutionintensive computations) and general-purpose RISC-V cores
future=
comment=a flexible processor-in-memory (PIM) solution for scalable and energy-efficient execution of deep convolutional networks (ConvNets), one of the fastest-growing workloads for servers and high-end embedded systems.
other=brain-inspired computing (BIC), near-memory computation
---
id=116
title=Toward High Mobile GPU Performance Through Collaborative Workload Offloading
author=Chao Wu
journal=TPDS
year=2018
tags=Mobile applications, distributed system, code offload, performance optimization, collaborative workload offloading
star=****
problem=the challenge of poor hardware support but fine-grained rendering details often makes user unsatisfied especially in calling for high frame rate scenarios, e.g., game
interest=The ever increasing of display resolution on mobile devices raises high demand for GPU rendering details
hardness=
idea=ButterFly, a novel system which collaboratively utilizes mobile GPUs to process high-quality rendering details for on-the-go mobile users
future=
comment=utilize mobile GPUs in the same wifi to provide better display
other=
---
id=117
title=Fast K-selection Algorithms for Graphics Processing Units
author=TOLU ALABI
journal=ACM Journal of Experimental Algorithmics
year=2012
tags=Algorithms, Design, Experimentation, Performance, Top-K, K-selection, Order Statistics, Multi-core, Graphics Processing Units, GPGPU, CUDA, radixSelect, bucketSelect, concurrent programming, parallel programming
star=****
problem=Finding the kth largest value in a list of n values
interest=
hardness=sort maybe done extra work
idea=sort&choose, radixSelect, bucketSelect
future=
comment=in sequential algorithm the k-selection problem has solutions running in O(n) time
other=https://github.com/yuxianzhi/Top-K; https://devtalk.nvidia.com/default/topic/814439/cuda-programming-and-performance/top-k-elements-selection-/
---
id=118
title=gem5-gpu: A Heterogeneous CPU-GPU Simulator
author=Jason Power
journal=Computer Architecture Letters
year=2015
tags=Modeling techniques, Simulators, Heterogeneous (hybrid) systems, General-purpose graphics processors, GPU
star=***
problem=gem5-gpu is a new simulator that models tightly integrated CPU-GPU systems
interest=It builds on gem5, a modular fullsystem CPU simulator, and GPGPU-Sim(id=172), a detailed GPGPU simulator.
hardness=GPGPU-Sim is unable to model the interactions between CPU and GPU
idea=
future=
comment=
other=
---
id=119
title=Parallel Spectral Graph Partitioning
author=Maxim Naumov
journal=NVIDIA Technical Report
year=2016
tags=Spectral graph, multi-level Partition scheme
star=****
problem=
interest=the behavior of our spectral scheme and popular multi-level schemes is starkly different for two classes of problems: (i) social network graphs that often have power law-like distribution of edges per node and (ii) meshes arising from discretization of partial differential equations 
hardness=
idea=a novel parallel spectral partitioning method that takes advantage of an Exploringcient implementation of a preconditioned eigenvalue solver and a k-means algorithm on the GPU
future=in our numerical experiments the multi-level schemes are almost always faster, we show that our spectral scheme can achieve a significantly higher quality of partitioning for the social network graphs
comment=the usage of spectral graph theory in graph partition
other=
---
id=120
title=A conjugate gradient method for the spectral partitioning of graphs
author=
journal=Parallel Computing
year=1997
tags=共轭梯度法(Conjugate Gradient Method),spectral graph theory, spectral partitioning 
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=121
title=An Improved Spectral Graph Partitioning Algorithm for Mapping Parallel Computations
author=Bruce Hendrickson
journal=SIAM Journal on Scientific Computing
year=1992
tags=Spectral graph Partitioning, parallel computing
star=****
problem=Efficient use of a distributed memory parallel computer requires that the computational load be balanced across processors in a way that minimizes interprocessor communication.
interest=
hardness=
idea=Our generalization of spectral graph bisection involves a novel use of multiple eigenvectors to allow for division of a computation into four or eight parts at each stage of a recursive decomposition. The resulting method is suitable for scientific computations like irregular finite elements or differences performed on hypercube or mesh architecture machines.
future=
comment=
other=
---
id=122
title=A Hybrid B+-tree as Solution for In-Memory Indexing on CPU-GPU Heterogeneous Computing Platforms
author=Amirhesam Shahvarani
journal=SIGMOD
year=2016
tags=Heterogeneous Computing, Indexing, In-memory Database, B+-tree, CPU-GPU
star=****
problem=An in-memory indexing tree is a critical component of many databases
interest=Modern many-core processors, such as GPUs, are offering tremendous amounts of computing power making them an attractive choice for accelerating indexing
hardness=the memory available to the accelerating co-processor is rather limited and expensive in comparison to the memory available to the CPU. This drawback is a barrier to exploit the computing power of co-processors for arbitrarily large index trees.
idea=the joint and simultaneous use of computing and memory resources of CPU-GPU systems
future=
comment=good paper, very solid
other=
---
id=123
title=Algebraic connectivity of graphs
author=MIROSLAV FIEDLER
journal=Czechoslovak mathematical journal 
year=1972
tags=Algebraic connectivity, spectral graph theory
star=*****
problem=
interest=
hardness=
idea=
future=
comment=the basic idea of spectral graph theory
other=
---
id=124
title=Laplacian of Graphs and Algebraic Connectivity
author=MIROSLAV FIEDLER
journal=Banach Center Publications
year=1989
tags=Laplacian of Graphs, spectral graph theory, Algebraic Connectivity
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=125
title=Lower bounds for the Partitioning of Graphs
author=W. E. Donath
journal=
year=
tags=spectral Graph theory
star=*****
problem=lower bound of the crossing edges in graph Partitioning Problem
interest=
hardness=
idea=
future=
comment=
other=
---
id=126
title=THE CONJUGATE GRADIENT METHOD IN EXTREMAL PROBLEMS
author=B. T. POLYAK
journal=
year=1967
tags=共轭梯度法(Conjugate Gradient Method), EXTREMAL problems, mathematical method, iterational algorithm, linear algebra
star=*****
problem=
interest=
hardness=
idea=proves the convergence of the method as applied to non-quadratic functionals, describe its extension to constrained problems, considers means for further accelerating the convergence, and describes experience in the practical application of the method for solving a variety of extremal problems.
future=
comment=
other=
---
id=127
title=Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering
author=
journal=RecSys
year=2011
tags=共轭梯度法(Conjugate Gradient Method),collaborative filtering
star=****
problem=The need for solving weighted ridge regression (WRR) problems arises in a number of collaborative filtering (CF) algorithms.
interest=
hardness=Often, there is not enough time to calculate the exact solution of the WRR problem, or it is not required.  idea=The conjugate gradient (CG) method is a state-of-the-art approach for the approximate solution of WRR problems.  In this paper, we investigate some applications of the CG method for new and existing implicit feedback CF models.
future=
comment=
other=
---
id=128
title=Similarity-Aware Spectral Sparsification by Edge Filtering
author=Zhuo Feng
journal=DAC
year=2018
tags=Spectral graph theory, graph partitioning, iterative methods
star=***
problem=
interest=
hardness=
idea=a similarity-aware spectral graph sparsification framework that leverages Exploringcient spectral otree edge embedding and filtering schemes to construct spectral sparsifiers with guaranteed spectral similarity (relative condition number) level.
future=
comment=
other=
---
id=129
title=Accelerating graph isomorphism queries in a graph database using GPU
author=
journal=
year=
tags=graph mining, graph isomorphism, GPU, graph database
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=the same paper with [id:29]
---
id=130
title=parallel graph mining with GPUs
author=
journal=
year=
tags=Parallel Frequent Graph Mining, Graphics Processing Unit(GPU), frequent pattern, graph database
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=131
title=GpSense: A GPU-friendly method for common-sense subgraph matching in massively parallel architectures
author=Ha-Nguyen Tran, Erik Cambria
journal=International Conference on Intelligent Text Processing and Computational Linguistics
year=2016
tags=GPU, subgraph matching, common-sense, parallel computing
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=use the subgraph matching algorithm in [id:12], like [id:25]
---
id=132
title=GPU Join Processing Revisited
author=Tim Kaldewey
journal=Proceedings of the Eighth International Workshop on Data Management on New Hardware (DaMoN)
year=2012
tags=GPU, join Processing, UVA, PCI-E
star=***
problem=hash join: a large table(probe table) and a small table(build table)
interest=
hardness=
idea=place build table in shared memory, and let GPU access CPU memory directly at PCI-E speed
future=
comment=utilize the new feature of GPU, but not so good practically
other=
---
id=133
title=Performance Optimization of the HPCG Benchmark on the Sunway TaihuLight Supercomputer
author=Yulong Ao, Chao Yang
journal=ACM Transactions on Architecture and Code Optimization
year=2018
tags=high-performance conjugate gradient (HPCG) benchmark, Sunway TaihuLight Supercomputer, Heterogeneous (hybrid) systems, Massively parallel algorithms, 共轭梯度法
star=***
problem=
interest=
hardness=
idea=Block multicoloring parallelization, a block multicoloring reordering method to increase the degree of parallelism without severely degrading the convergence rate; Locality-aware layout transformation; Requirement-based data access; Concurrent gather collective; Fine-grain task overlapping
future=
comment=
other=
---
id=134
title=A distributed in-memory key-value store system on heterogeneous CPU–GPU cluster
author=Kai Zhang
journal=VLDB Journal 
year=2017
tags=key-value store, CPU-GPU cluster, heterogeneous systems, distributed systems, energy efficiency, in-memory key-value indices, Mega-KV
star=****
problem=In-memory key-value stores play a critical role in many data-intensive applications to provide high-throughput and low latency data accesses.
interest=our experiments show that homogeneous multicore CPU systems are limited in performance
hardness=
idea=Effectively utilizing the high memory bandwidth and latency hiding capability of GPUs, Mega-KV provides fast data accesses and significantly boosts overall performance and energy efficiency over the homogeneous CPU architectures; Periodical GPU scheduling for bounded latency, the majority are search and the latency of updates is tolerated; Decoupling index data structure from key-value items; cuckoo hash table as the index data structure
future=
comment=
other=slab memory management: https://en.wikipedia.org/wiki/Slab_allocation
---
id=135
title=ALOR: Adaptive Layout Optimization of Raft Groups for Heterogeneous Distributed Key-Value Stores
author=Yangyang Wang
journal=IFIP International Conference on Network and Parallel Computing(NPC, CCF C Conference of architecture)
year=2018
tags=layout Optimization, Heterogeneous Distributed key-value stores
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=136
title=Cuckoo hashing
author=Pagh Rasmus
journal=Journal of Algorithms
year=2003
tags=cuckoo hashing, data structure and Algorithms
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=137
title=A optimal algorithm to generating minimal perfect hash functions
author=
journal=Information processing letters
year=1992
tags=minimal perfect hash functions, optimal algorithm
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=perfect hashing generator: https://blog.csdn.net/chixinmuzi/article/details/1727195;   hash theory: https://blog.csdn.net/lanchunhui/article/details/50568809
---
id=138
title=A New algorithm for constructing minimal perfect hash functions
author=
journal=
year=2004
tags=minimal perfect hash functions
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=139
title=An Approach for Minimal Perfect Hash Functions for Very Large Databases
author=
journal=
year=2006
tags=Minimal Perfect hash functions, database
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=140
title=A Practical Minimal Perfect Hashing Method
author=
journal=International Workshop on Experimental and Efficient Algorithms
year=2005
tags=Practical minimal perfect hashing method, hash functions
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=141
title=Bloom Filters via d-Left Hashing and Dynamic Bit Reassignment Extended Abstract
author=Flavio Bonomi
journal=Forty-Fourth Annual Allerton Conf
year=2006
tags=bloom filters, d-left hashing, dynamic bit Reassignment, hash functions, counting bloom filter(CBF)
star=****
problem=
interest=
hardness=
idea=dynamic bit reassignment, an approach that allows the size of the fingerprint to flexibly change with the load in each hash bucket, thereby reducing the probability of a false positive
future=
comment=
other=
---
id=142
title=Using Multiple Hash Functions to Improve IP Lookups
author=Broder Andrei
journal=Twentieth Annual Joint Conference of the IEEE Computer and Communications Societies
year=2001
tags=multiple hash functions, IP lookup, d-left hashing 
star=****
problem=High performance Internet routers require a mechanism for very efficient IP address look-ups
interest=Some techniques used to this end, such as binary search on levels, need to construct quickly a good hash table for the appropriate IP prefixes
hardness=
idea=obtaining good hash tables based on using multiple hashes of each input key (which is an IP address). The methods we describe are fast, simple, scalable, parallelizable, and flexible.  In particular, in instances where the goal is to have one hash bucket fit into a cache line, using multiple hashes proves extremely suitable
future=
comment=
other=the original idea of d-left hashing
---
id=143
title=Fast Sorted-Set Intersection using SIMD Instructions
author=Benjamin Schlegel
journal=Accelerating Data Management Systems using Modern Processor and Storage Architectures(ADMS)
year=2011
tags=sorted-set Intersection, SIMD
star=***
problem=
interest=
hardness=
idea=our algorithm requires more comparisons but less instructions than scalar algorithms that translates into a better overall speed. We achieve this by utilizing efficient single-instruction-multiple-data (SIMD) instructions that are available in many processors. We provide different sorted-set intersection algorithms for different integer data types. We propose versions that use uncompressed integer values as input and output as well as a version that uses a tailor-made data layout for even faster intersections
future=
comment=
other=
---
id=144
title=GPU merge path: a GPU merging algorithm
author=Green Oded
journal=Proceedings of the 26th ACM international conference on Supercomputing
year=2012
tags=Parallel algorithms, Parallel systems, Graphics processors, Measurement of multiple-processor systems, GPU merge path, merge-intersection, merge union operation
star=***
problem=compute the union of A and B
interest=
hardness=
idea=GPU partition stage and merge stage, load balance among SMs
future=
comment=
other=Our implementation is 10X faster than the fast parallel merge supplied in the CUDA Thrust library
---
id=145
title=Efficient Lists Intersection by CPU-GPU Cooperative Computing
author=Di Wu
journal=Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)
year=2010
tags=list Intersection, CPU-GPU Cooperative computing
star=***
problem=
interest=
hardness=
idea=a CPU-GPU cooperative model that can integrate the computing power of CPU and GPU to perform lists intersection more efficiently. In the so-called synchronous mode, queries are grouped into batches and processed by GPU for high throughput. We design a query-parallel GPU algorithm based on an element-thread mapping strategy for load balancing. In the traditional asynchronous model, queries are processed one-byone by CPU or GPU to gain perfect response time. We design an online scheduling algorithm to determine whether CPU or GPU processes the query faster. Regression analysis on a huge number of experimental results concludes a regression formula as the scheduling metric
future=
comment=
other=
---
id=146
title=A New Data Layout For Set Intersection on GPUs
author=Rasmus Resen Amossen
journal=IEEE International Parallel & Distributed Processing Symposium
year=2011
tags=Set intersection, Frequent itemset mining, Sparse boolean matrix multiplication, Data layout, GPU, BATMAP
star=***
problem=Set intersection is the core in a variety of problems, e.g. frequent itemset mining and sparse boolean matrix multiplication.
interest=It is well-known that large speed gains can, for some computational problems, be obtained by using a graphics processing unit (GPU) as a massively parallel computing device.
hardness=GPUs require highly regular control flow and memory access patterns, and for this reason previous GPU methods for intersecting sets have used a simple bitmap representation. This representation requires excessive space on sparse data sets
idea=a novel data layout, BATMAP, that is particularly well suited for parallel processing, and is compact even for sparse data.
future=
comment=Frequent itemset mining is one of the most important applications of set intersection. As a case-study on the potential of BATMAPs we focus on frequent pair mining, which is a core special case of frequent itemset mining. The main finding is that our method is able to achieve speedups over both Apriori and FP-growth when the number of distinct items is large, and the density of the problem instance is above 1%. Previous implementations of frequent itemset mining on GPU have not been able to show speedups over the best single-threaded implementations.
other=limitation of batmaps compared to bitmaps: the result of combining two batmaps is not a batmap, so it cannot directly support the intersection of more than two sets.
---
id=147
title=Distributed Power-law Graph Computing: Theoretical and Empirical Analysis
author=Cong Xie, Zhihua Zhang
journal=NIPS(CCF A+ conference of AI)
year=2014
tags=degree-based graph partitioning, distributed power-law graph computing, Theoretical and Empirical analysis, DBH(degree-based hashing)
star=*****
problem=machine learning based on distributed graph-computing (DGC) frameworks has attracted much attention from big data machine learning community
interest=In DGC frameworks, the graph partitioning (GP) strategy plays a key role to affect the performance, including the workload balance and communication cost.
hardness=the degree distributions of natural graphs from real applications follow skewed power laws, which makes GP a challenging task. Recently, many methods have been proposed to solve the GP problem. However, the existing GP methods cannot achieve satisfactory performance for applications with power-law graphs.
idea=a novel vertex-cut method, called degree-based hashing (DBH), for Graph Partitioning. DBH makes effective use of the skewed degree distributions for GP. We theoretically prove that DBH can achieve lower communication cost than existing methods and can simultaneously guarantee good workload balance
future=
comment=
other=
---
id=148
title=Tiles: A New Language Mechanism for Heterogeneous Parallelism
author=Yifeng Chen
journal=PPoPP(workshop)
year=2015
tags=Languages, Performance, concurrent programming structures, language constructs and features
star=****
problem=
interest=
hardness=
idea=This paper studies the essence of heterogeneity from the perspective of language mechanism design. The proposed mechanism, called tiles, is a program construct that bridges two relative levels of computation: an outer level of source data in larger, slower or more distributed memory and an inner level of data blocks in smaller, faster or more localized memory
future=
comment=
other=
---
id=149
title=PARRAY: A Unifying Array Representation for Heterogeneous Parallelism
author=Yifen chen
journal=PPoPP
year=2012
tags=PARRAY(Parallelizing ARRAYs), Parallel Programming, Array Representation, Heterogeneous Parallelism, GPU Cluster, Programming interface
star=****
problem=The current practice of software development requires combin- ing several low-level libraries like Pthread, OpenMP, CUDA and MPI.
interest=
hardness=Achieving productivity and portability is hard with different numbers and models of GPUs.
idea=PARRAY extends mainstream C programming with novel array types of the following features: 1) the dimensions of an array type are nested in a tree structure, conceptually reflecting the memory hierarchy; 2) the definition of an array type may contain references to other array types, allowing sophisticated array types to be created for parallelization; 3) threads also form arrays that allow programming in a Single-Program-Multiple-Codeblock (SPMC) style to unify various sophisticated communication patterns.
future=
comment=This leads to shorter, more portable and maintainable parallel codes, while the programmer still has con- trol over performance-related features necessary for deep manual optimization.
other=
---
id=150
title=Large-Scale FFT on GPU Clusters
author=Yifeng Chen
journal=ICS(International Conference on Supercomputing), CCF B Conference of Architecture area
year=2010
tags=FFT, GPU Clusters, Array Dimensions
star=***
problem=how to achieve substantial speedups for these more challenging tasks on a GPU cluster.
interest=Excellent acceleration is achievable for computation-intensive tasks (e.g. matrix multiplication and LINPACK) and bandwidth-intensive tasks with data locality (e.g. finite-difference simulation).
hardness=Bandwidth-intensive tasks such as large-scale FFTs without data locality are harder to accelerate, as the bottleneck often lies with the PCI between main memory and GPU device memory or the communication network be- tween workstation nodes. That means optimizing the performance of FFT for a single GPU device will not improve the overall performance.
idea=
future=
comment=
other=
---
id=151
title=S-PowerGraph: Streaming Graph Partitioning for Natural Graphs by Vertex-Cut
author=Cong Xie, Zhihua Zhang
journal=arXiv
year=2015
tags=streaming graph partitioning, natural graphs, vertex cut
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=152
title=NOVA: A Novel and Efficient Framework for Finding Subgraph Isomorphism Mappings in Large Graphs
author=
journal=
year=
tags=Subgraph Isomorphism, large graph
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=153
title=SAPPER: Subgraph Indexing and Approximate Matching in Large Graphs
author=Shijie Zhang
journal=VLDB
year=2010
tags=SAPPER, subgraph indexing, Approximate matching, large graphs, edit distance
star=****
problem=Due to the existence of noise (e.g., missing edges) in the large database graph, we investigate the problem of approximate subgraph indexing, i.e., finding the occurrences of a query graph in a large database graph with (possible) missing edges
interest=
hardness=
idea=Utilizing the hybrid neighborhood unit structures in the index, SAPPER takes advantage of pre-generated random spanning trees and a carefully designed graph enumeration order.
future=
comment=
other=
---
id=154
title=GADDI: Distance Index based Subgraph Matching in Biological Networks
author=Shijie Zhang
journal=EDBT
year=2009
tags=GADDI, Distance Index based Subgraph Matching, Biological Networks
star=***
problem=finding all the matches of a query graph in a given large graph of thousands of vertices, which is a very important task in many biological applications
interest=
hardness=
idea=a novel distance measurement which reintroduces the idea of frequent substructures in a single large graph. We devise the novel structure distance based approach (GADDI) to efficiently find matches of the query graph. GADDI is further optimized by the use of a dynamic matching scheme to minimize redundant calculations
future=
comment=
other=Most of the previous work focuses on indexing a set of small or medium sized database graphs (with only tens of vertices) and finding whether a query graph occurs in any of these
---
id=155
title=An In-depth Comparison of Subgraph Isomorphism Algorithms in Graph Databases  (survey, experimental paper)
author=Jinsoo Lee, Wook-Shin Han(the teacher)
journal=VLDB
year=2012
tags=Empirical analysis, NP-hard, Subgraph Isomorphism, graph databases, signature-based filtering, join order selection, survey
star=****
problem=they have not been empirically compared one another in most research work, it is not clear whether the later work outperforms the earlier work. Another problem is that reported comparisons were often done using the original authors’ binaries which were written in different programming environments
interest=many algorithms have been proposed to solve it in a reasonable time for real datasets using different join orders, pruning rules, and auxiliary neighborhood information.
hardness=
idea=we address these serious problems by re-implementing five state-of-the-art subgraph isomorphism algorithms in a common code base and by comparing them using many real-world datasets and their query loads.
future=
comment=Although there is no single winner for all experiments, to our surprise, QuickSI, the algorithm designed for handling small graphs, performs the best for many queries for both small and large data graphs (the AIDS and YEAST datasets) since the cost of its recursive call is the lowest.  QuickSI, VF2, and GADDI failed to find embeddings in trees (the NASA set) in a reasonable time, showing exponential behavior due to serious problems in their join order selection. GADDI shows very bad performance for many queries tested due to expensive NDS distance calculation and lowest pruning power. GraphQL is the only algorithm that completed all queries tested, although it is slower than QuickSI for most queries. SPath almost performed worse than GraphQL due to its large SPath neighborhood signature overhead and the serious problem in its join order selection.  We also note that all existing algorithms had problems in their join order selections, and signature-based pruning is only effective for some datasets. This calls for new subgraph algorithms which exploit both good join order selection and selective signature-based pruning.
other=Ullmann, VF2, QuickSI, GraphQL, SPath, GADDI
---
id=156
title=Combinatorial Optimization on Graphs of Bounded Treewidth
author=
journal=The Computer Journal
year=2008
tags=Combinatorial Optimization, graphs of bounded treewidth
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=157
title=A Dynamic Programming Framework for Combinatorial Optimization Problems on Graphs with Bounded Pathwidth
author=
journal=arXiv
year=2008
tags=dynamic programming, Combinatorial Optimization, graphs of bounded pathwidth
star=
problem=an algorithmic framework for solving a class of combinatorial optimization problems on graphs with bounded pathwidth
interest=The problems are NP-hard in general, but solvable in linear time on this type of graphs. The problems are relevant for assessing network reliability and improving the network’s performance and fault tolerance
hardness=
idea=dynamci programming
future=
comment=
other=
---
id=158
title=dynamic programming on Graphs with Bounded Treewidth
author=Hans L. Bodlaender
journal=International Colloquium on Automata, Languages, and Programming
year=1988
tags=dynamic programming, graphs with bounded Treewidth, partial k-trees, graph decision problems, restrictions of NP-complete problems, polynomial time algorithms, local condition compositions, C-LCC, C-ECC
star=*****
problem=the complexity of graph decision problems, restricted to the class of graphs with treewidth<=k.
interest=
hardness=
idea=
future=
comment=for several NP-complete problems, and subclasses of the graphs with bounded treewidth, polynomial algorithms have been obtained.
other=
---
id=159
title=A Complete Anytime Algorithm for Treewidth
author=
journal=Proceedings of the 20th conference on Uncertainty in artificial intelligence(AUAI Press)
year=2004
tags=Treewidth computation
star=***
problem=we present a Branch and Bound algorithm called QuickBB for computing the treewidth of an undirected graph.
interest=
hardness=
idea=This algorithm performs a search in the space of perfect elimination ordering of vertices of the graph. The algorithm uses novel prun- ing and propagation techniques which are derived from the theory of graph minors and graph isomorphism. We present a new algorithm called minor-min-width for computing a lower bound on treewidth that is used within the branch and bound algo- rithm and which improves over earlier available lower bounds.
future=
comment=QuickBB also has good anytime performance, being able to generate a bet- ter upper bound on treewidth of some graphs whose optimal treewidth could not be computed up to now.
other=
---
id=160
title=Diameter and Treewidth in Minor-Closed Graph Families
author=David Eppstein
journal=arXiv
year=1999
tags=diameter, treewidth, minor-closed graph families
star=***
problem=We investigate the extent to which similar relations hold in other graph families.
interest=
hardness=
idea=treewidth is bounded by a function of the diameter in a minor-closed family, if and only if some apex graph does not belong to the family. In particular, the O(D) bound above can be extended to bounded-genus graphs
future=we extend several approximation algorithms and exact subgraph isomorphism algorithms from planar graphs to other graph families.
comment=
other=It is known that any planar graph with diameter D has treewidth O(D), and this fact has been used as the basis for several planar graph algorithms
---
id=161
title=Weighted Treewidth: Algorithmic Techniques and Results
author=Emgad Bachoore, Hans L. Bodlaender
journal=International Symposium on Algorithms and Computation
year=2007
tags=weighted Treewidth
star=***
problem=From the analysis of algorithms for probabilistic networks, it is known that a tree decomposition of the minimum treewidth may not be optimal for these algorithms
interest=
hardness=Instead of treewidth, we consider therefore the weighted treewidth of a weighted graph.
idea=we present a number of heuristics for determining upper and lower bounds on the weighted treewidth, and a branch and bound algorithm for finding the exact weighted treewidth for weighted graphs.
future=
comment=
other=
---
id=162
title=Subgraph Isomorphism in Planar Graphs and Related Problems
author=David Eppstein
journal=Journal of Graph Algorithms and Applications
year=1999
tags=Subgraph Isomorphism, Planar graphs
star=
problem=solve the subgraph isomorphism problem in planar graphs in linear time, for any pattern of constant size.
interest=
hardness=
idea=partitioning the planar graph into pieces of small tree-width, and applying dynamic programming within each piece.
future=The same methods can be used to solve other planar graph problems including connectivity, diameter, girth, induced subgraph isomorphism, and shortest paths.
comment=
other=
---
id=163
title=GStream: a graph streaming processing method for large-scale graphs on GPUs
author=
journal=PPoPP(Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming)
year=2015
tags=gstream, graph streaming processing, large-scale graph, GPUs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=164
title=Finding Top-k Min-Cost Connected Trees in Databases
author=Bolin Ding, Jeffery Xu Yu, Shan Wang, Lu Qin, Xiao Zhang, Xuemin Lin
journal=ICDE(CCF A conference)
year=2007
tags=databases, top-k min-cost connected trees, steiner trees
star=****
problem=processing a l-keyword query against a relational database which can be modeled as a weighted graph
interest=the integration of database and information retrieval techniques will provide users with a wide range of high quality services
hardness=
idea=finding top-k minimum cost connected trees that contain at least one node in every subset Vi, and denote our problem as GST-k. When k = 1, it is known as a minimum cost group Steiner tree problem which is NP-Complete.
future=Our solution can handle graphs with a large number of nodes. OurGST-1 solution can be easily extended to support GST-k, which outperforms the existing GST-k solutions over both weighted undirected/directed graphs.
comment=The theory is beautiful but the experimental result is not so good; why the bound of iterration is the diameter?; why require the intersection of P1 and P2 is empty? does it influence the correctness, the efficiency? why the complexity is 3^l(for each label x, x has 3 possibilities, in P1 , in P2, or not in P1 and P2), if allowing overlapping between P1 and P2, does complexity change?
other=steiner tree: https://blog.csdn.net/wu_tongtong/article/details/78992913
---
id=165
title=Universal classes of hash functions
author=
journal=Journal of computer and system sciences
year=1979
tags=hash functions, theorectical bound
star=*****
problem=
interest=
hardness=
idea=an input independent average linear time Algorithm for storage and retrieval on keys
future=
comment=the ability to analyze the cost of storage and retrieval without worrying about the distribution of the input allows as corollaries improvements on the bounds of several Algorithms
other=hash functions:  https://en.wikipedia.org/wiki/Hash_function
---
id=166
title=A Comparative Experimental Study of Hash Functions Applied to Packet Sampling
author=
journal=Proc. of International Teletraffic Congress (ITC)
year=2005
tags=Network monitoring, Traffic measurements, Hash functions, Packet sampling
star=***
problem=Traffic measurements in high-speed links are challenging and risk introducing prohibitive costs in the monitoring infrastructure
interest=Packet sampling is an established technique to make these network measurements feasible. Hash based packet sampling is a technique that, in addition, enables new applications, like trajectory sampling and One Way Delay estimation, provided that the same hash function is used in all measurement points
hardness=Such applications require that the used hash functions have specific properties: uniformity of distribution, computation speed, and low collision probability. 
idea=a methodology for hash function comparison and related test results, which have been contributed to the IETF PSAMP (Packet SAMPling) working group.
future=
comment=
other=
---
id=167
title=Revisiting Co-Processing for Hash Joins on the Coupled CPU-GPU Architecture
author=Jiong He, Mian Lu, Bingsheng He
journal=VLDB
year=2013
tags=CoProcessing, hash join, coupled CPU-GPU Architecture(APU)
star=****
problem=hash joins, one of the most important join algorithms for main memory databases, on a coupled CPU-GPU architecture.(the fine-grained co-processing mechanisms on hash joins with and without partitioning.)
interest=Query co-processing on graphics processors (GPUs) has be- come an effective means to improve the performance of main memory databases.
hardness=the relatively low bandwidth and high latency of the PCI-e bus are usually bottleneck issues for co-processing.
idea=(1) the coupled architecture enables fine-grained co-processing and cache reuses, which are ineffi- cient on discrete CPU-GPU architectures; (2) the cost model can automatically guide the design and tuning knobs in the design space; (3) fine-grained co-processing achieves up to 53%, 35% and 28% performance improvement over CPU- only, GPU-only and conventional CPU-GPU co-processing, respectively
future=
comment=the strategy of dividing work of building hash table achieves wonderful balance on cpu-gpu; for hash-join, the big table will be divided called tiling method, and each tile is handled by a single kernel instead a kernel for all
other=coupled CPU-GPU architectures have received a lot of attention, e.g. AMD APUs with the CPU and the GPU integrated into a single chip.(coupled GPU usually less cores and lower latency than discrete GPU like Nvidia)
---
id=168
title=Local Algorithms for Hierarchical Dense Subgraph Discovery
author=
journal=VLDB
year=2019
tags=local Algorithms, h-index, dense subgraph, k-core, k-truss, nucleus decomposition
star=****
problem=Finding the dense regions of a graph and relations among them is a fundamental problem in network analysis
interest=Core and truss decompositions reveal dense subgraphs with hierarchical relations. The incremental nature of algorithms for computing these decompositions and the need for global information at each step of the algorithm hinders scalable parallelization and approximations since the densest regions are not revealed until the end
hardness=
idea=This work generalizes the iterative h-index computation for truss decomposition as well as nucleus decomposition which leverages higher-order structures to generalize core and truss decompositions. In addition, we prove convergence bounds on the number of iterations. We present a framework of local algorithms to obtain the core, truss, and nucleus decompositions.
future=
comment=Our algorithms are local, parallel, oㄦ high scalability, and enable approximations to explore time and quality trade-oṡ Our shared-memory implementation verifies the Exploringciency, scalability, and ectiveness of our local algorithms on real-world networks.
other=
---
id=169
title=Query Log Compression for Workload Analytics
author=
journal=VLDB
year=2019
tags=LOGR, query log Compression, Workload analytics, database, pattern mixture, log encodings,  information-theoretic bounds
star=****
problem=Analyzing database access logs is a key part of performance tuning, intrusion detection, benchmark development, and many other database administration tasks.
interest=
hardness=it is common for production databases to deal with millions or more queries each day, so these logs must be summarized before they can be used. Designing an appropriate summary encoding requires trading off between conciseness and information content; simple workload sampling may miss rare, but high impact queries
idea=LogR, a lossy log compression scheme suitable for use in many automated log analytics tools, as well as for human inspection. We formalize and analyze the space/fidelity trade-off in the context of a broader family of “pattern” and “pattern mixture” log encodings to which LogR belongs
future=
comment=We show through a series of experiments that LogR compressed encodings can be created efficiently, come with provable information-theoretic bounds on their accuracy, and outperform state-of-art log summarization strategies.
other=
---
id=170
title=Scalable Join Processing on Very Large RDF Graphs
author=
journal=SIGMOD
year=2009
tags=large RDF graph, join algorithm, query processing, Sideways Information Passing(SIP)
star=****
problem=
interest=the fine-grained and schema-relaxed use of RDF often entails star- and chain-shaped join queries with many input streams from index scans.
hardness=
idea=develop very light-weight methods for sideways information passing between separate joins at query run-time, to provide highly ective filters on the input streams of joins; improve previously proposed algorithms for join-order optimization by more accurate selectivity estimations for very large RDF graphs.
future=
comment=
other=implemented on open-source RDF-3x; We performed cold-cache experiments by dropping all file-system caches before restarting the various systems and running the queries. We repeated this procedure ten times and measured the average execution time and the standard deviation for each query (notation: meandeviation). For warm-cache experiments we ran the queries ten times without dropping the caches.
---
id=171
title=Hornet: An efficient data structure for dynamic sparse graphs and matrices on GPUs
author=
journal=HPEC
year=2018
tags=hornet, hornetsnest, graph data structure, dynamic sparse graphs and matrices, GPU, CSR, B+ tree, graph algorithms(bfs, sssp...)
star=****
problem=
interest=
hardness=
idea=
future=
comment=improvement of CSR and support high rate updates; better sssp performance than Gunrock(>nvgraph)
other=
---
id=172
title=Analyzing CUDA workloads using a detailed GPU simulator(gpgpu-sim)
author=
journal=IEEE International Symposium on Performance Analysis of Systems and Software
year=2009
tags=gpgpu-sim
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=173
title=SketchML: Accelerating Distributed Machine Learning with Data Sketches
author=
journal=SIGMOD
year=2018
tags=Distributed Machine Learning, Stochastic Gradient Descent, Quantification, Quantile Sketch, Frequency Sketch,probabilistic data structure
star=****
problem=is there a compression method that can efficiently handle a sparse and nonuniform gradient consisting of key-value pairs?
interest=Since many distributed ML algorithms trained by stochastic gradient descent (SGD) involve communicating gradients through the network, it is important to compress the transferred gradient
hardness=A category of low-precision algorithms can significantly reduce the size of gradients, at the expense of some precision loss.existing low-precision methods are not suitable for many cases where the gradients are sparse and nonuniformly distributed
idea=quantile-bucket quantification method that uses a quantile sketch to sort gradient values into buckets and encodes them with the bucket indexes; To further compress the bucket indexes, our second contribution is a sketch algorithm, namely MinMaxSketch.  MinMaxSketch builds a set of hash tables and solves hash collisions with a MinMax strategy;delta-binary encoding method that calculates the increment of the gradient keys and stores them with fewer bytes
future=
comment=the first effort combining data sketch with ML
other=
---
id=174
title=Single-pass Parallel Prefix Scan with Decoupled Look-back
author=Duane Merrill, Michael Garland
journal=NVIDIA Technical Report, funding from the Defense Advanced Research Projects Agency (DARPA)
year=2013
tags=CUB(cuda unbounded),NVlabs(Nvidia Research),prefix sum,prefix scan
star=****
problem=a work-efficient, communication-avoiding, single-pass method for the parallel computation of prefix scan
interest=
hardness=
idea=2n data movement,embodies a decoupled look-back strategy that performs redundant work to dissociate local computation from the latencies of global prefix propagation
future=
comment=the single-pass nature of our method allows it to be adapted for (1) in-place compaction behavior, and (2) in-situ global allocation within computations that oversubscribe the processor
other=this is the paper of CUB(cuda unbounded)
---
id=175
title=GPU LSM: A Dynamic Dictionary Data Structure for the GPU
author=Saman Ashkiani, Shengren Li, John D. Owens
journal=IPDPS
year=2018
tags=GPU, dynamic dictionary data structure, Log Structured Merge tree(LSM), dynamic graph, stream updates, LSM on GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=GPU LSM is the first dynamic general-purpose dictionary data structure for the GPU.The trade-off for the dynamic updates is that the sorted array is almost twice as fast on retrievals
other=an implementation of LSM on GPU
---
id=176
title=The Log-Structured Merge-Tree (LSM-Tree)
author=
journal=
year=1996
tags=LSM-Tree
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=177
title=Cache-oblivious streaming B-trees
author=
journal=
year=2007
tags=B-tree, Cache-oblivious
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=178
title=Algorithmic Complexity of Power Law Networks
author=Paweł Brach
journal=SODA(ACM-SIAM Symposium on Discrete Algorithms), CCF B conference of computer science theory area
year=2016
tags=Algorithm complexity, power law graph
star=****
problem=
interest=the majority of real-world networks are scale-free and follow power law degree distribution. The aim of this paper is to study the algorithmic complexity of such “typical” networks
hardness=
idea=
future=
comment=
other=
---
id=179
title=Computing Machinery and Intelligence
author=Alan M Turing
journal=Mind
year=1950
tags=Turing Test, computing Machinery, artificial Intelligence
star=*****
problem=what is Intelligence
interest=
hardness=
idea=
future=
comment=
other=this the origin of famous Turing Test
---
id=180
title=LESSONS LEARNED FROM CLAUDE SHANNON
author=Robert G. Gallager
journal=
year=1998
tags=Claude Shannon, Lessons
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=181
title=First Draft Report on the EDVAC
author=John von Neumann
journal=
year=1945
tags=EDVAC, computer design, computer architecture, computing machine
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=this is the origin idea and design of computers by Von Neumann
---
id=182
title=Parallel Graph Coloring with Applications to the Incomplete-LU Factorization on the GPU 
author=Maxim Naumov (NVIDIA)
journal=Nvidia Technical Report
year=2015
tags=MKL, graph coloring,Incomplete-LU Factorization, GPU, Algorithms and Numerical Methods,High Performance Computing
star=***
problem=
interest=
hardness=
idea=implement graph coloring based on different heuristics and showcase their performance on the GPU. We also present a comprehensive comparison of level-scheduling and graph coloring approaches for the incomplete-LU factorization and triangular solve
future=
comment=incomplete-LU factorization based on graph coloring can achieve a speedup of almost 8x on the GPU over the reference MKL implementation on the CPU
other=
---
id=183
title=Parallel Complexity of Forward and Backward Propagation 
author=Maxim Naumov (NVIDIA)
journal=Nvidia Technical Report
year=2017
tags=Algorithms and Numerical Methods,Machine Learning and Artificial Intelligence, Forward and Backward Propagation, parallel Complexity
star=****
problem=
interest= the forward and backward propagation can be formulated as a solution of lower and upper triangular systems of equations.
hardness=For standard feedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems are always block bi-diagonal, while for a general computation graph (directed acyclic graph) they can have a more complex triangular sparsity pattern.
idea=We discuss direct and iterative parallel algorithms that can be used for their solution and interpreted as different ways of performing model parallelism. Also, we show that for FNNs and RNNs with k layers and t time steps the backward propagation can be performed in parallel in O(log k) and O(log k log t) steps, respectively. Finally, we outline the generalization of this technique using Jacobians that potentially allows us to handle arbitrary layers.
future=
comment=
other=
---
id=184
title=Parallel Jaccard and Related Graph Clustering Techniques 
author=Alexandre Fender (NVIDIA)
journal=Proceedings of the 8th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems (ScalA '17)')
year=2017
tags=Algorithms and Numerical Methods, High Performance Computing, Machine Learning and Artificial Intelligence, Jaccard, graph Clustering
star=***
problem=generalize Jaccard and related measures, often used as similarity coefficients between two sets. We define Jaccard, Dice-Sorensen and Tversky edge weights on a graph and generalize them to account for vertex weights
interest=
hardness=
idea=develop an efficient parallel algorithm for computing Jaccard edge and PageRank vertex weights. We highlight that the weights computation can obtain more than 10x speedup on the GPU versus CPU on large realistic data sets. Also, we show that finding a minimum balanced cut for modified weights can be related to minimizing the sum of ratios of the intersection and union of nodes on the boundary of clusters
future=
comment=the novel weights can improve the quality of the graph clustering by about 15% and 80% for multi-level and spectral graph partitioning and clustering schemes, respectively.
other=
---
id=185
title=Parallel Depth-First Search for Directed Acyclic Graphs 
author=Maxim Naumov (NVIDIA)
journal=NVIDIA Technical report
year=2017
tags=High Performance Computing, dorected Acyclic graph, parallel depth-first search(dfs)
star=***
problem=
interest=Depth-First Search (DFS) is a pervasive algorithm, often used as a building block for topological sort, connectivity and planarity testing, among many other applications
hardness=
idea=We propose a novel work-efficient parallel algorithm for the DFS traversal of directed acyclic graph (DAG). The algorithm traverses the entire DAG in a BFS-like fashion no more than three times. As a result it finds the DFS pre-order (discovery) and post-order (finish time) as well as the parent relationship associated with every node in a DAG
future=
comment=We analyse the runtime and work complexity of this novel parallel algorithm
other=its CUDA implementation on the GPU outperforms sequential DFS on the CPU by up to 6x in our experiments.
---
id=186
title=A Dynamic Hash Table for the GPU
author=Saman Ashkiani, John D. Owens
journal=arXiv
year=2018
tags=dynamic hash table, GPU, dynamic memory allocation on GPU
star=***
problem=fully concurrent dynamic hash table for GPUs with comparable performance to the state of the art static hash tables
interest=
hardness=
idea=warp-cooperative work sharing strategy that reduces branch divergence and provides an efficient alternative to the traditional way of per-thread (or per-warp) work assignment and processing. By using this strategy, we build a dynamic nonblocking concurrent linked list, the slab list, that supports asynchronous, concurrent updates (insertions and deletions) as well as search queries. We use the slab list to implement a dynamic hash table with chaining (the slab hash). We also design a warp-synchronous dynamic memory allocator, SlabAlloc, that suits the high performance needs of the slab hash.
future=
comment=
other=this paper talks about dynamic memory allocation on GPU and give a survey
---
id=187
title=DUALSIM: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine
author=Kim H, Lee J, Wook-Shin Han(the teacher)
journal=International Conference on Management of Data. ACM.
year=2016
tags=parallel subgraph Enumeration, single machine, DUALSIM
star=***
problem=Can subgraph enumeration be done disk-based, on a single machine in a way that is scalable and efficient?
interest=used in network motif discovery, graphlet kernel computation, subgraph frequency(frequent patterns)
hardness=Existing methods fail due to exponential partial solutions; Disk access one of costliest bottlenecks; CPU stall also notable bottleneck
idea=DualSim does not maintain explosive partials;Red Black Ivory query graph transformation
future=
comment=
other=
---
id=188
title=TurboGraph: A fast parallel graph engine handling billion-scale graphs in a single PC
author=Wook-Shin Han, Sangyeon Lee
journal=SIGKDD
year=2013
tags=billion-scale graph, single PC, singel machine, parallel graph engine, TurboGraph, bfs, Graph processing, Big data, Parallelism, Pin-and-slide
star=****
problem=a general, disk-based graph engine called TurboGraph to process billion-scale graphs very efficiently by using modern hardware on a single PC; a novel parallel execution model, called pin-andslide.  TurboGraph also provides engine-level operators such as BFS which are implemented under the pin-and-slide model
interest=
hardness=Although GraphChi significantly outperforms all representative (disk-based) distributed graph engines(GBase and Pregel, GraphLab, PowerGraph), we observe that GraphChi still has serious performance problems for many important types of graph queries due to 1) limited parallelism and 2) separate steps for I/O processing and CPU processing
idea=full parallelism including multicore parallelism and FlashSSD IO parallelism; full overlap of CPU processing and I/O processing as much as possible
future=
comment=
other=homepage  https://sites.google.com/a/dblab.postech.ac.kr/postechdblab/home/people/professor-1
---
id=189
title=TurboGraph++: A Scalable and Fast Graph Analytics System
author=Seongyun Ko, Wook-Shin Han
journal=SIGMOD
year=2018
tags=TurboGraph++, distributed  graph analytic system
star=****
problem=a scalable and fast graph analytics system which efficiently processes large graphs by exploiting external memory for scale-up without compromising efficiency
interest=
hardness=Existing distributed graph analytics systems are categorized into two main groups: those that focus on efficiency with a risk of out-ofmemory error and those that focus on scale-up with a fixed memory budget and a sacrifice in performance. While the former group keeps a partitioned graph resident in memory of each machine and uses an in-memory processing technique, the latter stores the partitioned graph in external memory of each machine and exploits a streaming processing technique. Gemini and Chaos are the state-of-the-art distributed graph systems in each group, respectively.
idea=a new graph processing abstraction for efficiently supporting neighborhood analytics that requires processing multi-hop neighborhoods of vertices, such as triangle counting and local clustering coefficient computation, with a fixed memory budget;  a balanced and bufferaware partitioning scheme for ensuring balanced workloads across machines with reasonable cost; leverages three-level parallel and overlapping processing for fully utilizing three hardware resources, CPU, disk, and network, in a cluster
future=
comment=TurboGraph++ is designed to scale well to handle large-scale graphs using 25 machines, like Chaos, while its performance is comparable to Gemini.
other=
---
id=190
title=efficient error recovery for reliable multicast
author=Zhen Xiao (pku teacher)
journal=Cornell University
year=2001
tags=phD graduate paper, distributed system, error recovery
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=the homepage  http://net.pku.edu.cn/vc/index_chinese.php
---
id=191
title=Token-ordered LRU: an effective page replacement policy and its implementation in Linux systems
author=Song Jiang, Xiaodong Zhang(the teacher)
journal=Performance of Evaluation
year=2004
tags=Process thrashing, Global LRU replacement, Load control, Performance evaluation, page replacement policy, Linux systems
star=****
problem=the process thrashing in a single node or a small number of nodes could severely affect other nodes running coordinating processes, even crash the whole system. In this paper, we focus on how to improve the page replacement algorithm running on one node
interest=Most computer systems use a global page replacement policy based on the LRU principle to approximately select a Least Recently Used page for a replacement in the entire user memory space
hardness=During execution interactions, a memory page can be marked as LRU even when its program is conducting page faults. We define the LRU pages under such a condition as false LRU pages because these LRU pages are not produced by program memory reference delays, which is inconsistent with the LRU principle. False LRU pages can significantly increase page faults, even cause system thrashing. This poses a more serious risk in a large parallel systems with distributed memories because of the existence of coordination among processes running on individual node
idea=
future=
comment=
other=homepage of teacher   http://web.cse.ohio-state.edu/~zhang.574/
---
id=192
title=AA-Sort: A New Parallel Sorting Algorithm for Multi-Core SIMD Processors
author=Hiroshi Inoue
journal=International Conference on Parallel Architecture & Compilation Techniques(PACT)
year=2007
tags=simd, sse, avx2, multi-core, parallel sorting
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=193
title=An Efficient Implementation of the Bellman-Ford Algorithm for Kepler GPU Architectures
author=federico Busato
journal=TPDS (CCF A journal)
year=2016
tags=Bellman-Ford, Kepler GPU, SSSP(single-source shortest path), CUDA
star=****
problem=This article presents a parallel implementation of the Bellman-Ford algorithm that exploits the architectural characteristics of recent GPU architectures (i.e., NVIDIA Kepler, Maxwell) to improve both performance and work efficiency
interest=Finding the shortest paths from a single source to all other vertices is a common problem in graph analysis. The Bellman-Ford’s algorithm is the solution that solves such a single-source shortest path (SSSP) problem and better applies to be parallelized for many-core architectures.
hardness=the high degree of parallelism is guaranteed at the cost of low work efficiency, which, compared to similar algorithms in literature (e.g., Dijkstra’s) involves much more redundant work and a consequent waste of power consumption.
idea=different optimizations to the implementation, which are oriented both to the algorithm and to the architecture
future=
comment=
other=
---
id=194
title=Corolla: GPU-Accelerated FPGA Routing Based on Subgraph Dynamic Expansion
author=Minghua Shen, Guojie Luo
journal=FPGA
year=2017
tags=Corolla, gpu, fpga routing, Subgraph dynamic expansion
star=***
problem=the long routing time imposes a barrier on FPGA computing, which signficantly hinders the design produc- tivity. Existing attempts of parallelizing the FPGA routing either do not fully exploit the parallelism or suㄦ from an excessive quality loss. Massive parallelism using GPUs has the potential to solve this issue but faces non-trivial challenges
interest=FPGAs are increasingly popular as application-specific accelerators because they lead to a good balance between fexibility and energy Exploringciency, compared to CPUs and ASICs.
hardness=
idea=Corolla enables applying the GPU-friendly shortest path algorithm in FPGA routing, leveraging the idea of problem size reduction by limiting the search in routing subgraphs. We maintain the convergence after problem size reduction using the dynamic expansion of the routing resource subgraphs. In addition, Corolla explores the fine-grained single-net parallelism and proposes a hybrid approach to combine the static and dynamic parallelism on GPU. To explore the coarse-grained multi-net parallelism, Corolla proposes an ective method to parallelize mutli-net routing while preserving the equivalent routing results as the original single-net routing.
future=
comment=
other=
---
id=195
title=Accelerating Large-Scale Single-Source Shortest Path on FPGA
author=Shijie Zhou
journal=IEEE International Parallel and Distributed Processing Symposium Workshops
year=2015
tags=sssp, fpga, Bellman-Ford, external memory
star=***
problem=large-scale graphs involve millions or even billions of vertices, making efficient parallel graph processing challenging
interest=propose a single-FPGA based design to accelerate SSSP for massive graphs
hardness=graph is stored in external memory, which is more realistic for processing largescale graphs. Using the available external memory bandwidth, our design achieves the maximum data parallelism to concurrently process multiple edges in each clock cycle, regardless of data dependencies.
idea=
future=
comment=
other=
---
id=196
title=An FPGA Implementation for Solving the Large Single-Source-Shortest-Path Problem
author=Guoqing Lei, Yong Dou, Rongchun Li, Fei Xia
journal=IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS—
year=2016
tags=Field-programmable gate arrays (FPGAs), single source shortest path (SSSP), systolic array priority queue (SAPQ), internal memory, Dijkstra
star=***
problem=the existing SSSP implementations on field-programmable gate arrays (FPGAs) are incapable of processing large graphs by storing the graph and results in internal memories
interest=
hardness=
idea=a parallel FPGA implementation to solve the SSSP problem, which is derived from a variant of the “eager” Dijkstra algorithm. In order to process a large graph problem, an extended systolic array priority queue called ExSAPQ is proposed to allow large-scale priority queue processing
future=
comment=
other=
---
id=197
title=LIRS: An Efficient Low Interreference Recency Set Replacement Policy to Improve Buffer Cache Performance
author=Song Jiang, Xiaodong zhang
journal=Acm Sigmetrics Performance Evaluation Review
year=2002
tags=LRU replacement, LIRS, buffer cache Performance, replacement policy
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=198
title=a permutation-based page interleaving scheme to reduce row-buffer conflicts and exploit data locality
author=zhao zhang, Xiaodong Zhang
journal=Proceedings of the 33rd annual ACM/IEEE international symposium on Micro architecture. ACM
year=2000
tags=page interleaving scheme, row-buffer conflicts, data locality
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=The Permutation-based Page Interleaving has been Widely Used in Computers for Fast Memory Accesses 
---
id=199
title=Spark-GPU: an accelerated in-memory data processing engine on clusters
author=Yuan yuan, Xiaodong zhang
journal=IEEE International Conference on Big Data. IEEE
year=2017
tags=gpu, spark, in-memory data processing engine on clusters, Distributed computing
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=200
title=Mega-KV: case for GPUs to maximize the throughput of in-memory key-value stores
author=Kai Zhang, Xiaodong zhang
journal=VLDB
year=2015
tags=in-memory key-value stores, Mega-KV, GPU
star=****
problem=In-memory key-value stores have several unique properties that include (1) data intensive operations de- manding high memory bandwidth for fast data accesses, (2) high data parallelism and simple computing operations de- manding many slim parallel computing units, and (3) a large working set.
interest=In-memory key-value stores play a critical role in data pro- cessing to provide high throughput and low latency data accesses.
hardness=As data volume continues to increase, our ex- periments show that conventional and general-purpose multicore systems are increasingly mismatched to the special properties of key-value stores because they do not provide massive data parallelism and high memory bandwidth; the powerful but the limited number of computing cores do not satisfy the demand of the unique data processing task; and the cache hierarchy may not well benefit to the large working set.
idea=a GPU-based in-memory key-value store system that achieves high per- formance and high throughput. Effectively utilizing the high memory bandwidth and latency hiding capability of GPUs, Mega-KV provides fast data accesses and significantly boosts overall performance.
future=
comment=
other=
---
id=201
title=Concurrent analytical query processing with GPUs
author=Kaibo Wang, Kai zhang, Xiaodong zhang
journal=VLDB
year=2014
tags=GPU, Concurrent query processing
star=****
problem=Sharing GPUs among concurrent queries is not supported, causing serious resource underutilization
interest=Based on the profiling of an open-source GPU query engine running commonly used single- query data warehousing workloads, we observe that the utilization of main GPU resources is only up to 25%. The underutilization leads to low system throughput.
hardness=
idea=To Exploringciently share GPUs among concurrent queries for high throughput, the major challenge is to provide software support to control and resolve resource contention incurred by the sharing. Our solution relies on GPU query scheduling and device memory swapping policies to address this challenge.
future=
comment=
other=
---
id=202
title=On graph query optimization in large networks  (Spath)
author=Peixiang Zhao, Jiawei Han
journal=VLDB
year=2010
tags=SPath,subgraph isomorphism, subgraph matching
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=203
title=Grami: Frequent subgraph and pattern mining in a single large graph
author=Elseidy Mohammed
journal=VLDB
year=2014
tags=frequent subgraph and pattern mining
star=****
problem=Mining frequent subgraphs is an important operation on graphs; it is defined as finding all subgraphs that appear frequently in a database according to a given frequency threshold
interest=
hardness=
idea=
future=
comment=
other=
---
id=204
title=Scalable subgraph enumeration in mapreduce
author=Lai Longbin, Qin L
journal=VLDB
year=2015
tags=subgraph enumeration, MapReduce, Distributed computing, parallel algorithm
star=****
problem=Subgraph enumeration, which aims to find all the subgraphs of a large data graph that are isomorphic to a given pattern graph, is a fundamental graph problem with a wide range of applications
interest=
hardness=
idea=
future=
comment=
other=
---
id=205
title=NScale: neighborhood-centric large-scale graph analytics in the cloud
author=Quamar Abdul, Amol Deshpande
journal=VLDB
year=2016
tags=graph analytics, cloud computing, neighborhood-centric
star=****
problem=There is an increasing interest in executing complex analyses over large graphs, many of which require processing a large number of multi-hop neighborhoods or subgraphs. 
interest=
hardness=
idea=
future=
comment=
other=
---
id=206
title=Taming subgraph isomorphism for RDF query processing  (TurboHom++)
author=Kim Jinha, Wook-Shin Han(the teacher)
journal=VLDB
year=2015
tags=RDF query processing, subgraph isomorphism, subgraph matching, TurboHom++
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=207
title=Durable graph pattern queries on historical graphs
author=Semertzidis Konstantinos
journal=ICDE
year=2016
tags=durable graph pattern matching, historical graphs, subgraph matching
star=****
problem=we focus on labeled graphs that evolve over time. Given a sequence of graph snapshots representing the state of the graph at different time instants, we seek to find the most durable matches of an input graph pattern query
interest=
hardness=
idea=
future=
comment=
other=
---
id=208
title=Functional dependencies for graphs
author=Wenfei Fan, Yinghui wu
journal=Proceedings of the 2016 International Conference on Management of Data. ACM
year=2016
tags=Functional dependencies for graphs
star=****
problem=a class of functional dependencies for graphs, referred to as GFDs. GFDs capture both attribute-value dependencies and topological structures of entities, and subsume conditional functional dependencies (CFDs) as a special case
interest=
hardness=
idea=
future=
comment=
other=
---
id=209
title=Indexing query graphs to speed up graph query processing
author=Wang Jing
journal=EDBT
year=2016
tags=graph query processing, indexing query graphs, historical information
star=***
problem=
interest=Subgraph/supergraph queries although central to graph an-alytics, are costly as they entail the NP-Complete problem of subgraph isomorphism.
hardness=
idea=a fresh solution, the novel principle of which is to acquire and utilize knowledge from the results of previously executed queries
future=
comment=
other=
---
id=210
title=Subgraph matching with set similarity in a large graph database
author=Liang Hong, Lei Zou
journal=TKDE
year=2015
tags=Subgraph matching, set similarity, graph database
star=***
problem=study a subgraph matching with set similarity (SMS2) query over a large graph database, which retrieves subgraphs that are structurally isomorphic to the query graph, and meanwhile satisfy the condition of vertex pair matching with the (dynamic) weighted set similarity
interest=In real-world graphs such as social networks, Semantic Web and biological networks, each vertex usually contains rich information, which can be modeled by a set of tokens or elements.
hardness=
idea=
future=
comment=
other=
---
id=211
title=Diversified top-k subgraph querying in a large graph
author=Zhengwei Yang
journal=In Proceedings of the 2016 International Conference on Management of Data
year=2016
tags=Diversified top-k subgraph querying, subgraph matching
star=***
problem=top-k diversified results are useful since the number of matching subgraphs can be very large
interest=
hardness=
idea=
future=
comment=
other=
---
id=212
title=Efficient and scalable labeled subgraph matching using SGMatch
author=CR Rivero, HM Jamil
journal=Knowledge and Information Systems
year=2017
tags=labeled subgraph matching, SGMatch, subgraph isomorphism
star=***
problem=An open research question is whether graphs can be matched based on parts and local solutions can be combined to reach a global matching
interest=
hardness=
idea=we present an approach based on graph decomposition called SGMatch to match graphs. We represent graphs in smaller units called graphlets and develop a matching technique to leverage this representation. Pruning strategies use a new notion of edge covering called minimum hub cover and metadata, such as statistics and inverted indices, to reduce the number of matching candidates
future=
comment=Our evaluation of SGMatch versus contemporary algorithms, i.e., VF2, GraphQL, QuickSI, GADDI, or SPath, shows that SGMatch substantially improves the performance of current state-of-the-art techniques for larger query graphs with different structures, i.e., cliques, paths or subgraphs.
other=
---
id=213
title=PGX.ISO: parallel and efficient in-memory engine for subgraph isomorphism
author=Raghavan Raman
journal=In Proceedings of Workshop on GRAph Data management Experiences and Systems
year=2014
tags=in-memory, subgraph isomorphism, PGX.ISO, parallel algorithms
star=***
problem=
interest=
hardness=
idea=Graph matching query language GMQL; breadth-first search for better parallelization
future=
comment=
other=the work of Oracle
---
id=214
title=Dualiso: An algorithm for subgraph pattern matching on very large labeled graphs
author=M Saltz
journal=In 2014 IEEE International Congress on Big Data
year=2014
tags=Dualiso, subgraph matching, large labeled graphs
star=***
problem=This paper presents a conceptually simple, memory-efficient, pruning-based algorithm for the subgraph isomorphism problem that outperforms commonly used algorithms on large graphs. The high performance is due in large part to the effectiveness of the pruning algorithm, which in many cases removes a large percentage of the vertices not found in isomorphic matches. 
interest=
hardness=
idea=
future=
comment=
other=
---
id=215
title=Efficient graph computation on hybrid CPU and GPU systems
author=Tao Zhang
journal=the journal of Supercomputing
year=2015
tags=graph computation, hybrid cpu and gpu system, non-distributed computing
star=***
problem=
interest=efficient non-distributed platforms require less hardware resource and can achieve better energy efficiency than distributed ones
hardness=Although distributed graph engines such as GBase and Pregel handle billion-scale graphs, users need to be skilled at managing and tuning a distributed system in a cluster, which is a non-trivial job for ordinary users. Furthermore, these distributed systems need many machines in a cluster in order to provide reasonable performance
idea=a general, disk-based graph engine called gGraph to process billion-scale graphs efficiently by utilizing both CPUs and GPUs in a single PC. GGraph exploits full parallelism and full overlap of computation and I/O processing as much as possible
future=
comment=Experiment results show that gGraph outperforms GraphChi and PowerGraph. In addition, gGraph achieves the best energy efficiency among all evaluated platforms.
other=
---
id=216
title=A review on algorithms for maximum clique problems
author=Qinghua Wu, jin-Kao Hao
journal=European Journal of Operational Research
year=2015
tags=maximum clique, Experimental paper, review, survey
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=217
title=Finding the maximum clique in massive graphs
author=Can Lu, Jeffrey Xu Yu(the teacher), Hao Wei, Yikai Zhang
journal=VLDB
year=2017
tags=maximum clique, massive graphs, randomized graph algorithm
star=****
problem=algorithms designed for the maximum clique problem are expensive to deal with real-world networks
interest=the maximum clique problem is known to have direct applications in various fields, such as community search in social networks and social media, team formation in expert networks, gene expression and motif discovery in bioinformatics and anomaly detection in complex networks, revealing the structure and function of networks
hardness=
idea=devise a randomized algorithm for the maximum clique problem. Different from previous algorithms that search from each vertex one after another, our approach RMC, for the randomized maximum clique problem, employs a binary search while maintaining a lower bound and upper bound of w(G)
future=
comment=
other=homepage   http://www.se.cuhk.edu.hk/research/information.html#4 ;   diverse relaxations of clique are mentioned in this paper: quasi-clique, k-core, k-edge-connectivity, dense subgraph.
---
id=218
title=FAST: Fast Architecture Sensitive Tree Search on Modern CPUs and GPUs
author=Changkyu Kim (Throughput Computing Lab, Intel Corporation)
journal=SIGMOD
year=2010
tags=FAST, Architecture sensitive tree search, binary search, GPU, CPU, SIMD(SSE, AVX2), cache-friendly
star=****
problem=FAST, an extremely fast architecture sensitive layout of the index tree
interest=In-memory tree structured index search is a fundamental database operation. Modern processors provide tremendous computing power by integrating multiple cores, each with wide vector units. There has been much work to exploit modern processor architectures for database primitives like scan, sort, join and aggregation.
hardness=unlike other primitives, tree search presents significant challenges due to irregular and unpredictable data accesses in tree traversal
idea=FAST is a binary tree logically organized to optimize for architecture features like page size, cache line size, and SIMD width of the underlying hardware. FAST eliminates impact of memory latency, and exploits thread-level and datalevel parallelism on both CPUs and GPUs to achieve 50 million (CPU) and 85 million (GPU) queries per second, 5X (CPU) and 1.7X (GPU) faster than the best previously reported performance on the same architectures. FAST supports efficient bulk updates by rebuilding index trees in less than 0.1 seconds for datasets as large as 64M keys and naturally integrates compression techniques
future=
comment=the key compression technique is very trival and not practical
other=
---
id=219
title=Relatedness-based Multi-Entity Summarization
author=Kalpa Gunaratna
journal=IJCAI  (CCF A conference)
year=2017
tags=Relatedness-based, Multi-Entity Summarization
star=****
problem=
interest=Representing world knowledge in a machine processable format is important as entities and their descriptions have fueled tremendous growth in knowledge-rich information processing platforms, services, and systems. Prominent applications of knowledge graphs include search engines (e.g., Google Search and Microsoft Bing), email clients (e.g., Gmail), and intelligent personal assistants (e.g., Google Now, Amazon Echo, and Apple’s Siri)
hardness=
idea=summarize facts about a collection of entities by analyzing their relatedness in preference to summarizing each entity in isolation. Specifically, we generate informative entity summaries by selecting: (i) inter-entity facts that are similar and (ii) intra-entity facts that are important and diverse. We employ a constrained knapsack problem solving approach to efficiently compute entity summaries
future=
comment=We perform both qualitative and quantitative experiments and demonstrate that our approach yields promising results compared to two other stand-alone state-of-the-art entity summarization approaches
other=
---
id=220
title=FACES: Diversity-Aware Entity Summarization Using Incremental Hierarchical Conceptual Clustering
author=kalpa Gunaratna
journal=AAAI
year=2015
tags=FACES, Diversity-Aware entity Summarization, Incremental Hierarchical Conceptual Clustering
star=****
problem=Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest
interest=Semantic Web documents that encode facts about entities on the Web have been growing rapidly in size and evolving over time.
hardness=
idea=explore automatic summarization techniques that characterize and enable identification of an entity and create summaries that are human friendly. Specifically, we highlight the importance of diversified (faceted) summaries by combining three dimensions: diversity, uniqueness, and popularity.  Our novel diversity-aware entity summarization approach mimics human conceptual clustering techniques to group facts, and picks representative facts from each group to form concise (i.e., short) and comprehensive (i.e., improved coverage through diversity) summaries.
future=
comment=We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization
other=Linking Open Data(LOD)
---
id=221
title=NetLSD: Hearing the Shape of a Graph
author=Anton Tsitsulin
journal=SIGKDD
year=2018
tags=NetLSD, graph property, graph comparison, graph similarity, Laplacian spectrum
star=****
problem=Comparison among graphs is ubiquitous in graph analytics
interest=it is a hard task in terms of the expressiveness of the employed similarity measure and the efficiency of its computation
hardness=Ideally, graph comparison should be invariant to the order of nodes and the sizes of compared graphs, adaptive to the scale of graph patterns, and scalable. Unfortunately, these properties have not been addressed together. Graph comparisons still rely on direct approaches, graph kernels, or representation-based methods, which are all inefficient and impractical for large graph collections.
idea=NetLSD (Network Laplacian Spectral Descriptor), a permutation- and size-invariant, scale-adaptive, and scalably computable graph representation method that allows for straightforward comparisons. NetLSD hears the shape of a graph by extracting a compact signature that inherits the formal properties of the Laplacian spectrum, specifically its heat or wave kernel
future=
comment=NetLSD is the first expressive graph representation that allows for efficient comparisons of large graphs
other=
---
id=222
title=An Optimal and Progressive Approach to Online Search of Top-k Important Communities
author=Fei Bi, Lijun Chang, Xuemin Lin, Wenjie Zhang
journal=VLDB
year=2017
tags=community search, top-k important communities, social network
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=223
title= Efficient String Similarity Search: A Cross Pivotal Based Approach 
author=Fei Bi, Lijun Chang, Wenjie Zhang, Xuemin Lin
journal=DASFAA
year=2015
tags=String Similarity search
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=224
title=Literature Survey on Finding Influential Communities in Large Scale Networks
author=
journal=arXiv
year=2019
tags=Literature survey, Influential Communities, large social networks
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=225
title=Dynamic Top-K Interesting Subgraph Query on Large-Scale Labeled Graphs
author=
journal=School of Information, Liaoning University
year=2019
tags=dynamic top-k, Subgraph query, large-scale labeled graphs
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=226
title=Relaxed Operator Fusion for In-Memory Databases: Making Compilation, Vectorization, and Prefetching Work Together At Last
author=Prashanth Menon, Todd C. Mowry, Andrew Pavlo
journal=VLDB
year=2017
tags=relaxed Operator fusion, in-memory databases, Compilation-Vectorization-Prefetching work together, just-in-time compilation(JIT), relational database, query optimization, SIMD Vectorization, tactful materialization, inter-tuple parallelism
star=****
problem=Because disk accesses are no longer the principle bottleneck in such systems, the focus in designing query execution engines has shifted to optimizing CPU performance.
interest=In-memory database management systems (DBMSs) are a key component of modern on-line analytic processing (OLAP) applications, since they provide low-latency access to large volumes of data
hardness=The state-of-the-art in query compilation is to fuse operators together in a query plan to minimize materialization overhead by passing tuples efficiently between operators
idea=Our empirical analysis shows, however, that more tactful materialization yields better performance.  We present a query processing model called “relaxed operator fusion” that allows the DBMS to introduce staging points in the query plan where intermediate results are temporarily materialized.  This allows the DBMS to take advantage of inter-tuple parallelism inherent in the plan using a combination of prefetching and SIMD vectorization to support faster query execution on data sets that exceed the size of CPU-level caches
future=
comment=Recent systems have revived an older technique of using just-in-time (JIT) compilation to execute queries as native code instead of interpreting a plan
other=
---
id=227
title=A Formal Semantics of SQL Queries, Its Validation, and Applications
author=Paolo Guagliardo, Leonid Libkin(School of Informatics, University of Edinburgh)
journal=VLDB
year=2018
tags=SQL queries, formal Semantics, Validation and Applications, bag Semantics and nulls, SELECT-FROM-WHERE
star=****
problem=While formal semantics of theoretical languages underlying SQL have been provided in the past, they all made simplifying assumptions ranging from changes in the syntax to omitting bag semantics and nulls. This situation is reminiscent of what happens in the field of programming languages, where semantics of formal calculi underlying the main features of languages are abundant, but formal semantics of real languages that people use are few and far between.
interest=
hardness=
idea=We consider the basic class of SQL queries – essentially SELECT-FROM-WHERE queries with subqueries, set/bag operations, and nulls – and define a formal semantics for it, without any departures from the real language. This fragment already requires decisions related to the data model and handling variable names that are normally disregarded by simplified semantics
future=
comment=We give two applications of the semantics. One is the first formal proof of the equivalence of basic SQL and relational algebra that extends to bag semantics and nulls. The other application looks at the three-valued logic employed by SQL, which is universally assumed to be necessary to handle nulls.  We prove however that this is not so, as three-valued logic does not add expressive power: every SQL query in our fragment can be evaluated under the usual two-valued Boolean semantics of conditions.
other=
---
id=228
title=Cloud Computing Applications for Smart Grid: A Survey
author=
journal=TPDS
year=2015
tags=cloud computing Applications, smart grid, survey
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=229
title=Towards Low-Latency Batched Stream Processing by Pre-Scheduling
author=Hai Jin
journal=TPDS
year=2019
tags=Batch Processing Computers, Cluster Computing, Parallel Processing, Scheduling, Task Scheduling, Apache Spark Streaming, Post Scheduling Methods, Batched Stream Processing Jobs, Pre Scheduling Straggler Mitigation Framework, Task Analysis, Batch Production Systems, Sparks, Cloning, Data Models, Fault Tolerance, Fault Tolerant Systems, Stream Processing, Recurring Jobs, Straggler, Scheduling, Data Assignment, Low-Latency batched stream processing, Pre-Scheduling
star=****
problem=In batched stream processing frameworks, straggler, happened due to the uneven task execution time, has been regarded as a major hurdle of latency-sensitive applications. 
interest=Many stream processing frameworks have been developed to meet the requirements of real-time processing. Among them, batched stream processing frameworks are widely advocated with the consideration of their fault-tolerance, high throughput and unified runtime with batch processing.
hardness=Existing straggler mitigation techniques, operating in either reactive or proactive manner, are all post-scheduling methods, and therefore inevitably result in high resource overhead or long job completion time.
idea=We notice that batched stream processing jobs are usually recurring with predictable characteristics. By exploring such a heuristic, we present a pre-scheduling straggler mitigation framework called Lever. Lever first identifies potential stragglers and evaluates nodes' capacity by analyzing execution information of historical jobs. Then, Lever carefully pre-schedules job input data to each node before task scheduling so as to mitigate potential stragglers.
future=
comment=We implement Lever and contribute it as an extension of Apache Spark Streaming. 
other=
---
id=230
title=Online Diagnosis of Performance Variation in HPC Systems Using Machine Learning
author=Ozan Tuncer
journal=TPDS
year=2019
tags=Fault Diagnosis, Feature Extraction, Learning Artificial Intelligence, Parallel Processing, Software Fault Tolerance, Software Performance Evaluation, System Monitoring, Time Series, High Performance Computing Systems, System Monitoring, Performance Anomalies, Time Series Data, Anomaly Signature Extraction, Anomaly Detection, HPC System Resiliency, Shared Resource Contention, Machine Learning, Anomaly Diagnosis, HPC System Performance, Feature Extraction, Measurement, Runtime, Anomaly Detection, Machine Learning, Monitoring, Time Series Analysis, High Performance Computing, Anomaly Detection, Machine Learning, Performance Variation, machine learning, HPC(high-performance computing), Online Diagnosis of Performance variation
star=****
problem=As the size and complexity of high performance computing (HPC) systems grow in line with advancements in hardware and software technology, HPC systems increasingly suffer from performance variations due to shared resource contention as well as software- and hardware-related problems. Such performance variations can lead to failures and inefficiencies, which impact the cost and resilience of HPC systems. 
interest=
hardness=To minimize the impact of performance variations, one must quickly and accurately detect and diagnose the anomalies that cause the variations and take mitigating actions. However, it is difficult to identify anomalies based on the voluminous, high-dimensional, and noisy data collected by system monitoring infrastructures. 
idea= a novel machine learning based framework to automatically diagnose performance anomalies at runtime. Our framework leverages historical resource usage data to extract signatures of previously-observed anomalies. We first convert collected time series data into easy-to-compute statistical features. We then identify the features that are required to detect anomalies, and extract the signatures of these anomalies. At runtime, we use these signatures to diagnose anomalies with negligible overhead
future=
comment=
other=
---
id=231
title=A Distributed Multilevel Force-Directed Algorithm
author=Alessio Arleo
journal=TPDS
year=2019
tags=Cloud Computing, Data Visualisation, Directed Graphs, Distributed Multilevel Force Directed Algorithm, Multi Gi LA, Vertex Centric Computation Paradigm, Apache Giraph, Graph Visualization Algorithm, Cloud Computing, Layout, Force, Partitioning Algorithms, Computational Modeling, Sun, Electronic Mail, Distributed Graph Visualization Algorithms, Visual Analytics, Large And Complex Networks, Force-Directed, Distributed Multilevel Algorithm
star=****
problem=This creates the need of developing efficient and effective algorithms that automatically compute graph layouts
interest=The use of graph visualization approaches to present and analyze complex data is taking a leading role in conveying information and knowledge to users in many application domains.
hardness=force-directed algorithms are arguably among the most popular graph layout techniques. Aimed at leveraging the potential of modern distributed graph algorithms platforms
idea=Multi-GiLA, the first multilevel force-directed graph visualization algorithm based on a vertex-centric computation paradigm. We implemented Multi-GiLA using the Apache Giraph platform. 
future=
comment=
other=
---
id=232
title=Persistent Octrees for Parallel Mesh Refinement through Non-Volatile Byte-Addressable Memory (DPM-octree)
author=Bao Nguyen
journal=TPDS
year=2019
tags=Mesh Generation, Octrees, Parallel Processing, Random Access Storage, In Memory Storage, Multiversion Data Structure, DPM Octree Layout, NVBM Induced Memory, In Memory Octant Recovery, DPM Octree Scales, Mesh Elements, Parallel Mesh Refinement, Nonvolatile Byte Addressable Memory, Adaptive Mesh Refinement, Octree Data Structures, Meshing Algorithms, In Core Algorithms, Out Of Core Algorithms, Distributed Persistent Merged Octree, Fluid Dynamics Simulation, Gerris Software, Erasure Coding, Parity Trees, Feature Directed Sampling Approach, Octrees, Random Access Memory, Data Models, Nonvolatile Memory, Computational Modeling, Three Dimensional Displays, Octree, Adaptive Mesh Refinement, Non Volatile Byte Addressable Memory(NVBM), DPM-octree, Simulation of fluid dynamics
star=****
problem=
interest=Adaptive mesh refinement based on octree data structures has enabled efficient simulations of complex physical phenomena. 
hardness=Existing meshing algorithms were proposed with the assumption that computer memory is volatile. Consequently, for failure recovery, in-core algorithms need to save memory states as snapshots with slow file I/O, while out-of-core algorithms store octants on disk for persistence. However, neither was designed to best exploit the unique characteristics of non-volatile byte-addressable memory (NVBM). 
idea=a novel data structure, the Distributed Persistent Merged octree (DPM-octree), for both meshing and in-memory storage of persistent octrees using NVBM. DPM-octree is a multi-version data structure that can recover from failures using an earlier persistent version stored in NVBM. In addition, we design a feature-directed sampling approach to help dynamically transform the DPM-octree layout for reducing NVBM-induced memory write latency. DPM-octree uses parity trees which are created using erasure coding and stored in NVBM to support low-latency in-memory octant recovery after data loss.
future=
comment=DPM-octree has been successfully integrated with the Gerris software for simulation of fluid dynamics.
other=
---
id=233
title=Effective Extensible Programming: Unleashing Julia on GPUs
author=Tim Besard
journal=TPDS
year=2019
tags=Graphics Processing Units(GPU), High Level Languages, Parallel Architectures, Parallel Programming, Program Compilers, Application Code, High Level Julia Programming Language, GPU Programming, Application Performance, Effective Extensible Programming, Accelerators, Popular Devices, Parallelizable Applications, Efficient Device Code, Low Level Programming Language, High Level Language Ecosystem, Compiler Infrastructure, Existing Programming Language, NVIDIA GP Us, NVIDIA CUDA Toolkit, Graphics Processing Units, Programming, Hardware, High Level Languages, Libraries, Graphics Processors, Very High Level Languages, Code Generation, Retargetable Compilers
star=****
problem=
interest=GPUs and other accelerators are popular devices for accelerating compute-intensive, parallelizable applications. 
hardness=However, programming these devices is a difficult task. Writing efficient device code is challenging, and is typically done in a low-level programming language. High-level languages are rarely supported, or do not integrate with the rest of the high-level language ecosystem. 
idea=compiler infrastructure to efficiently add support for new hardware or environments to an existing programming language. We evaluate our approach by adding support for NVIDIA GPUs to the Julia programming language. By integrating with the existing compiler, we significantly lower the cost to implement and maintain the new compiler, and facilitate reuse of existing application code. Moreover, use of the high-level Julia programming language enables new and dynamic approaches for GPU programming. This greatly improves programmer productivity, while maintaining application performance similar to that of the official NVIDIA CUDA toolkit.
future=
comment=
other=
---
id=234
title=Visibility Rendering Order: Improving Energy Efficiency on Mobile GPUs through Frame Coherence (VRO)
author=Enrique de Lucas
journal=TPDS
year=2019
tags=Graphics Processing Units, Rendering Computer Graphics, Pipelines, Geometry, Hardware, Image Color Analysis, Color, mobile GPU, Graphics Pipeline, Energy Efficiency, Rasterization, Rendering, Fragment Processing, Pixel Shading, Occlusion Culling, Visibility, Tile Based Deferred Rendering, Tile Based Rendering, Topological Order, Visibility Rendering Order (VRO)
star=****
problem=During real-time graphics rendering, objects are processed by the GPU in the order they are submitted by the CPU, and occluded surfaces are often processed even though they will end up not being part of the final image, thus wasting precious time and energy. 
interest=
hardness=To help discard occluded surfaces, most current GPUs include an Early-Depth test before the fragment processing stage. However, to be effective it requires that opaque objects are processed in a front-to-back order. Depth sorting and other occlusion culling techniques at the object level incur overheads that are only offset for applications having substantial depth and/or fragment shading complexity, which is often not the case in mobile workloads. 
idea= a novel architectural technique for GPUs, Visibility Rendering Order (VRO), which reorders objects front-to-back entirely in hardware by exploiting the fact that the objects in graphics animated applications tend to keep its relative depth order across consecutive frames (temporal coherence). Since order relationships are already tested by the Depth Test, VRO incurs minimal energy overheads because it just requires adding a small hardware to capture that information and use it later to guide the rendering of the following frame. Moreover, unlike other approaches, this unit works in parallel with the graphics pipeline without any performance overhead.
future=
comment=
other=
---
id=235
title=Parallel Personalized PageRank on Dynamic Graphs   (PPR)
author=Wentian Guo, Yuchen Li, Mo Sha
journal=VLDB
year=2018
tags=PPR, parallel Personalized PageRank, Dynamic Graph
star=****
problem=Personalized PageRank (PPR) is a well-known proximity measure in graphs
interest=
hardness=To meet the need for dynamic PPR maintenance, recent works have proposed a local update scheme to support incremental computation. Nevertheless, sequential execution of the scheme is still too slow for highspeed stream processing
idea=design a parallel approach for dynamic PPR computation.  First, as updates always come in batches, we devise a batch processing method to reduce synchronization cost among every single update and enable more parallelism for iterative parallel execution; devise novel optimization techniques to e↵ectively reduce runtime overheads for parallel processes
future=
comment=Our theoretical analysis shows that the parallel approach has the same asymptotic complexity as the sequential approach; Experimental evaluation shows that our parallel algorithm can achieve orders of magnitude speedups on GPUs and multi-core CPUs compared with the state-of-the-art sequential algorithm.
other=
---
id=236
title=Synthesizing Entity Matching Rules by Examples
author=Rohit Singh
journal=VLDB
year=2018
tags=entity matching rules(EM), program Synthesis, General Boolean formula(GBF), machine learning
star=****
problem=how to synthesize entity matching rules from positive-negative matching examples
interest=Entity matching (EM) is a critical part of data integration
hardness=
idea=The core of our solution is program synthesis, a powerful tool to automatically generate rules (or programs) that satisfy a given high-level specication, via a predefined grammar.
future=
comment=Extensive experiments show that we outperform other interpretable rules (e.g., decision trees with low depth) in effectiveness, and are comparable with non-interpretable tools (e.g., decision trees with high depth, gradient-boosting trees, random forests and SVM).
other=
---
id=237
title=Stylus: A Strongly-Typed Store for Serving Massive RDF Data
author=Liang He, Bin Shao, Yatao Li
journal=VLDB
year=2018
tags=Stylus, Strongly-Typed store, massive RDF data, sparql query processing, graph database, materialized join strategy, Twig, XTwig
star=****
problem=Despite the flexibility of RDF triples, it is challenging to serve SPARQL queries on RDF data efficiently by directly managing triples
interest=RDF is one of the most commonly used knowledge representation forms.
hardness=First, heavy joins on a large number of triples are needed for query processing, resulting in a large number of data scans and large redundant intermediate results; Second, weakly-typed triple representation provides suboptimal random access – typically with logarithmic complexity;   This data access challenge, unfortunately, cannot be easily met by a better query optimizer as large graph processing is extremely I/O-intensive.
idea=strongly-typed graph representation is the key to high-performance RDF query processing. We propose Stylus – a strongly-typed store for serving massive RDF data. Stylus exploits a strongly-typed storage scheme to boost the performance of RDF query processing. The storage scheme is essentially a materialized join view on entities, it thus can eliminate a large number of unnecessary joins on triples. Moreover, it is equipped with a compact representation for intermediate results and an efficient graphdecomposition based query planner
future=
comment=
other=
---
id=238
title=Interleaving with Coroutines: A Practical Approach for Robust Index Joins
author=Georgios Psaropoulos
journal=VLDB
year=2018
tags=robust index join, Interleaving with Coroutines, instruction stream Interleaving, cache miss, CPU architecture, hardware optimization, CSB+-tree
star=****
problem=
interest=robust index join performance becomes possible with instruction stream interleaving: given a group of lookups, we can hide cache misses in one lookup with instructions from other lookups by switching among their respective instruction streams upon a cache miss.
hardness=Index join performance is determined by the efficiency of the lookup operation on the involved index. Although database indexes are highly optimized to leverage processor caches, main memory accesses inevitably increase lookup runtime when the index outsizes the last-level cache; hence, index join performance drops.
idea=propose interleaving with coroutines for any type of index join. We showcase our proposal on SAP HANA by implementing binary search and CSB+-tree traversal for an instance of index join related to dictionary compression.  Coroutine implementations not only perform similarly to prior interleaving techniques, but also resemble the original code closely, while supporting both interleaved and non-interleaved execution
future=
comment=
other=
---
id=239
title=The Part-Time Parliament   (Paxos)
author=Leslie Lamport  (digital equipment corporation)
journal=ACM Transactions on computer system
year=1998
tags=Paxos, Distributed systems, network operating systems, reliability, fault-tolerance, State machines, three-phase commit, voting
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=also see [id:240]
---
id=240
title=Paxos Made simple  (a brief introduction)
author=Leslie Lamport
journal=
year=2001
tags=Paxos, Distributed systems, network operating systems, reliability, fault-tolerance, State machines, three-phase commit, voting
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=also see [id:239]
---
id=241
title=Pregel: A System for Large-Scale Graph Processing
author=Grzegorz Malewicz  (Google Inc)
journal=SIGMOD
year=2010
tags=Distributed computing, graph algorithms, pregel, Distributed systems, compute models
star=*****
problem=The scale of these graphs|in some cases billions of vertices, trillions of edges|poses challenges to their ecient processing
interest=Many practical computing problems concern large graphs.  Standard examples include the Web graph and various social networks
hardness=
idea=a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertexcentric approach is exible enough to express a broad set of algorithms. The model has been designed for ecient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier.
future=
comment=Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.
other=
---
id=242
title=A Comparison of Adaptive Radix Trees and Hash Tables (Experimental paper)
author=Victor Alvarez
journal=ICDE
year=2015
tags=Adaptive radix trees, hash table, data structure, ARTful, FAST, B+-trees, Judy Array, survey, experimental paper
star=****
problem=
interest=With prices of main memory constantly decreasing, people nowadays are more interested in performing their computations in main memory, and leave high I/O costs of traditional disk-based systems out of the equation. This change of paradigm, however, represents new challenges to the way data should be stored and indexed in main memory in order to be processed efficiently.
hardness=Traditional data structures, like the venerable B-tree, were designed to work on disk-based systems, but they are no longer the way to go in main-memory systems, at least not in their original form, due to the poor cache utilization of the systems they run on. Because of this, in particular, during the last decade there has been a considerable amount of research on index data structures for main-memory systems. Among the most recent and most interesting data structures for main-memory systems there is the recently-proposed adaptive radix tree ARTful (ART for short)
idea=a thorough experimental comparison between ART, Judy, two variants of hashing via quadratic probing, and three variants of Cuckoo hashing. These hashing schemes are known to be very efficient. For our study we consider whether the data structures are to be used as a non-covering index (relying on an additional store), or as a covering index (covering key-value pairs). We consider both OLAP and OLTP scenarios. Our experiments strongly indicate that neither ART nor Judy are competitive to the aforementioned hashing schemes in terms of performance, and, in the case of ART, sometimes not even in terms of space.
future=
comment=The authors of ART presented experiments that indicate that ART was clearly a better choice over other recent tree-based data structures like FAST and B+-trees. However, ART was not the first adaptive radix tree. To the best of our knowledge, the first was the Judy Array (Judy for short), and a comparison between ART and Judy was not shown. Moreover, the same set of experiments indicated that only a hash table was competitive to ART. The hash table used by the authors of ART in their study was a chained hash table, but this kind of hash tables can be suboptimal in terms of space and performance due to their potentially high use of pointers.
other=
---
id=243
title=Hybrid FPGA approach for a B+ tree in a Semantic Web database system
author=Dennis Heinrich
journal=ReCoSoC
year=2015
tags=hybrid FPGA(Field programmable Gate Array), B+ tree, Bplus tree, Semantic web database system
star=***
problem=a hybrid index structure which is allocated in a Field Programmable Gate Array (FPGA) and a traditional CPU-based host system
interest=
hardness=
idea= The lower levels of the B + -tree, especially the leaves where the values are stored, are located on the host system while the root and the most upper levels with the interior nodes are stored on the FPGA. We speed up the search in the upper levels of our hybrid index by applying an FPGA accelerated parallel search.
future=
comment=
other=
---
id=244
title=The Ubiquity of Large Graphs and Surprising Challenges of Graph Processing   (survey)
author=Siddhartha Sahu, M. Tamer Ozsu  (Waterloo University)
journal=VLDB
year=2018
tags=Ubiquity of large graphs, Surprising Challenges of graph processing, survey, database system, RDBMSes
star=****
problem=In spite of this prevalence, there is little research about how graphs are actually used in practice.
interest=Graph processing is becoming increasingly prevalent across many application domains.
hardness=We conducted an online survey aimed at understanding: (i) the types of graphs users have; (ii) the graph computations users run; (iii) the types of graph software users use; and (iv) the major challenges users face when processing their graphs.
idea=We describe the participants’ responses to our questions highlighting common patterns and challenges.  We further reviewed user feedback in the mailing lists, bug reports, and feature requests in the source repositories of a large suite of software products for processing graphs. Through our review, we were able to answer some new questions that were raised by participants’ responses and identify specific challenges that users face when using different classes of graph software
future=
comment=The participants’ responses and data we obtained revealed surprising facts about graph processing in practice. In particular, real-world graphs represent a very diverse range of entities and are often very large, and scalability and visualization are undeniably the most pressing challenges faced by participants. We hope these findings can guide future research.
other=
---
id=245
title=Clustering Stream Data by Exploring the Evolution of Density Mountain  (EDMStream)
author=Shufeng Gong, Ge Yu
journal=VLDB
year=2018
tags=clustering stream data, Evolution of density mountain, EDMStream, DStream, MR-Stream, DBSTREAM, DenStream
star=****
problem=Stream clustering is a fundamental problem in many streaming data analysis applications.
interest=
hardness=Comparing to classical batch-mode clustering, there are two key challenges in stream clustering: (i) Given that input data are changing continuously, how to incrementally update their clustering results efficiently? (ii) Given that clusters continuously evolve with the evolution of data, how to capture the cluster evolution activities? Unfortunately, most of existing stream clustering algorithms can neither update the cluster result in real-time nor track the evolution of clusters.
idea=a stream clustering algorithm EDMStream by exploring the Evolution of DensityMountain.  The density mountain is used to abstract the data distribution, the changes of which indicate data distribution evolution. We track the evolution of clusters by monitoring the changes of density mountains. We further provide efficient data structures and filtering schemes to ensure that the update of density mountains is in real-time, which makes online clustering possible.
future=
comment=comparing to the state-of-the-art stream clustering algorithms, e.g., DStream, DenStream, DBSTREAM and MR-Stream, our algorithm is able to response to a cluster update much faster (say 7-15x faster than the best of the competitors) and at the same time achieve comparable cluster quality.  Furthermore, EDMStream successfully captures the cluster evolution activities.
other=
---
id=246
title=Froid: Optimization of Imperative Programs in a Relational Database
author=Karthik Ramachandra  (Microsoft Gray Systems Lab)
journal=VLDB
year=2018
tags=Froid, Imperative Programs, Relational Database, declarative SQL query, RDBMS, User Defined Functions(UDFs), relational algebraic expressions
star=****
problem=While the evaluation of declarative SQL has received a lot of attention resulting in highly sophisticated techniques, the evaluation of imperative programs has remained nave and highly inecient.
interest=For decades, RDBMSs have supported declarative SQL as well as imperative functions and procedures as ways for users to express data processing tasks;   Imperative programs oer several benets over SQL and hence are often preferred and widely used.
hardness=But unfortunately, their abysmal performance discourages, and even prohibits their use in many situations. We address this important problem that has hitherto received little attention
idea=Froid, an extensible framework for optimizing imperative programs in relational databases. Froid's novel approach automatically transforms entire User Defined Functions (UDFs) into relational algebraic expressions, and embeds them into the calling SQL query. This form is now amenable to cost-based optimization and results in ef- cient, set-oriented, parallel plans as opposed to inecient, iterative, serial execution of UDFs.
future=
comment=Froid's approach additionally brings the benets of many compiler optimizations to UDFs with no additional implementation eort. We describe the design of Froid and present our experimental evaluation that demonstrates performance improvements of up to multiple orders of magnitude on real workloads.
other=functional, declarative and imperative programming: https://stackoverflow.com/questions/602444/functional-declarative-and-imperative-programming
---
id=247
title=An Experimental Study on Hub Labeling based Shortest Path Algorithms (experimental paper, survey)
author=Ye Li
journal=VLDB
year=2018
tags=survey, experiments paper, hub labeling(HL), Shortest path Algorithms, Signicant path based Hub Pushing (SHP)
star=****
problem=Shortest path distance retrieval is a core component in many important applications
interest=For a decade, hub labeling (HL) techniques have been considered as a practical solution with fast query response time (e.g., 1-3 orders of magnitude faster), competitive indexing time, and slightly larger storage overhead (e.g., several times larger). These techniques enhance query throughput up to hundred thousands queries per second, which is particularly helpful in large user environment.
hardness=Despite the importance of HL techniques, we are not aware of any comprehensive experimental study on HL techniques. Thus it is dicult for a practitioner to adopt HL techniques for her applications.
idea=a comprehensive experimental study on the state-of-the-art HL technique with analysis of their eciency, eectiveness and applicability.  From insightful summary of dierent HL techniques, we further develop a simple yet eective HL techniques called Signicant path based Hub Pushing (SHP) which greatly improves indexing time of previous techniques while retains good query performance.
future=
comment=We also complement extensive comparisons between HL techniques and other shortest path solutions to demonstrate robustness and eciency of HL techniques.
other=
---
id=248
title=SQL Statement Logging for Making SQLite Truly Lite
author=Jong-Hyeok Park
journal=VLDB
year=2018
tags=SQL Statement logging, vanilla SQLite, SQLite/SSL, strong update locality, SQLite-based mobile application, SQLite/PPL, IO efficiency, byte-addressable NVM(non-volatile memory), WAL journal mode
star=****
problem=forced it to take less-complicated transactional schemes, such as physical page logging, journaling, and force commit, which in turn cause excessive write amplification. Thus, the write IO cost in SQLite is not lightweight at all.
interest=The lightweight codebase of SQLite was helpful in making it become the de-facto standard database in most mobile devices
hardness=
idea=to make SQLite truly lite in terms of IO efficiency for the transactional support, we propose SQLite/SSL, a per-transaction SQL statement logging scheme: when a transaction commits, SQLite/SSL ensures its durability by storing only SQL statements of small size, thus writing less and performing faster at no compromise of transactional solidity. Our main contribution is to show that, based on the observation that mobile transactions tend to be short and exhibit strong update locality, logical logging can, though long discarded, become an elegant and perfect fit for SQLite-based mobile applications. Further, we leverage the WAL journal mode in vanilla SQLite as a transaction-consistent checkpoint mechanism which is indispensable in any logical logging scheme. In addition, we show for the first time that byte-addressable NVM (non-volatile memory) in host-side can realize the full potential of logical logging because it allows to store fine-grained logs quickly.
future=
comment=We have prototyped SQLite/SSL by augmenting vanilla SQLite with a transaction-consistent checkpoint mechanism and a redo-only recovery logic, and have evaluated its performance using a set of synthetic and real workloads. When a real NVMboard is used as its log device, SQLite/SSL can outperform vanilla SQLite’s WAL mode by up to 300x and also outperform the state-of-the-arts SQLite/PPL scheme by several folds in terms of IO time.
other=
---
id=249
title=Cardinality Estimation: An Experimental Survey    (survey, experimental paper)
author=Hazar Harmouch
journal=VLDB
year=2018
tags=Cardinality Estimation, Experimental paper, survey, zeroth-frequency moment, data preparation, data profiling, data distribution, the number of distinct values in each column, 
star=****
problem=Cardinality estimation itself has been an active research topic in the past decades due to its many applications.
interest=Data preparation and data profiling comprise many both basic and complex tasks to analyze a dataset at hand and extract metadata, such as data distributions, key candidates, and functional dependencies;  Among the most important types of metadata is the number of distinct values in a column, also known as the zeroth-frequency moment.
hardness=review the literature of cardinality estimation and to present a detailed experimental study of twelve algorithms, scaling far beyond the original experiments
idea=First, we outline and classify approaches to solve the problem of cardinality estimation we describe their main idea, error-guarantees, advantages, and disadvantages. Our experimental survey then compares the performance all twelve cardinality estimation algorithms. We evaluate the algorithms' accuracy, runtime, and memory consumption using synthetic and real-world datasets.
future=
comment=Our results show that dierent algorithms excel in dierent in categories, and we highlight their trade-os.
other=
---
id=250
title=Clustering Uncertain Graphs
author=Matteo Ceccarello
journal=VLDB
year=2018
tags=Uncertain graphs, clustering, probability, NP-hardness, maximizing the minimum connection probability, approximation guarantee
star=****
problem=a probability space whose outcomes (referred to as possible worlds), each edge occurs with probability p(e)
interest=These graphs naturally arise in many application domains where data management systems are required to cope with uncertainty in interrelated data, such as computational biology, social network analysis, network reliability, and privacy enforcement, among the others. For this reason, it is important to devise fundamental querying and mining primitives for uncertain graphs.
hardness=
idea=This paper contributes to this endeavor with the development of novel strategies for clustering uncertain graphs. Specifically, given an uncertain graph G and an integer k, we aim at partitioning its nodes into k clusters, each featuring a distinguished center node, so to maximize the minimum/average connection probability of any node to its cluster’s center, in a random possible world.
future=
comment=We assess the NP-hardness of maximizing the minimum connection probability, even in the presence of an oracle for the connection probabilities, and develop efficient approximation algorithms for both problems and some useful variants.  Unlike previous works in the literature, our algorithms feature provable approximation guarantees and are capable to keep the granularity of the returned clustering under control.  Our theoretical findings are complemented with several experiments that compare our algorithms against some relevant competitors, with respect to both running-time and quality of the returned clusterings.
other=
---
id=251
title=Concurrent Log-Structured Memory for Many-Core Key-Value Stores (Nibble)
author=Alexander Merritt
journal=VLDB
year=2018
tags=key-value stores, many-core, concurrent Log-Structured memory, Nibble, multi-head log, distributed epoch, Rust
star=****
problem=
interest=Key-value stores are an important tool in managing and accessing large in-memory data sets. As many applications benefit from having as much of their working state fit into main memory, an important design of the memory management of modern key-value stores is the use of log-structured approaches, enabling ecient use of the memory capacity, by compacting objects to avoid fragmented states.
hardness=with the emergence of thousand-core and peta-byte memory platforms (DRAM or future storage-class memories) logstructured designs struggle to scale, preventing parallel applications from exploiting the full capabilities of the hardware: careful coordination is required for background activities (compacting and organizing memory) to remain asynchronous with respect to the use of the interface, and for insertion operations to avoid contending for centralized resources such as the log head and memory pools.
idea=the design of a log-structured key-value store called Nibble that incorporates a multi-head log for supporting concurrent writes, a novel distributed epoch mechanism for scalable memory reclamation, and an optimistic concurrency index.
future=
comment=Nibble scales linearly in uniform YCSB workloads, matching competitive nonlog- structured key-value stores for write- dominated traces at 50 million operations per second on 1 TiB-sized working sets. Our memory analysis shows Nibble is ecient, requiring less than 10% additional capacity, whereas memory use by non-log-structured key-value store designs may be as high as 2x.
other=
---
id=252
title=
author=
journal=VLDB
year=2018
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=253
title=
author=
journal=VLDB
year=2018
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=254
title=
author=
journal=VLDB
year=2018
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=255
title=
author=
journal=VLDB
year=2018
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
