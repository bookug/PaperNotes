---
id=0
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=1
title=Lessons Learned from Exploring the Backtracking Paradigm on the GPU
author=    John Jenkins,Isha Arkatkar,John D. Owens,Alok Choudhary,Nagiza F. Samatova
journal= European Conference on Parallel and Distributed Computing(Euro-Par)
year=2011
tags=Shared Memory,Connectivity Query,Memory Operation,Frequent Itemset Mining,Candidate Path,backtrack,Maximal Clique Enumeration(MCE), k-d tree(KD-tree)
star=***
problem=how to parallelize backtracking paradigm
interest=backtracking paradigm(depth-first search) is common in graph algorithms
hardness=backtracking paradigm is hard to parallelize
idea=store candidate paths in stack instead of backtracking, warp-level parallelism on GPU, work stealing, output buffering, coarse-grain parallelization where multiple subtrees are explored in parallel, utilize both CPU and GPU
future=improve the load balance on GPU
comment=A deep consideration of backtracking paradigm and depth-first search for graph algorithms,inability to provide better performance of MCE than CPU,four lessons are remarkable
other=breadth-first search is easier to be parallelized compared to depth-first search, but it consumes too much memory;combination is an idea and dividing into many blocks is another
---
id=2
title= A Sparse Completely Positive Relaxation of the Modularity Maximization for Community Detection
author=Haoyang Liu
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=3
title=GPU acceleration of subgraph isomorphism search in large scale graph
author=Bo Yang, Kai Lu, Yinghui Gao, Xiaoping Wang, Kai Xu
journal=Journal of Central South University
year=2015
tags=subgraph isomorphism, backtrack paradigm, GPU, parallel
star=*
problem=how to apply TurboISO to GPU
interest=TurboISO is a fast CPU subgraph isomorphism algorithm, is it suitable for GPU?
hardness=TurboISO adopts backtrack paradigm which is hard to be parallelized
idea=parallelism in different candidate region, the independency property of the partial subtree embedding allows that the GPU region exploration algorithm can first divide the region exploration into expanding and backtracking of partial subtree embeddings and then conquer the partial subtree embedding and generate new ones in parallel
future=
comment=the key of this paper is to adopts some BFS expanding strategies in the DFS framework, the shortcoming is that lots of DFS operations still exist and will limit the overall performance; if dfs work is too little, then the size of candidates will be too large for GPUto run(memory and thread limits), if dfs work is too much, then the time cost of dfs is too high, though the size of candidates for BFS is reduced
other=backtrack paradigm is rarely used in parallel computing; much faster than vf2[id:58], but hard to implement
---
id=4
title=THE ENUMERATION OF MAXIMAL CLIQUES OF LARGE GRAPHS
author=E. A. Akkoyunlu
journal=SIAM J. Comput.
year=1973
tags=Graph Algorithm, Maximal Clique,Backtrack
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=the same idea as [id:5]
---
id=5
title=Finding All Cliques of an Undirected Graph
author=Coenraad Bron, Joep Kerbosch
journal=Commun. ACM
year=1973
tags=Graph Algorithm, Maximal Clique,Backtrack
star=****
problem=how to enumerate all maximal cliques in a graph
interest=widely used and its efficiency is very important in practice
hardness=A NP-hard problem
idea=use backtracking for search, with pruning strategies(pivot selection and vertex degeneracy ordering)
future=better pivot vertex selection, special optimization for special graphs
comment=classical and efficient work on maximal cliques enumeration,strict theoretical bound,work efficiently for many kinds of graphs including social network
other=different kinds of graphs have different kinds of optimizations; https://en.wikipedia.org/wiki/Bron%E2%80%93Kerbosch_algorithm#cite_note-1
---
id=6
title=Real-time KD-tree construction on graphics hardware
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=7
title=A Survey of General-Purpose Computation on Graphics Hardware
author=John D. Owens
journal=
year=2007
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=8
title=Efficient Gradient Boosted Decision Tree Training on GPUs
author=Zeyi Wen,Bingsheng He
journal=IEEE International Parallel and Distributed Processing Symposium(IPDPS)
year=2018
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=9
title=Gunrock: A High-Performance Graph Processing Library on the GPU
author=Yangzihao Wang , Andrew A. Davidson , Yuechao Pan , Yuduo Wu , Andy Riffel , John D. Owens
journal=Symposium on Principles and Practice of Parallel Programming(PPoPP), also on arXiv
year=2016
tags=GPU,Graph Algorithm,Graph Library,Graph Processing System,data-centric,bulk-synchronous,based on frontier,load balance, kernel fusion
star=*****
problem=
interest=
hardness=the irregularity of data access/control flow and the complexity of programming GPUs
idea=data-centric primitives(advance, filter, compute, intersection)
future=
comment=
other=comparison result(vs CuSha, Galois, Hardwired, Ligra, MapGraph, NVGraph)    https://gunrock.github.io/docs/engines_topc.html      ;   considering SSSP, only in road_usa Gunrock performs worser than nvGraph
---
id=10
title= PowerGraph:DistributedGraph-ParallelComputationonNaturalGraphs
author=Joseph E. Gonzalez, Yucheng Low
journal=USENIX Symposium on Operating Systems Design and Implementation(OSDI)
year=2012
tags=Graph System
star=*****
problem=how to deal with natural graph(power-law distribution) in  distributed computing
interest=natural graph is widely encountered, the performance of distributed computing is very critical
hardness=high-degree nodes,heavy communication cost among machines
idea=divide partitions by vertex cut; GAS decomposition; delta caching, values of many vertices not change and no need to gather them
future=
comment=an efficient and promising work
other=
---
id=11
title=Hardware Acceleration in Commercial Databases: A Case Study of Spatial Operations
author=Nagender Bandi, Chengyu Sun
journal=VLDB
year=2004
tags=Hardware Acceleration,complex data types(spatial geometries, protein structures)
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=12
title=Shared Memory Parallel Subgraph Enumeration
author=Raphael Kimmig,Henning Meyerhenke,Darren Strash
journal=IEEE International Parallel and Distributed Processing Symposium(IPDPS) Workshops
year=2017
tags=subgraph enumeration, subgraph isomorphism,parallel combinatorial search,graph mining,network analysis,work-stealing, multi-core, shared memory
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=13
title=Efficient Subgraph Matching Using GPUs
author=Xiaojie Lin,Rui Zhang,Zeyi Wen
journal=Databases Theory and Applications - 25th Australasian Database Conference(ADC)
year=2014
tags=subgraph matching,GPU,relational join,comparison of several subgraph isomorphism algorithms
star=***
problem=the join process of STwigs are very time-consuming
interest=
hardness=
idea=use hash instead of binary search to join two relation tables of STwigs; indicate a constant time though with random access
future=
comment=
other=
---
id=14
title=Query Workload-based RDF Graph Fragmentation and Allocation
author=Peng Peng, Lei Zou, Lei Chen,Dongyan Zhao
journal= International Conference on Extending Database Technology (EDBT, CCF B in Database area)
year=2016
tags=RDF,Graph Fragmentation, query workload, Graph Partition,communication cost, distributed environment, crossing match
star=***
problem= reduce the number of crossing matches and the communication cost during SPARQL query processing in distributed environment
interest=distributed computing is common and the communication cost is the bottleneck
hardness=high-degree nodes, complex model of distributed computing
idea= mine and select some frequent access patterns to reflect the characteristics of the workload,  Vertical fragmentation is for better throughput and horizontal fragmentation is for lower latency
future=
comment=find out all instances of a frequent pattern as fragments,place all instances of a query in several machines to lower latency of the single query(enable parallism of this query), place all instances in one machine to improve throughput(enable parallism of multiple queries); allocate closely related fragments in one machine to lower the communication cost of dealing with decomposed query
other=An improved version is in [id:16]; based on edge cut, may not work well on high-degree nodes
---
id=15
title=Processing SPARQL queries over distributed RDF graphs
author=Peng Peng, Lei Zou, Tamer, Lei Chen,Dongyan Zhao
journal=VLDB Journal
year=2016
tags=distributed environment,RDF, SPARQL,partial evaluation and assembly, local partial match, centralized and distributed
star=****
problem=how to answer SPARQL queries in a distributed environment
interest=RDF datasets with billions of tripels are common now
hardness=how to combine the results in different machines,how to reduce the communication cost
idea=given an arbitary partition(partition-agnostic), partial evaluation and join the results;centralized assembly is simple but the cost of the master machine will be too high, distributed assembly is complex(BSP, bulk synchronous parallel) but efficient and load balanced
future=handling SPARQL queries over linked open data (LOD),  multiple SPARQL query optimization in the context of distributed RDF graphs
comment=in practice specific partition for a specific kind of dataset is more efficient, though not so flexible
other=
---
id=16
title=Adaptive Distributed RDF Graph Fragmentation and Allocation based on Query Workload
author=Peng Peng, Lei Zou, Lei Chen,Dongyan Zhao
journal=IEEE Transactions on Knowledge and Data Engineering(TKDE)
year=2018
tags=Distributed RDF Database, Data Fragmentation, Data Allocation, Query Workload
star=****
problem=
interest=
hardness=
idea=allocate these fragments to various sites while balancing the fragments;  vertical, horizontal and mixed fragmentation
future=
comment=
other=The original work is in [id:14], the enhancement is that a mixed fragmentation strategy is proposed
---
id=17
title=Collaborative (CPU + GPU) Algorithms for Triangle Counting and Truss Decomposition on the Minsky Architecture
author=Ketan Date,Keven Feng
journal=High Performance Extreme Computing Conference (HPEC)
year=2017
tags=CPU,GPU,Triangle Counting,Truss Decomposition
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=various memory management on GPU
---
id=18
title=Fast and Adaptive List Intersections on the GPU
author=James Fox, Oded Green, Kasimir Gabert
journal=HPEC(not in CCF list)
year=2018
tags=GPU,List Intersection
star=***
problem=for  many  graph  based problems  it  is  necessary  to  find  intersections  for  a  very  large number  of  lists—these  lists  tend  to  vary  greatly  in  size  and are   difficult   to   efficiently   load-balance
interest=List intersections are ubiquitous and can be found in   wide   range   of   applications,   including   triangle   counting and  finding  the  maximal k-truss,  both  of  which  are  part  of the  HPEC  Static  Graph  Challenge
hardness=load imbalance due to the irregular property of graph
idea=assigns  a  different  number  of  threads  for  different intersections  in  order  to  effectively  utilize  the  resources  of  the GPU; search-based and merge-based; estimate the cost and split into sublists
future=
comment=less abstarct, not so novel; no use about shared memory; how to set the size of bin and how many threads to use for this bin; load imbalance still exists in a bin
other=the original idea is in [id:57]
---
id=19
title=Static Graph Challenge: Subgraph Isomorphism (competition)
author=Siddharth Samsi
journal=HPEC workshop (graph challenge of HPEC, not in CCF, but HPEC is the second level conference)
year=2018
tags=static graph challenge, subgraph isomorphism, subgraph match, competition
star=***
problem=
interest=
hardness=
idea=this is just an introduction of Graph Challenge competition: static subgraph isomorphism(only small query graphs, i.e. triangle and k-truss), dynamic graph stream(clustering)
future=
comment=just a competition instead of a paper, named GraphChallenge
other=https://graphchallenge.mit.edu/
---
id=20
title=Multilevel Parallelism for the Exploration of Large-Scale Graphs
author=Massimo Bernaschi, Mauro Bisson
journal=IEEE Trans. Multi-Scale Computing Systems
year=2018
tags=GPU cluster,BC(Betweeness Centrality), BFS(Breadth-first search),Large graphs, graph algorithms, parallel algorithms, parallel programming, distributed programming, CUDA
star=**
problem=
interest=
hardness=
idea=
future=improve the heuristic to switch between the top-down and the bottom-up variant and to evaluate the advantages that technologies likeGPUDirectAsynccanprovideforreducingthe overhead of the communication among GPUs; explore the chance of using our BFS as a building block for the solution of other graphs problems.
comment=
other=
---
id=21
title=Experimental Evaluation of GPU Solutions to the Single Source Shortest Path Problem(SSSP)
author=
journal=
year=2017
tags=GPU,CUDA,Shortest Path
star=***
problem=
interest=
hardness=
idea=compare dijkstra(strict limitation, lowest work complexity), bellman-ford(lose limitation, highest work complexity) and the mixed version(delta stepping, split into buckets); diffrent system like BGL(Boost Graph Library), PGBL(Parallel Boost Graph Library), Gunrock and LoneStarGPU
future=
comment=
other=https://www.boost.org/doc/libs/1_63_0/libs/graph_parallel/doc/html/index.html
---
id=22
title=HyperX: A Scalable Hypergraph Framework
author=Wenkai Jiang, Jianzhong Qi, Jeffery Xu Yu
journal=IEEE Transactions on Knowledge and Data Engineering(TKDE)
year=2018
tags=Hypergraph, HyperX, graph framework, graph partitioning, label propagation partitioning
star=****
problem=support hypergraph computing
interest=not regular and hard to represent, but do occur in real case; Hypergraphs are generalizations of graphs where the (hyper)edges can connect any number of vertices. They are powerful tools for representing complex and non-pairwise relationship
hardness=existing graph computation frameworks cannot accommodate hypergraphs without converting them into graphs, because they do not offer APIs that support (hyper)edges directly. This graph conversion may create excessive replicas and result in very large graphs, causing difficulties in workload balancing 
idea=design a new optimization objective aimed to minimize the number of replicas and to achieve the balanced partitions, propose a novel label propagation algorithm to achieve the optimization running in parallel with several heuristics
future=open source HyperX and use it for other hypergraph processing tasks such as building similarity based regularization classifier for recommender systems and studying biochemical interactions.
comment=
other=
---
id=23
title=Learning with hypergraphs: Clustering, classification, and embedding
author=Dengyong Zhou, Jiayuan Huang
journal=Annual Conference on Neural Information Processing Systems(NIPS)
year=2006
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=24
title=Accelerating Dynamic Graph Analytics on GPUs(GPMA)
author=Mo Sha, Yuchen Li, Bingsheng He
journal=Proceedings of the VLDB Endowment
year=2017
tags=Dynamic Graph Analytics,GPU, stream updates, Graph Stream, GPMA,CSR,B+ tree, PMA on GPU
star=****
problem=in many applications such as social networks, cyber security, and fraud detection, their representative graphs evolve frequently and one has to perform a rebuild of the graph structure on GPUs to incorporate the updates
interest=As graph analytics often involves compute-intensive operations, GPUs have been extensively used to accelerate the processing
hardness=rebuilding the graphs(like the traditional CSR structure) becomes the bottleneck of processing high-speed graph streams
idea=a GPU-based dynamic graph storage scheme to support existing graph algorithms easily. Furthermore, we propose parallel update algorithms to support Erikcient stream updates so that the maintained graph is immediately available for high-speed analytic processing on GPUs; the intuition is add holes to CSR, the holes can not be too large or too small ,just like the node of B-tree, split and coalesce on some specific cases; as for updates, some heuristic methods are used, in the input buffer insertions and deletions are separated, operations to the same node are separated(otherwise will cause lock), if we can decide that some insertions will cause the adjustion of substructure then we can reorganize this part first
future=
comment=novel ideas and practical; how to support tc and sm on such structures?; no framework or primitive that can support all graph algorithms on GPUs well
other=a technical report in detail can be acquired on arXiv; an implementation of PMA on GPU
---
id=25
title=Towards GPU-Based Common-Sense Reasoning: Using Fast Subgraph Matching
author=Ha-Nguyen Tran, Erik Cambria, Amir Hussain
journal=Cognitive Computation
year=2016
tags=Common-Sense Reasoning, GPU, Subgraph Matching, CUDA
star=***
problem=transform reasoning to subgraph Isomorphism on Knowledge graph
interest=leverage the power of GPU to do reasoning, and not from scratch but using the existing work of subgraph matching
hardness=subgraph matching is a NP-hard problem
idea=edge-based subgraph Isomorphism on GPU, multi-level graph compression(finding similar nodes in Knowledge graphs and combine into one hyper-node) to place large graph on GPU
future=
comment=
other=use subgraph Isomorphism algorithm like [id:12] in literature.list; the graph compression strategy is similar to [id:5] in yuqizhou.list
---
id=26
title=Efficient Semantic Search over Structured Web Data: A GPU Approach
author=Ha-Nguyen Tran
journal=Computational Linguistics and Intelligent Text Processing
year=2017
tags=GPU, Reasoning, RDF, SPARQL
star=**
problem=
interest=
hardness=
idea=backward chaining
future=
comment=
other=use subgraph Isomorphism algorithm like [id:12] in literature.list
---
id=27
title=privacy-preserving ranked neighbor query over encrypted graph data in the cloud
author=Hong Zhu, Bin Wu
journal=security and communication networks
year=2016
tags=encrypted graph, randked neighbor query, cloud computing, searchable encryption
star=**
problem=how to rank neighbors in a encrypted scene
interest=
hardness=in cloud encryption is used to protect the privacy of users, but this means ranking is very hard to do
idea=
future=
comment=
other=
---
id=28
title=An Efficient Algorithm for Subgraph Isomorphism using Dynamic Programming on Directed Acyclic Graphs
author=
journal=
year=2018
tags=
star=
problem=
interest=
hardness=
idea= dynamic programming on directed acyclic graphs, the adaptive matching order with DAG-ordering, pruning by failing sets
future=
comment=
other=
---
id=29
title=Accelerating graph isomorphism queries in a graph database using the GPU
author=
journal=
year=2016
tags=GPU, subgraph isomorphism, graph database
star=
problem=performing subgraph isomorphism in a graph database using GPU
interest=
hardness=
idea=
future=for graph database an index can be built to speed up the searching, which uses the features of the data graphs
comment=the subgraph isomorphism algorithm is GpSM in [id:12] in literature.list
other=the same paper with [id:129]
---
id=30
title=Challenging the Time Complexity of Exact Subgraph Isomorphism for Huge and Dense Graphs with VF3
author=Carletti V
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI, CCF A journal of Artificial Intelligence)
year=2018
tags=Graphs, graph matching, graph isomorphism, subgraph isomorphism, graphs dataset,vf3, induced subgraph
star=****
problem=
interest=able to manage huge and dense graphs
hardness=traditional algorithms only deals with small and sparse graphs; hard to prune in dense graphs
idea=
future=
comment=
other=it seems there is a former version in 2017;   vf2 is also published on TPAMI, and vf3 is the evolution of VF2Plus, which is also an evolution of VF2[id:58]; TPAMI is a famous journal with Impact Factor higher than 9; another paper is Introducing VF3: A New Algorithm for Subgraph Isomorphism
---
id=31
title=A Distributed Multi-GPU System for Fast Graph Processing
author=Zhihao Jia, Yongkee Kwon
journal=PVLDB
year=2017
tags=multi-GPU clusters, graph processing, distributed computing
star=****
problem=speed up graph processing using GPU cluster
interest=to leverage power of multi-GPUs to beat distributed or shared-memory systems
hardness=work assignment and communication among GPUs
idea=Lux system exploiting locality and  the aggregate memory bandwidth on GPUs, dynamic graph repartitioning strategy that enables well-balanced workload distribution with minimal overhead, a model choosing the number of nodes and GPUs for the best possible performance
future=
comment=not so novel but a general framework
other=GPUs communicate via NVLink; Five algorithms are tested, PR(PageRank), CC(connected components), SSSP(single-source shortest path), BC(betweenness centrality), CF(collaborative filtering)
---
id=32
title=Work-Efficient Parallel GPU Methods for Single-Source Shortest Paths
author=Andrew A. Davidson, Sean Baxter, Michael Garland, John D. Owens
journal=IPDPS(CCF B of high performance computing)
year=2014
tags=GPU computing, graph traversal, single-source shortest paths(SSSP), sparse graphs, delta stepping, label-correcting, label-setting, Delta+, work organization, load balance
star=****
problem=how to implement SSSP on GPU
interest=SSSp is frequently encountered in real life
hardness=dijkstra's algorithm is hard to parallize, while the work complexity of bellman-ford is too high
idea=consider delta stepping implementation by [id:33] ;    These two classic algorithms span a parallel vs. efficiency spectrum. Neither is ideal: Dijkstra exposes no parallelism across vertices, while Bellman-Ford is expensive. This paper explores the space between these two endpoints, studying algorithms that both exploit parallelism and maintain efficiency.  We develop and describe three such methods that are targeted for fine-grained, massively parallel machines such as GPUs;   Workfront Sweep, Near-Far and Bucketing; to balance the tradeoff between saving work and organizational overhead; also explore a variety of parallel load-balanced graph traversal strategies and apply them towards our SSSP solver.
future=dynamic method that switches between Workfront Sweep and Near-Far(begin with a Workfront Sweep method until the vertex queue becomes large enough to saturate the GPU, Now that there is sufficient parallelism, we would switch to our Near-Far Pile technique where work efficiency is more important. Finally, after most of the graph has been explored, and we return to a lack of sufficient parallelism, we would switch back again to Workfront Sweep to finish off the problem, similar to [id:36]);  lack of available parallelism on road network (low-degree graphs), combine our work-saving method with a PHAST-like pre-processing step to identify more vertices from which to start our SSSP sweeps
comment=reduce the work complexity remarkably; works for low-degree and scale-free graphs both; utilize ideas of Bellman-Ford(work-front sweep) and delta-stepping(near-far pile and bucket), delta-stepping is label-setting and not supports negative weights, so does this algorithm(Delta+)
other=On all graphs, we demonstrate significant speedups over the previous GPU state of the art, LonestarGPU’s Bellman-Ford implementation [4], and on dense graphs that are more amenable for parallel SSSP computation, speedups over a variety of CPU and GPU implementations.
---
id=33
title=Δ-stepping: a parallelizable shortest path algorithm (delta-stepping)
author=U. Meyer, P. Sanders(the corresponding author, Germany)
journal=J. Algorithms
year=2003
tags=coarse-grained parallel CPUs, both sequential and parallel(better), delta stepping, shortest path(SSSP), delta-stepping, label-setting, theorectical analysis, average linear-time, upper bound of distance, uniform distribution of edge weights, distributed memory machines, (parallel random access machine) PRAM model, (distributed memory machine) DMM model, fit for General Graphs(high-degree and low-degree)
star=****
problem=The single source shortest path problem for arbitrary directed graphs with n nodes, m edges and nonnegative edge weights can sequentially be solved using O(n · log n + m) operations.
interest=we present a rather simple algorithm for the single source shortest path problem. Our new algorithm, which we call Delta-stepping, can be implemented very efficiently in sequential and parallel setting for a large class of graphs.
hardness=no work-efficient parallel algorithm is known that runs in sublinear time for arbitrary graphs
idea=This algorithm maintains a list of eligible nodes with their tentative distances in an array of buckets B, each of which denotes a distance range of size Δ the “bucket width”. During any iteration, this algorithm removes all nodes of the current nonempty bucket and relaxes their outgoing edges of weight at most Δ, while current bucket is non-empty. During the relaxation step new nodes are inserted into bucket. If any node v has been removed from the current non-empty bucket B[i] without its final distance value, then in some succeeding step of same iteration, v will surely be reinserted into B[i]. Edges having weight higher than Δ are relaxed only after their corresponding starting node is surly settled. So the edges of weight more than Δ originating from all nodes that have been removed from B[i] are relaxed once for all when B[i] finally becomes empty. Parallelism is obtained by simultaneously removing all nodes of the current non-empty bucket, relaxing their outgoing edges of weight at most Δ and finally relaxing edges having weight more than Δ
future=
comment=work complexity is linear when using maximum path weight as constant, [id:32] also claims this is O(vlgv+e) as [id:408], This is indeed a label-setting algorithm but try to improve parallelism; successful for coarse-grained parallel CPUs; difficult to implement efficiently on a GPU-like machine(by [id:32]):bucket implementation requires dynamic arrays that can be quickly resized in parallel. Dynamic arrays are poorly suited to the current programming model of GPUs, and implementing a custom memory management system for dynamic arrays (utilizing heaps) would be difficult and inefficient;  fine-grained renaming and moving vertices between buckets is difficult to paral lelize, likely requiring atomics and thus losing concurrency; efficient GPU implementations require exploiting three-layer memory hierarchy(global DRAM, per-block shared memory, and per-thread registers) of GPU
other=based on [id:446] but distinguish light edges and heavy edges;   delta stepping, the original idea; provide a work-efficient parallel algorithm for SSSP; give theoretical bounds;   It processes multiple light edges simultaneously in a single superstep, as long as the smallest tentative distance of an edge's source falls in the region gap.    
---
id=34
title=GPGPU based image segmentation livewire algorithm implementation
author=
journal=
year=2007
tags=GPGPU, image segmentation, delta-stepping, shortest path(SSSP)
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=a GPU version of delta-stepping for SSSP, see [id:33]
---
id=35
title=Implementing sparse matrix-vector multiplication on throughput-oriented processors
author= Nathan Bell, Michael Garland
journal=International Conference for High Performance Computing, Networking, Storage, and Analysis(SC, CCF A)
year=2009
tags=Graph Data Structure, GPU, DIA(Diagonal format), ELL(ELLPACK), CSR(Compressed Sparse Row), COO(Coordinate Format)
star=*****
problem=
interest=
hardness=
idea=ELLPACK format is well-suited to vector and SIMD architectures,  its efficiency rapidly degrades when the number of nonzeros per matrix row varies; the storage efficiency of the COO format is invariant to the distribution of nonzeros per row, and the use of segmented reduction makes its performance largely invariant as well; To obtain the advantages of both, we combine these into a hybrid ELL/COO format
future=
comment=not use CSR and COO when matrix is small because there is not enough work; CSR not benefit from coalescing memory access
other=discussion of possible implementations, advantages, and disadvantages of several formats for sparse matrices
---
id=36
title=Memory-scalable GPU spatial hierarchy construction
author=
journal=IEEE Transactions on Visualization and Computer Graphics(TVCG, CCF A Journal)
year=2011
tags=GPU, BFS,Memory bound, kd-tree, bounding volume hierarchy,partial BFS 
star=****
problem=While being able to exploit the massive parallelism on the GPU, the BFS order also consumes excessive GPU memory and threads
interest=
hardness=
idea=use the partial breadth-first search (PBFS) construction order to control memory consumption while maximizing performance; memory allocation strategies to effectively limit memory fragmentation
future=
comment=a novel idea to turn from BFS to DFS at some point
other=
---
id=37
title=Fast Sparse Matrix and Sparse Vector Multiplication Algorithm on the GPU
author=Carl Yang, Yangzihao Wang, John D. Owens
journal=IPDPS
year=2015
tags=GPU, SpMSpV, SpMV
star=
problem=
interest=
hardness=different from SpMV(sparse matrix, dense vector)
idea=
future=
comment=
other=
---
id=38
title=Efficient wait-free implementation of a concurrent priority queue
author=
journal=WDAG
year=1993
tags=concurrent priority queue, Data Structure
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=39
title=Comparative Performance Analysis of Intel Xeon Phi, GPU, and CPU: A Case Study from Microscopy Image Analysis
author=
journal=IPDPS
year=2014
tags=GPU, MIC(Many Integrated Core)
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=40
title=Efficiency of a Good But Not Linear Set Union Algorithm
author=
journal=Journal of the ACM(JACM, CCF A Journal)
year=1975
tags=set union, disjoint set, union find, data structure, algorithm, complexity, equivalence, partition, tree 
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=citation higher than 1500; the original paper of disjoint set
---
id=41
title=Parallelizing Union-Find in Constraint Handling Rules Using Confluence Analysis
author=
journal=International Conference on Logic Programming(ICLP)
year=2005
tags=union find, disjoint set, parallel
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=42
title=Wait-free parallel algorithms for the union-find problem
author=
journal=ACM symposium on Theory of computing(STOC, CCF A Conference of computer science)
year=1991
tags=union find, disjoint set, parallel algorithm, wait-free, asynchronous parallelism
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=citation higher than 120
---
id=43
title=A New Scalable Parallel DBSCAN Algorithm Using the Disjoint-Set Data Structure
author=
journal=SC
year=2012
tags=Density based clustering, Union-Find algorithm, Disjoint-set  data  structure
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=44
title=Experiments on Union-Find Algorithms for the Disjoint-Set Data Structure
author=
journal=International Symposium on Experimental Algorithms(SEA)
year=2010
tags=Union-Find Disjoint Set Experimental Algorithms 
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=45
title=Multi-core spanning forest algorithms using the disjoint-set data structure
author=
journal=IPDPS
year=2012
tags=Multi-core, spanning forrest, connected components, Disjoint sets
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=46
title=Template Skycube Algorithms for Heterogeneous Parallelism on Multicore and GPU Architectures
author=
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Heterogeneous Parallelism
star=****
problem=
interest=
hardness=
idea= a novel templating methodology to create portable, yet architecture-aware algorithms;  cache-conscious CPU optimizations
future=
comment=
other=
---
id=47
title=A Memory Bandwidth-Efficient Hybrid Radix Sort on GPUs
author=Elias Stehle, Hans-Arno Jacobsen
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Hybrid Radix Sort, memory bandwidth
star=****
problem=
interest=
hardness=
idea=proceeding from the most-significant to the least-significant digit allows our algorithm to drop the requirement  of  stable  sorting  passes(not LSB-based, reduce the number of sorting passes and the amount of memory transfers);   heterogeneous  sorting  algorithm that uses the CPU on powerful host systems to mitigate the overhead introduced with PCIe data transfers and sort arbitrarily large inputs, using pipeline to exploit the full-duplex communication of the PCIe bus
future=
comment=
other=
---
id=48
title=Scout: A GPU-Aware System for Interactive Spatio-temporal Data Visualization
author=Harshada Chavan, Mohamed F. Mokbel
journal=SIGMOD(CCF A)
year=2017
tags=GPU, Data Visualization, Spatio-temporal
star=****
problem=
interest=
hardness=
idea=Spatio-temporal indices
future=
comment=only a specific area, not so novel, seems like a demo
other=
---
id=49
title=Parallelizing Sequential Graph Computations
author=
journal=SIGMOD
year=2017
tags=GRAPE, parallel model, graph computation, partial evaluation, incremental evaluation, scalability
star=*****
problem=
interest=auto-parallelization with minor changes to sequential algorithm and ensure the correctness
hardness=
idea=
future=
comment=
other=best paper award of SIGMOD 2017
---
id=50
title=SuRF: Practical Range Query Filtering with Fast Succinct Tries
author=
journal=SIGMOD
year=2018
tags=data structure, range query, bloom filter, reduce I/O, membership test
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=best paper award of SIGMOD 2018
---
id=51
title=Entity Matching with Active Monotone Classification
author=
journal= ACM SIGMOD Conference on Principles of DB Systems(PODS, CCF B, top theorectical conference in Database area)
year=2018
tags=entity matching, active learning, monotone classification, entity matching, computation theory, Approximation algorithms analysis
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=best paper award of PODS 2018
---
id=52
title=Query-based Workload Forecasting for Self-Driving Database Management Systems
author=
journal=SIGMOD
year=2018
tags=workload forecasting, dynamic workload, self-driving database system
star=****
problem=predict the workload in future and select the proper optimizations in a timely manner for a dynamic changing workload
interest=
hardness=
idea=
future=
comment=
other=
---
id=53
title=Cold Filter: A Meta-Framework for Faster and More Accurate Stream Processing
author=Yang Zhou, Tong Yang
journal=SIGMOD
year=2018
tags=data streams, Approximate algorithms, data structures, sketch, stream processing
star=****
problem=
interest=
hardness=
idea=Different from existing filters that mainly focus on hot items, our filter captures cold items in the first stage, and hot items in the second stage; each item enters one stage only once
future=
comment=
other=
---
id=54
title=TurboFlux: A Fast Continuous Subgraph Matching System for Streaming Graph Data
author=Kyongmin Kim, In Seo (same contribution), Wook-Shin Han(the teacher)
journal=sigmod
year=2018
tags=dynamic graph, graph stream, continuous Subgraph matching
star=****
problem=answering continuous subgraph matching on dynamic graph
interest=subgraph matching is NP-hard and graph stream is hard to deal with
hardness=repeated subgraph matching for each edge update or expensive overheads in maintaining enormous intermediate results
idea=a concise representation of intermediate results, and its execution model allows fast incremental maintenance; an efficiently updatable graph for storing partial solutions(data-centric graph); edge transition model, which efficiently identifies which update operation can affect the current partial solutions
future=a future work is executing TurboFlux under MVCC, see [id:314]
comment=an amazing work which tries to solve the continuous subgraph matching problem on practical graph stream; the intuition is dynamicly updating the partial matchings of a query tree only, and do subgraph search on this auxiliary structure to verify non-tree edges again each time
other=
---
id=55
title=Speeding Up Set Intersections in Graph Algorithms using SIMD Instructions
author=Shuo Han, Lei Zou, Jeffery Xu Yu
journal=sigmod
year=2018
tags=set Intersections, graph algorithms, SIMD, subgraph matching, triangle counting, clique detection, graph ordering, graph processing, bitmap
star=****
problem=
interest=set intersection is widely used in graph algorithms, occupying a large potion of time
hardness=
idea=a binary representation scheme(BSR) to encode adjacency-lists, a merge-based intersection algorithm(QFilter), the node ordering also affects the performance by influencing the compactness of BSR sets
future=
comment=
other=similar idea to [id:66]
---
id=56
title=Randomized Algorithms Accelerated over CPU-GPU for Ultra-High Dimensional Similarity Search
author=Yiqiu Wang, Anshumali Shrivastava
journal=sigmod
year=2018
tags=CPU-GPU, similarity search, locality sensitive hashing, reservoir sampling, GPGPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=57
title=Logarithmic Radix Binning and Vectorized Triangle Counting
author=
journal=HPEC (HPEC Graph Challenge Innovation Award)
year=2018
tags=Logarithmic Radix Binning, Vectorized Triangle Counting, GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=58
title=A (Sub)Graph Isomorphism Algorithm for Matching Large Graphs (vf2)
author=Luigi P. Cordella, Pasquale Foggia, Carlo Sansone, Mario Vento
journal=IEEE Transactions on Pattern Analysis and Machine Intelligence(TPAMI, CCF A journal of Artificial Intelligence)
year=2004
tags=vf2,graph-subgraph isomorphism,induced subgraph,depth-first search,Backtrack paradigm,backtracking,large graphs, attributed relational graphs
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=based on induced subgraph rather than embedding subgraph;the implementation is very critical; much better than [id:59]
---
id=59
title=An Algorithm for Subgraph Isomorphism
author=J. R. Ullmann
journal=Journal of the Association for Computing Machinery(JACM, CCF A Journal)
year=1976
tags=graph, graph isomorphism, directed graph isomorphism, digraph isomorphism, subgraph, subgraph isomorphism, clique, clique detection, isomorphism algorithm, tree search, search tree, game tree, parallel processing, array processing, special purpose computer, logic-in-memory arrays, asynchronous sequential circuits, Boolean matrices
star=*****
problem=
interest=
hardness=
idea=
future=
comment=based on Linear Algebra
other=
---
id=60
title=Taming verification hardness: an efficient algorithm for testing subgraph isomorphism   (QuickSI)
author=Haichuan Shang, Ying zhang, xuemin lin, Jeffery Xu Yu
journal=VLDB
year=2008
tags=QuickSI
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=61
title= The transitive reduction of a directed graph
author=
journal=SIAM
year=1972
tags=transitive reduction, directed graph
star=****
problem=
interest=
hardness=
idea=
future=
comment=the complexity of transitive reduction is O(n^3) for a graph of n vertices.
other=used by BoostISO, [id:6] of yuqizhou.list
---
id=62
title=Efficient Subgraph Matching by Postponing Cartesian Products (CFL-Match)
author=Fei Bi, Lijun Chang, Xuemin Lin, Lu Qin, Wenjie Zhang
journal=SIGMOD
year=2016
tags=subgraph matching, subgraph isomorphism, core-forest, CFL-Match, CPI-index, core-forest-leaf decomposition
star=****
problem=unpromising results by Cartesian products from dissimilar vertices
interest=
hardness=
idea=core-forest-leaf decomposition, CPI index to prepare candidates for joining phase, matching order based on path with the minimum growing cost
future=k-core decomposition, extend to directed graphs with edge labels, consider parallel and distributed
comment=too complicated and not widely used
other=
---
id=63
title=Comparing performance of graph matching algorithms on huge graphs
author=Vincenzo Carletti
journal=Pattern Recognition Letters (PRL, CCF C Conference of AI)
year=2018
tags=subgraph isomorphism;subgraph matching,pattern recognition
star=***
problem=
interest=
hardness=
idea=compare vf2, vf3, RI(these three are tree-based), LAD and PathLAD(these two are constraint programming) on all kinds of graphs
future=
comment=no one beats others totally; vf3 is generally better, and better tradeoff between time and memory cost;vf2 is best at small graphs; vf3 is the disputed winner for finding the first solution; vf3 and RI confirmed to be a step forward with respect to the other algorithms for finding all solutions; it is advisable to use vf3 for most subgraph isomorphism problems
other=associated with ICPR contest; the experimental result in vf3
---
id=64
title=Computers and Intractability: A Guide to the Theory of NP-Completeness
author=M. R. Garey , David S. Johnson
journal=W. H. Freeman
year=1979
tags=NP-hard,NPC,NP-completeness,algorithm complexity,Intractability
star=*****
problem=
interest=
hardness=
idea=
future=
comment=notice that NPC is decision problems, but NP-hard is not
other=
---
id=65
title=Accelerating Large Graph Algorithms on the GPU Using CUDA
author=Pawan Harish
journal=HiPC (CCF C Conference of high performance Computing, also called HPC)
year=2007
tags=gpu,cuda,bfs,breadth-first search,sssp, apsp, bellman-ford
star=**
problem=
interest=
hardness=
idea=
future=
comment=an early but basic implementation of these algorithms on GPU; Provide parallel implementation of Bellman-ford algorithm
other=
---
id=66
title=Fast Online Set Intersection for Network Processing on FPGA
author=Yun R. Qu, Viktor K. Prasanna
journal=TPDS(CCF A)
year=2016
tags=set intersection,network processing, field-programmable gate array(FPGA), bitmap
star=****
problem=For real-time network processing, the major challenge of set intersection is the strict performance requirement. Sets have to be intersected at very high throughput to sustain line-rate processing
interest=very common  and useful operator
hardness=all the elements of the sets are presorted but only known during run-time
idea=divide a set into multiple groups, compare groups of difdferent sets using LA algorithm(merge-join) and use bitwise-and for elements in the same group ID(BA algorithm); tree-based parallel architecture; only encode at the begining and decode at last
future=
comment=assume the lists are all sorted in the same order; able to deal with many sets
other=
---
id=67
title=Worst-case Optimal Join Algorithms
author=Hung Q. Ngo, Ely Porat
journal=PODS(CCF B, but the highest conference in database theory)
year=2012
tags=join Algorithm analysis, theoretical bound, natural join query, database research, relational table, worst-case data complexity, relational database, fractional cover bound, Loomis-Whitney inequality, Bollobás-Thomason inequality
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=68
title=Skew Strikes Back: New Developments in the Theory of Join Algorithms 
author=Hung Q. Ngo
journal=SIGMOD
year=2013
tags=join Algorithm analysis, skew data, theoretical bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=a graph with N edges has power(N, 3/2) distinct triangles
---
id=69
title=Leapfrog Triejoin: A Simple, Worst-Case Optimal Join Algorithm
author=Todd L. Veldhuizen
journal=Computer Science(arXiv preprint)
year=2012
tags=Algorithms, Theory, worst-case optimal join
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other= We show that NPRR is not worst-case optimal for such classes, giving a counterexample where leapfrog triejoin runs in O(nlogn) tiem and NPPR runs in theta(power(n, 1.375)) time
---
id=70
title=Join processing for graph patterns: An old dog with new tricks
author=Dung Nguyen
journal=Proceedings of the GRADES
year=2015
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=71
title=A Worst-Case Optimal Multi-Round Algorithm for Parallel Computation of Conjunctive Queries
author=Bas Ketsman, Dan Suciu
journal=PODS
year=2017
tags=parallelism, Conjunctive queries, multi-round, Worst-Case Optimal
star=****
problem=study the optimal communication cost for computing a full conjunctive query Q over p distributed servers
interest=
hardness=
idea=
future=
comment=
other=
---
id=72
title=Graph pattern matching: from intractable to polynomial time
author=Wenfei Fan
journal=VLDB
year=2010
tags=graph simulation
star=****
problem=define the graph simulation problem instead of graph matching
interest=
hardness=
idea=
future=
comment=
other=
---
id=73
title=Distributed exact subgraph matching in small diameter dynamic graphs
author=Charith Wickramaarachchi 
journal=Big Data
year=2016
tags=distributed subgraph matching, small diameter, dynamic graph
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=74
title=Bloom Filters, Adaptivity, and the Dictionary Problem
author=Michael A. Bender
journal=IEEE Symposium on Foundations of Computer Science(FOCS, CCF A of computer science)
year=2018
tags=bloom filters, Adaptivity, Dictionary, algorithm and data structures
star=****
problem=the probability guarantee of an approximate membership query data structure(Bloom, quotient, cuckoo filter)
interest=
hardness=
idea=
future=
comment=
other=
---
id=75
title=A Faster Isomorphism Test for Graphs of Small Degree
author=
journal=FOCS
year=2018
tags=Isomorphism test, small degree graphs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=76
title=Nearly work-efficient parallel algorithm for digraph reachability
author=
journal=STOC
year=2018
tags=work-efficient parallel algorithm, digraph reachability, graph algorithms
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=77
title=The query complexity of graph isomorphism: bypassing distribution testing lower bounds
author=
journal=STOC
year=2018
tags=graph isomorphism, query complexity, lower bounds
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=78
title=Round Compression for Parallel Matching Algorithms
author=
journal=ACM Symposium on Theory of Computing(STOC, CCF A of computer science)
year=2018
tags=round Compression, parallel matching Algorithms
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=79
title=Parallel Graph Connectivity in Log Diameter Rounds
author=
journal=FOCS
year=2018
tags=parallel Algorithms, graph Algorithms, graph Connectivity, log diameter
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=80
title=An exponential lower bound for Individualization-Refinement algorithms for Graph Isomorphism
author=
journal=STOC
year=2018
tags=graph Isomorphism, Individualization-Refinement algorithms, exponential lower bound
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=81
title=SIMD- and Cache-Friendly Algorithm for Sorting an Array of Structures
author=Hiroshi Inoue, Kenjiro Taura
journal=VLDB
year=2015
tags=SIMD, Cache, multiway sorting, vectorized algorithm
star=****
problem=sorting an array of structures by efficiently exploiting the SIMD instructions and cache memory
interest=sorting is common in database and the power of simd and cache is common and widely used now;exist SIMD libraries focus on sorting integers
hardness=if packing key and index(64 bit), then the cache miss of random access in the final rearrangement is severe; if sorting the whole structure directly, then keys need to be read veery time and the movement of all structures is costly
idea=based on multiway mergesort, does the key encoding and record rearranging for each multiway merge stage, while the key-index approach does the encoding only at the beginning of the entire sorting operation and record rearrangement at the end
future=
comment=
other=an improvement of [id:192]
---
id=82
title=Finding, Counting and Listing all Triangles in Large Graphs, An Experimental Study
author=Thomas Schank, Dorothea Wagner
journal=International Workshop on Experimental & Efficient Algorithms
year=2001
tags=Triangle Counting, Triangle Listing, Complexity Analysis
star=****
problem=the complexity and efficiency of algorithms of counting and listing triangles in large graphs
interest=very common and useful
hardness=
idea=a clique of vertex num n has almost n*n*n triangles; a graph of edge num n has O(m^1.5) triangles
future=
comment=
other=
---
id=83
title=FPGA acceleration of semantic tree reasoning algorithms
author=
journal=Journal of Systems Architecture
year=
tags=FPGA acceleration Algorithms, semantic tree
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=84
title=TRIÈST: Counting Local and Global Triangles in Fully-Dynamic Streams with Fixed Memory Size
author=
journal=SIGKDD
year=2016
tags=Triangle counting, dynamic stream
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=85
title=High Performance Exact Triangle Counting on GPUs
author=Mauro Bisson
journal=TPDS
year=2017
tags=Triangle counting, Graph processing, GPU Computing, Parallel computing, Big Data, CUDA, bitmap
star=****
problem=
interest=
hardness=
idea=based on node and CSR structure, matrix multiplication
future=
comment=
other=general triangle counting based on edge has complexity as O(|E|^1.5); naive methods will have 6 duplicates, but there are perfect strategy to eliminate all duplicates which just need a order definition and only save edges satisfying this order; use order of degree(only save edges from high degree to low degree) yield wonderful performance because high degree nodes are evenly divided and result in natural load balance
---
id=86
title=Space/Time Trade-offs in Hash Coding with Allowable Errors (Bloom Filter)
author=Burton H. Bloom
journal=Communications of the ACM
year=1970
tags=hash coding, hash addressing, scatter storage, searching, storage layout, retrieval trade-offs, retrieval efficiency, storage efficiency, bloom filter
star=*****
problem=reduce the hash area size(m) when allowing a small error(false positive) targeting at judging if an element is in a given set(size is n)
interest=it is a very common primitive to judge many times if an element is in a set(the total elements are much larger than this set)
hardness=how to keep a tradeoff between hash area and reject time, how to provide a theorectical guarantee on the falso positive error
idea=two methods that are different from the conventional error-free hash; use multiple hash functions to reduce the errors while keeping a small hash array
future=how to distinguish elements with high frequency and low frequency
comment=the first wonderful work to come up with the idea of bloom filter; it is very suitable for many judgements on a not-so-large set and many judgements are invalid(then needless to access the high-latency memory); it is widely used in GPU, FPGA and CPU cache; to yield an ideal performance, the size of hash array is required to be two times larger than the size of set
other=if use a single hash function to reduce the conflict rate to 0.01, we need to use a hash array whose size is 100 times of the number of elements; http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html ; 哈希函数的选择对性能的影响应该是很大的，一个好的哈希函数要能近似等概率的将字符串映射到各个Bit。选择k个不同的哈希函数比较麻烦，一种简单的方法是选择一个哈希函数，然后送入k个不同的参数; 对于给定的m、n，当 k = ln(2)* m/n 时出错的概率是最小的; https://blog.csdn.net/jiaomeng/article/details/1495500
---
id=87
title=HeavyKeeper: An Accurate Algorithm for Finding Top-k Elephant Flows
author=Junzhi Gong, Tong Yang
journal=USENIX Annual Technical Conference
year=2018
tags=data stream, top-k, data flow, network traffic, frequency
star=****
problem=
interest=
hardness=
idea=we adopt a new strategy, called count-with-exponential-decay, to achieve space-accuracy balance by actively removing small flows through decaying, while minimizing the impact on large flows, so as to achieve high precision in finding top-k elephant flows. Moreover, the proposed algorithm called HeavyKeeper incurs small, constant processing overhead per packet and thus supports high line rates
future=
comment=
other=
---
id=88
title=Optimizing N-Dimensional, Winograd-Based Convolution for Manycore CPUs
author=Zhen Jia
journal=PPoPP
year=2018
tags=N-dimensional, winograd, Convolution, manycore CPUs, high-performance computing, machine learning
star=****
problem=existing implementations are limited to 2D data and a single kernel size of 3 by 3.
interest=
hardness=
idea=
future=
comment=
other=winograd http://shuokay.com/2018/02/21/winograd/ ;
---
id=89
title=SuperNeurons: Dynamic GPU Memory Management for Training Deep Neural Networks
author=Linnan Wang, Jinmian He
journal=PPoPP
year=2018
tags=GPU, Neural network, Deep Learning(DL), dynamic GPU memory management, SuperNeurons, machine learning
star=****
problem=
interest=deeper and wider neural network can provide higher accuracy; free DL(Deep Learning) practitioners from adjusting bottom GPU architecture
hardness=mmeory capacity, long training time
idea=a dynamic GPU memory scheduling runtime to enable the network training far beyond the GPU DRAM capacity. SuperNeurons features 3 memory optimizations, Liveness Analysis, Unified Tensor Pool, and Cost-Aware Recomputation; together they effectively reduce the network-wide peak memory usage down to the maximal memory usage among layers. We also address the performance issues in these memory-saving techniques
future=
comment=
other=
---
id=90
title=Transparent GPU Memory Management for DNNs   (demo)
author=Jungho Park
journal=PPoPP(demo, two pages)
year=2018
tags=GPU memory management, DNN, machine learning
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=91
title=Bridging the Gap between Deep Learning and Sparse Matrix Format Selection
author=Yue Zhao
journal=PPoPP
year=2018
tags=Deep Learning, Sparse Matrix Format Selection, Sparse Matrix Vector multiplication(SpMV), Machine Learning
star=****
problem=determining the best storage format for a matrix to maximize the performance of Sparse Matrix Vector Multiplication (SpMV). It describes how to effectively bridge the gap between deep learning and the special needs of the pillar HPC problem through a set of techniques on matrix representations, deep learning structure, and cross-architecture model migrations
interest=
hardness=
idea=
future=
comment=
other=COO, CSR, CSC, BSR (Block Compressed Sparse Row Format)
---
id=92
title=FlashR: Parallelize and Scale R for Machine Learning using SSDs
author=Da Zheng
journal=PPoPP
year=2018
tags=parallel algorithm, R language, Solid-state drives(SSD), Machine Learning
star=****
problem=R is one of the most popular programming languages for statistics and machine learning, but it is slow and unable to scale to large datasets.
interest=
hardness=
idea=FlashR accelerates and scales existing R code by parallelizing a large number of matrix functions in the R base package and scaling them beyond memory capacity with solid-state drives (SSDs). FlashR performs memory hierarchy aware execution to speed up parallelized R code by (i) evaluating matrix operations lazily, (ii) performing all operations in a DAG in a single execution and with only one pass over data to increase the ratio of computation to I/O, (iii) performing two levels of matrix partitioning and reordering computation on matrix partitions to reduce data movement in the memory hierarchy
future=
comment=
other=best paper candidate
---
id=93
title=Featherlight On-the-fly False-sharing Detection
author=Milind Chabbi
journal=PPoPP
year=2018
tags=False-sharing Detection, shared-memory parallism, CPU cacheline, performance monitoring units(PMU), debug registers
star=****
problem=Shared-memory parallel programs routinely suffer from false sharing—a performance degradation caused by different threads accessing different variables that reside on the same CPU cacheline and at least one variable is modified
interest=State-of-the-art tools detect false sharing via a heavyweight process of logging memory accesses and feeding the ensuing access traces to an offline cache simulator
hardness=
idea=achieves low overhead by exploiting two hardware features ubiquitous in commodity CPUs: the performance monitoring units (PMU) and debug registers. Additionally, Feather is a first-of-its-kind tool to detect false sharing in multi-process applications
future=
comment=
other=best paper candidate
---
id=94
title=Cache-Tries: Concurrent Lock-Free Hash Tries with Constant-Time Operations
author=Aleksandar Prokopec
journal=PPoPP
year=2018
tags=parallel algorithm, data structure, trie, lock-free, concurrent, hash, constant-time, cache-friendly
star=****
problem=operations on most existing concurrent hash tries run in O(logn) time
interest=
hardness=
idea=
future=
comment=
other=best paper candidate
---
id=95
title=Register Optimizations for Stencils on GPUs
author=Prashant Singh Rawat
journal=PPoPP  (best paper)
year=2018
tags=Compiler Optimization, register Optimization, register pressure, optimal schedule, heuristic algorithm, Stencils, GPU, Loop Unroll, CUDA, ILP(Instruction-level parallelism)
star=*****
problem=register pressure in complex high order Stencils(compute-intensive and much data sharing)
interest=卷积/模板运算非常普遍（偏微分方程，数学物理，计算化学，图像处理，信号处理，神经网络等），且卷积的结构和大小对 算法的精度有很大的影响。卷积运算中存在大量的数据共享，通常的做法是loop unroll 或者shared memory
hardness=logical induction and mathematical analysis, as well as the difficulity of using GPU
idea=在保证spill-free 的前提下，降低MAXLIVE 时间，即同一时刻寄存器最大使用量。这可以通过最大化各执行树之间的共享，并改善调度算法来实现; develop a statement reordering framework that models stencil computations as a DAG of trees with shared leaves, and adapts an optimal scheduling algorithm for minimizing register usage for expression trees(计算最优调度的复杂度太高，实际上是用启发式 算法来找一个较优的调度)
future=maybe apply the optimizations to more primitives
comment=a solid work that targets at the optimization of a specific primitive which is widely used
other=best paper candidate; nvcc is not opensourced and gpucc is just a front-end which also uses nvcc as backend, LLVM(low level virtue machine) is opensourced; the compiler optimization is more important and widely than code optimization, but more difficult; the prons and cons of kernel fusion and kernel fission; pattern-specific optimization techniques have demonstrably been more beneficial, as well as algorithms, protocols, chips, systems and so on
---
id=96
title=Practical Concurrent Traversals in Search Trees
author=
journal=PPoPP
year=2018
tags=Concurrent Traversal, search tree, optimistic concurrency-control scheme, validation
star=****
problem=Operations of concurrent objects often employ optimistic concurrency-control schemes that consist of a traversal followed by a validation step. The validation checks if concurrent mutations interfered with the traversal to determine if the operation should proceed or restart. A fundamental challenge is to discover a necessary and sufficient validation check that has to be performed to guarantee correctness.
interest=
hardness=
idea=a necessary and sufficient condition for validating traversals in search trees. The condition relies on a new concept of succinct path snapshots, which are derived from and embedded in the structure of the tree; a general lock-free membership test suitable for any search tree
future=
comment=
other=
---
id=97
title=LazyGraph: Lazy Data Coherency for Replicas in Distributed Graph-Parallel Computation
author=Lei Wang
journal=PPoPP
year=2018
tags=Lazy Data Coherency, Distributed Graph-parallel Computation, Execution Model, node replicas
star=****
problem=any changes to vertex data must be immediately communicated to all replicas of v, leading to frequent global synchronization and communications.
interest=
hardness=
idea=
future=
comment=
other=
---
id=98
title=PAM: Parallel Augmented Maps
author=Yihan Sun
journal=PPoPP
year=2018
tags=parallel algorithm, data structure, ordered map
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=99
title=Griffin: Uniting CPU and GPU in Information Retrieval Systems for Intra-Query Parallelism
author=Yang Liu
journal=PPoPP
year=2018
tags=
star=****
problem=previous work runs queries either on GPU or CPU, ignoring the fact that the best processor for a given query depends on the query’s characteristics, which may change as the processing proceeds.
interest=
hardness=
idea=dynamically combines GPU- and CPU-based algorithms to process individual queries according to their characteristics; leveraging a new compression scheme and exploiting an advanced merge-based intersection algorithm
future=
comment=
other=
---
id=100
title=Juggler: A Dependence-Aware Task-Based Execution Framework for GPUs
author=
journal=PPoPP
year=2018
tags=GP-GPU programming, task-based execution, data dependence, OpenMP 4.5
star=****
problem=the existence of data dependences across thread blocks may significantly impact the speedup by requiring global synchronization across multiprocessors (SMs) inside the GPU
interest=
hardness=
idea=a task-based execution scheme for GPU workloads with data dependences. The Juggler framework takes applications embedding OpenMP 4.5 tasks as input and executes them on the GPU via an efficient in-device runtime, hence eliminating the need for kernel-wide global synchronization
future=
comment=
other=
---
id=101
title=Interval-Based Memory Reclamation
author=Haosen Wen
journal=PPoPP
year=2018
tags=memory reclamation, concurrent data structures, safe reclamation, disconnected memory blocks
star=****
problem=a thread, before freeing a block, must ensure that no other threads are accessing that block; the required synchronization tends to be expensive.
interest=
hardness=In contrast with epoch-based reclamation, in which threads reserve all blocks created after a certain time, or pointerbased reclamation (e.g., hazard pointers), in which threads reserve individual blocks
idea=By comparing a thread’s reserved interval with the lifetime of a detached but not yet reclaimed block, the system can determine if the block is safe to free. Like hazard pointers, IBR avoids the possibility that a single stalled thread may reserve an unbounded number of blocks; unlike hazard pointers, it avoids a memory fence on most pointer-following operations.  It also avoids the need to explicitly “unreserve” a no-longer-needed pointer.
future=
comment=
other=
---
id=102
title=Efficient Parallel Lists Intersection and Index Compression Algorithms using Graphics Processing Units
author=Naiyong Ao, Fan Zhang, Di Wu
journal=VLDB
year=2011
tags=parallel Algorithm, list Intersection, index Compression, GPU, linear regression, machine learning, binary search
star=****
problem=
interest=
hardness=
idea=linear regression(x is the list index, y is the elements) and hash segmentation(hash into buckets, then in bucket do normal binary search) to speed up list intersection by contracting the search range; for index compression, propose a Linear Regression Compression schema which has an inherent parallel structure
future=
comment=
other=in web search a sentence is divided into several keywords and each keyword returns a sorted list of document IDs, the final job is to intersect these lists; d-gap compression: in the list of document IDs, if using variable byte encoding, then using the difference between two IDs instead of the IDs themselves is better
---
id=103
title=Improving Medium-Grain Partitioning for Scalable Sparse Tensor Decomposition
author=Seher Acer
journal=TPDS
year=2018
tags=tensor decomposition, CPD-ALS, CartHP, distributed-memory-parallel algorithm, sparse tensor, canonical polyadic decomposition, cartesian partitioning, load balancing, communication volume, hypergraph partitioning
star=****
problem=CPD-ALS does not utilize the sparsity pattern of the tensor to reduce the total communication volume
interest=tensor decomposition is widely used and High computational and memory costs of CPD-ALS necessitate the use of a distributed-memory-parallel algorithm for efficiency
hardness=
idea=
future=
comment=
other=
---
id=104
title=Developing User Perceived Value Based Pricing Models for Cloud Markets
author=Peijin Cong, Liying Li
journal=TPDS
year=2018
tags=Cloud computing, Dynamic Pricing Model, User Perceived Value, Profit Maximization, Augmented Lagrange Function
star=****
problem=existing pricing models rarely consider the dynamic interactions between user requests and the cloud service provider
interest=With the rapid deployment of cloud computing infrastructures, understanding the economics of cloud computing has become a pressing issue for cloud service providers
hardness=
idea=a dynamic pricing model based on the concept of user perceived value that accurately captures the real supply and demand relationship in the cloud service market. Subsequently, a profit maximization scheme is designed based on the dynamic pricing model that optimizes profit of the cloud service provider without violating service-level agreement. Finally, a dynamic closed loop control scheme is developed to adjust the cloud service price and multiserver configurations according to the dynamics of the cloud computing environment such as fluctuating electricity and rental fees
future=
comment=
other=
---
id=105
title=Competitiveness of a Non-Linear Block-Space GPU Thread Map for Simplex Domains
author=Matthieu Vernier
journal=TPDS
year=2018
tags=GPU thread mapping, block-space, simplex domains, GPU optimization
star=****
problem=unnecessary threads assign in a special problem domain; for example, only the lower triangle of a matrix is really used or symmetric
interest=
hardness=
idea=
future=
comment=
other=
---
id=106
title=Analysis and Design Techniques towards High-Performance and Energy-Efficient Dense Linear Solvers on GPUs
author=Ahmad Abdelfattah
journal=TPDS
year=2018
tags=Dense linear solvers, GPU computing, energy efficiency, matrix factorization, Algorithm
star=****
problem=existing hybrid CPU-GPU strategies have probolems of less efficiency and high energy consuming
interest=Graphics Processing Units (GPUs) are widely used in accelerating dense linear solvers. The matrix factorizations, which dominate the runtime for these solvers, are often designed using a hybrid scheme, where GPUs perform trailing matrix updates, while the CPUs perform the panel factorizations
hardness=
idea=This paper presents analysis and design techniques that overcome the shortcomings of the hybrid algorithms, and allow the design of high-performance and energy-efficient dense LU and Cholesky factorizations that use GPUs only.
future=
comment=
other=CuSOLVER by Nvidia is the existing algorithm that only uses GPU
---
id=107
title=Eunomia: Scaling Concurrent Search Trees under Contention Using HTM
author=Xin Wang
journal=TPDS
year=2018
tags=Hardware Transactional Memory(HTM), Concurrent Search Tree, Opportunistic Consistency, Concurrency Control
star=****
problem=with the assistance of HTM, can we construct a concurrent search tree structure that delivers high and scalable performance even under high contention
interest=hardware transactional memory (HTM) has recently been adopted to construct efficient concurrent search tree structures, such designs fail to deliver scalable performance under contention
hardness=
idea=First, based on the observation that most HTM conflicts happen in the leaf layer, we partition a monolithic HTM region into multiple parts and protect the atomicity of different parts using HTM respectively.  A version-based scheme is utilized to guarantee overall consistency at the boundary of different HTM regions. With this scheme, most conflicts only cause retry within the partitioned transaction pieces, instead of the entire monolithic transaction. Second, to eliminate false conflicts incurred by consecutive data layout and metadata accesses, Eunomia refactors the tree structure in a partitioned way, which dispatches concurrent requests to different segments. Third, to throttle the true conflicting requests, Eunomia adopts an efficient mechanism, which anticipates potential conflicts and avoids them accordingly. Finally, Eunomia adopts an adaptive contention control mechanism, which can detect various contention rates and achieve high performance under both high and low contention.
future=
comment=
other=https://en.wikipedia.org/wiki/Transactional_memory
---
id=108
title=Confluence: Speeding Up Iterative Distributed Operations by Key-Dependency-Aware Partitioning
author=Feng Liang
journal=TPDS
year=2018
tags=Spark, shuffle, key dependency, iterative distributed operation, partitioning, Map Reduce, Algorithm
star=****
problem=A typical shuffle operation randomly partitions data on many computers, generating possibly a significant amount of network traffic which often dominates a job’s completion time
interest=This traffic is particularly pronounced in iterative distributed operations where each iteration invokes a shuffle operation(like MapReduce)
hardness=
idea=If data generated by the current iteration are partitioned to the computers where they will be processed in the next iteration, unnecessary shuffle network traffic between the two iterations can be prevented
future=
comment=
other=there is a figure of MapReduce in this figure which explains the idea clearly
---
id=109
title=Organization and maintenance of large ordered indexes
author=Bayer, Rudolf and McCreight, Edward
journal=Software pioneers
year=2002
tags=B+ tree, large ordered indices, Bplus tree, the evolution of B-tree, Data structure
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=110
title=Argobots: A Lightweight Low-Level Threading and Tasking Framework
author=Sangmin Seo
journal=TPDS
year=2018
tags=Argobots, user-level thread, tasklet, OpenMP, MPI, I/O, interoperability, lightweight, context switch, stackable scheduler, concurrency, Framework
star=****
problem=Current state-of-the-art user-level threading and tasking models, however, either are too specific to applications or architectures or are not as powerful or flexible
interest=a number of user-level threading and taskingmodels have been proposed in the literature to address the shortcomings of OS-level threads, primarily with respect to cost and flexibility
hardness=
idea=Argobots offers a carefully designed execution model that balances generality of functionalitywith providing a rich set of controls to allow specialization by end users or high-level programmingmodels; We describe the design, implementation, and performance characterization of Argobots and present integrations with three high-levelmodels: OpenMP,MPI, and colocated I/O services
future=
comment=experiment and evaluation are the main parts of this paper
other=
---
id=111
title=An Auto-Tuner for OpenCL Work-Group Size on GPUs
author=Thanh Tuan Dao
journal=TPDS
year=2018
tags=GPU, auto-tuning, workload characterization, workgroup size, OpenCL, NVIDIA, AMD
star=****
problem=Tuning the kernel work-group size for GPUs is a challenging problem
interest=the most influential performance factors with regard to the work-group size include occupancy, coalesced global memory accesses, cache contention, and variation in the amount of workload in the kernel
hardness=
idea=using the performance counters provided by GPUs, we characterize a large body of OpenCL kernels to identify the performance factors that affect the choice of a good work-group size
future=maybe use Machine Learning for tuning parameters
comment=We show the effectiveness of our auto-tuner by evaluating it with a set of 54 OpenCL kernels on three different NVIDIA GPUs and one AMD GPU; find sub-optimal work-group size within a small time interval and the performance is very closed to the optimal one
other=nvidia cuda now also supports varied work group size
---
id=112
title=Easy PRAM-Based High-Performance Parallel Programming with ICE
author=Fady Ghanim
journal=TPDS
year=2018
tags=ICE, ease of programming, irregular programs, PRAM(parallel random-access machine/model), fine-grained parallelism, XMT, nested ICE, nested parallelism
star=****
problem= Unfortunately parallel programming technologies have advanced at a much slower pace except for regular programs
interest=Parallel machines have become more widely used.
hardness=For irregular programs, this advancement is inhibited by high synchronization costs, non-loop parallelism, non-array data structures, recursively expressed parallelism and parallelism that is too fine-grained to be exploitable.
idea=easy-to-program, since: (i) ICE is a synchronous, lock-step language so there is no need for programmer-specified synchronization; (ii) for a PRAM algorithm its ICE program amounts to directly transcribing it; and (iii) the PRAM algorithmic theory offers unique wealth of parallel algorithms and techniques
future=
comment=
other=
---
id=113
title=AIRA: A Framework for Flexible Compute Kernel Execution in Heterogeneous Platforms
author=Robert Lyerly
journal=TPDS
year=2018
tags=Heterogeneous architectures, compilers, runtimes, programming models, architecture selection, CPU-GPU
star=****
problem=
interest=Heterogeneous-ISA computing platforms have become ubiquitous, and will be used for diverse workloads which render static mappings of computation to processors inadequate
hardness=
idea=Dynamic mappings which adjust an application’s usage in consideration of platform workload can reduce application latency and increase throughput for heterogeneous platforms
future=
comment=
other=
---
id=114
title=MSGD: A Novel Matrix Factorization Approach for Large-scale Collaborative Filtering Recommender Systems on GPUs
author=Hao Li, Kenli Li
journal=TPDS
year=2018
tags=Collaborative filtering (CF), CUDA parallelization algorithm, Matrix factorization (MF), Multi-GPU implementation, Stochastic gradient descent (SGD).
star=****
problem=stochastic gradient descent (SGD) is one of the most famous approaches for MF. However, it is non-trivial to parallelize SGD for large-scale problems due to the dependence on the user and item pair, which can cause parallelization over-writing
interest=Real-time accurate recommendation of large-scale recommender systems is a challenging task. Matrix factorization (MF), as one of the most accurate and scalable techniques to predict missing ratings, has become popular in the collaborative filtering (CF) community
hardness=To remove the dependence on the user and item pair, we propose a multi-stream SGD (MSGD) approach, for which the update process is theoretically convergent
idea=divides the task into coarse sub-tasks that are mapped to independent thread blocks, and then be solved by those independent thread blocks. Each sub-task is divided into finer pieces that map to threads within the thread block, then be solved cooperatively by those threads in parallel.
future=
comment=
other=
---
id=115
title=Neurostream: Scalable and Energy Efficient Deep Learning with Smart Memory Cubes
author=Erfan Azarkhish
journal=TPDS
year=2018
tags=Hybrid memory cube, convolutional neural networks, large-scale deep learning, streaming floating-point
star=****
problem=
interest=High-performance computing systems aremoving towards 2.5D and 3Dmemory hierarchies, based onHigh Bandwidth Memory (HBM) and HybridMemory Cube (HMC) tomitigate themainmemory bottlenecks
hardness=
idea=Our co-design approach consists of a network ofSmart Memory Cubes (modular extensions to the standard HMC) each augmented with a many-core PIMplatformcalled NeuroCluster. NeuroClusters have amodular design based onNeuroStreamcoprocessors (forConvolutionintensive computations) and general-purpose RISC-V cores
future=
comment=a flexible processor-in-memory (PIM) solution for scalable and energy-efficient execution of deep convolutional networks (ConvNets), one of the fastest-growing workloads for servers and high-end embedded systems.
other=brain-inspired computing (BIC), near-memory computation
---
id=116
title=Toward High Mobile GPU Performance Through Collaborative Workload Offloading
author=Chao Wu
journal=TPDS
year=2018
tags=Mobile applications, distributed system, code offload, performance optimization, collaborative workload offloading
star=****
problem=the challenge of poor hardware support but fine-grained rendering details often makes user unsatisfied especially in calling for high frame rate scenarios, e.g., game
interest=The ever increasing of display resolution on mobile devices raises high demand for GPU rendering details
hardness=
idea=ButterFly, a novel system which collaboratively utilizes mobile GPUs to process high-quality rendering details for on-the-go mobile users
future=
comment=utilize mobile GPUs in the same wifi to provide better display
other=
---
id=117
title=Fast K-selection Algorithms for Graphics Processing Units
author=TOLU ALABI
journal=ACM Journal of Experimental Algorithmics
year=2012
tags=Algorithms, Design, Experimentation, Performance, Top-K, K-selection, Order Statistics, Multi-core, Graphics Processing Units, GPGPU, CUDA, radixSelect, bucketSelect, concurrent programming, parallel programming
star=****
problem=Finding the kth largest value in a list of n values
interest=
hardness=sort maybe done extra work
idea=sort&choose, radixSelect, bucketSelect
future=
comment=in sequential algorithm the k-selection problem has solutions running in O(n) time
other=https://github.com/yuxianzhi/Top-K; https://devtalk.nvidia.com/default/topic/814439/cuda-programming-and-performance/top-k-elements-selection-/
---
id=118
title=gem5-gpu: A Heterogeneous CPU-GPU Simulator
author=Jason Power
journal=Computer Architecture Letters
year=2015
tags=Modeling techniques, Simulators, Heterogeneous (hybrid) systems, General-purpose graphics processors, GPU
star=***
problem=gem5-gpu is a new simulator that models tightly integrated CPU-GPU systems
interest=It builds on gem5, a modular fullsystem CPU simulator, and GPGPU-Sim(id=172), a detailed GPGPU simulator.
hardness=GPGPU-Sim is unable to model the interactions between CPU and GPU
idea=
future=
comment=
other=
---
id=119
title=Parallel Spectral Graph Partitioning
author=Maxim Naumov
journal=NVIDIA Technical Report
year=2016
tags=Spectral graph, multi-level Partition scheme
star=****
problem=
interest=the behavior of our spectral scheme and popular multi-level schemes is starkly different for two classes of problems: (i) social network graphs that often have power law-like distribution of edges per node and (ii) meshes arising from discretization of partial differential equations 
hardness=
idea=a novel parallel spectral partitioning method that takes advantage of an Exploringcient implementation of a preconditioned eigenvalue solver and a k-means algorithm on the GPU
future=in our numerical experiments the multi-level schemes are almost always faster, we show that our spectral scheme can achieve a significantly higher quality of partitioning for the social network graphs
comment=the usage of spectral graph theory in graph partition
other=
---
id=120
title=A conjugate gradient method for the spectral partitioning of graphs
author=
journal=Parallel Computing
year=1997
tags=共轭梯度法(Conjugate Gradient Method),spectral graph theory, spectral partitioning 
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=121
title=An Improved Spectral Graph Partitioning Algorithm for Mapping Parallel Computations
author=Bruce Hendrickson
journal=SIAM Journal on Scientific Computing
year=1992
tags=Spectral graph Partitioning, parallel computing
star=****
problem=Efficient use of a distributed memory parallel computer requires that the computational load be balanced across processors in a way that minimizes interprocessor communication.
interest=
hardness=
idea=Our generalization of spectral graph bisection involves a novel use of multiple eigenvectors to allow for division of a computation into four or eight parts at each stage of a recursive decomposition. The resulting method is suitable for scientific computations like irregular finite elements or differences performed on hypercube or mesh architecture machines.
future=
comment=
other=
---
id=122
title=A Hybrid B+-tree as Solution for In-Memory Indexing on CPU-GPU Heterogeneous Computing Platforms (HB+Tree)
author=Amirhesam Shahvarani
journal=SIGMOD
year=2016
tags=Heterogeneous Computing, Indexing, In-memory Database, B+-tree, CPU-GPU, HB+Tree
star=****
problem=An in-memory indexing tree is a critical component of many databases
interest=Modern many-core processors, such as GPUs, are offering tremendous amounts of computing power making them an attractive choice for accelerating indexing
hardness=the memory available to the accelerating co-processor is rather limited and expensive in comparison to the memory available to the CPU. This drawback is a barrier to exploit the computing power of co-processors for arbitrarily large index trees.
idea=the joint and simultaneous use of computing and memory resources of CPU-GPU systems
future=
comment=good paper, very solid
other=
---
id=123
title=Algebraic connectivity of graphs
author=MIROSLAV FIEDLER
journal=Czechoslovak mathematical journal 
year=1972
tags=Algebraic connectivity, spectral graph theory
star=*****
problem=
interest=
hardness=
idea=
future=
comment=the basic idea of spectral graph theory
other=
---
id=124
title=Laplacian of Graphs and Algebraic Connectivity
author=MIROSLAV FIEDLER
journal=Banach Center Publications
year=1989
tags=Laplacian of Graphs, spectral graph theory, Algebraic Connectivity
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=125
title=Lower bounds for the Partitioning of Graphs
author=W. E. Donath
journal=
year=
tags=spectral Graph theory
star=*****
problem=lower bound of the crossing edges in graph Partitioning Problem
interest=
hardness=
idea=
future=
comment=
other=
---
id=126
title=THE CONJUGATE GRADIENT METHOD IN EXTREMAL PROBLEMS
author=B. T. POLYAK
journal=
year=1967
tags=共轭梯度法(Conjugate Gradient Method), EXTREMAL problems, mathematical method, iterational algorithm, linear algebra
star=*****
problem=
interest=
hardness=
idea=proves the convergence of the method as applied to non-quadratic functionals, describe its extension to constrained problems, considers means for further accelerating the convergence, and describes experience in the practical application of the method for solving a variety of extremal problems.
future=
comment=
other=
---
id=127
title=Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering
author=
journal=RecSys
year=2011
tags=共轭梯度法(Conjugate Gradient Method),collaborative filtering
star=****
problem=The need for solving weighted ridge regression (WRR) problems arises in a number of collaborative filtering (CF) algorithms.
interest=
hardness=Often, there is not enough time to calculate the exact solution of the WRR problem, or it is not required.  idea=The conjugate gradient (CG) method is a state-of-the-art approach for the approximate solution of WRR problems.  In this paper, we investigate some applications of the CG method for new and existing implicit feedback CF models.
future=
comment=
other=
---
id=128
title=Similarity-Aware Spectral Sparsification by Edge Filtering
author=Zhuo Feng
journal=DAC
year=2018
tags=Spectral graph theory, graph partitioning, iterative methods
star=***
problem=
interest=
hardness=
idea=a similarity-aware spectral graph sparsification framework that leverages Exploringcient spectral otree edge embedding and filtering schemes to construct spectral sparsifiers with guaranteed spectral similarity (relative condition number) level.
future=
comment=
other=
---
id=129
title=Accelerating graph isomorphism queries in a graph database using GPU
author=
journal=
year=
tags=graph mining, graph isomorphism, GPU, graph database
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=the same paper with [id:29]
---
id=130
title=parallel graph mining with GPUs
author=
journal=
year=2014
tags=Parallel Frequent Graph Mining, Graphics Processing Unit(GPU), frequent pattern, graph database
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=131
title=GpSense: A GPU-friendly method for common-sense subgraph matching in massively parallel architectures
author=Ha-Nguyen Tran, Erik Cambria
journal=International Conference on Intelligent Text Processing and Computational Linguistics
year=2016
tags=GPU, subgraph matching, common-sense, parallel computing
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=use the subgraph matching algorithm in [id:12], like [id:25]
---
id=132
title=GPU Join Processing Revisited
author=Tim Kaldewey
journal=Proceedings of the Eighth International Workshop on Data Management on New Hardware (DaMoN)
year=2012
tags=GPU, join Processing, UVA, PCI-E
star=***
problem=hash join: a large table(probe table) and a small table(build table)
interest=
hardness=
idea=place build table in shared memory, and let GPU access CPU memory directly at PCI-E speed
future=
comment=utilize the new feature of GPU, but not so good practically
other=
---
id=133
title=Performance Optimization of the HPCG Benchmark on the Sunway TaihuLight Supercomputer
author=Yulong Ao, Chao Yang(ACM Gordon Bell Prize)
journal=ACM Transactions on Architecture and Code Optimization
year=2018
tags=high-performance conjugate gradient (HPCG) benchmark, Sunway TaihuLight Supercomputer, Heterogeneous (hybrid) systems, Massively parallel algorithms, 共轭梯度法
star=***
problem=
interest=
hardness=
idea=Block multicoloring parallelization, a block multicoloring reordering method to increase the degree of parallelism without severely degrading the convergence rate; Locality-aware layout transformation; Requirement-based data access; Concurrent gather collective; Fine-grain task overlapping
future=
comment=
other=
---
id=134
title=A distributed in-memory key-value store system on heterogeneous CPU–GPU cluster
author=Kai Zhang
journal=VLDB Journal 
year=2017
tags=key-value store, CPU-GPU cluster, heterogeneous systems, distributed systems, energy efficiency, in-memory key-value indices, Mega-KV
star=****
problem=In-memory key-value stores play a critical role in many data-intensive applications to provide high-throughput and low latency data accesses.
interest=our experiments show that homogeneous multicore CPU systems are limited in performance
hardness=
idea=Effectively utilizing the high memory bandwidth and latency hiding capability of GPUs, Mega-KV provides fast data accesses and significantly boosts overall performance and energy efficiency over the homogeneous CPU architectures; Periodical GPU scheduling for bounded latency, the majority are search and the latency of updates is tolerated; Decoupling index data structure from key-value items; cuckoo hash table as the index data structure
future=
comment=
other=slab memory management: https://en.wikipedia.org/wiki/Slab_allocation
---
id=135
title=ALOR: Adaptive Layout Optimization of Raft Groups for Heterogeneous Distributed Key-Value Stores
author=Yangyang Wang
journal=IFIP International Conference on Network and Parallel Computing(NPC, CCF C Conference of architecture)
year=2018
tags=layout Optimization, Heterogeneous Distributed key-value stores
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=136
title=Cuckoo hashing
author=Pagh Rasmus
journal=Journal of Algorithms
year=2003
tags=cuckoo hashing, data structure and Algorithms
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=137
title=A optimal algorithm to generating minimal perfect hash functions
author=
journal=Information processing letters
year=1992
tags=minimal perfect hash functions, optimal algorithm
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=perfect hashing generator: https://blog.csdn.net/chixinmuzi/article/details/1727195;   hash theory: https://blog.csdn.net/lanchunhui/article/details/50568809
---
id=138
title=A New algorithm for constructing minimal perfect hash functions
author=
journal=
year=2004
tags=minimal perfect hash functions
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=139
title=An Approach for Minimal Perfect Hash Functions for Very Large Databases
author=
journal=
year=2006
tags=Minimal Perfect hash functions, database
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=140
title=A Practical Minimal Perfect Hashing Method
author=
journal=International Workshop on Experimental and Efficient Algorithms
year=2005
tags=Practical minimal perfect hashing method, hash functions
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=141
title=Bloom Filters via d-Left Hashing and Dynamic Bit Reassignment Extended Abstract
author=Flavio Bonomi
journal=Forty-Fourth Annual Allerton Conf
year=2006
tags=bloom filters, d-left hashing, dynamic bit Reassignment, hash functions, counting bloom filter(CBF)
star=****
problem=
interest=
hardness=
idea=dynamic bit reassignment, an approach that allows the size of the fingerprint to flexibly change with the load in each hash bucket, thereby reducing the probability of a false positive
future=
comment=
other=
---
id=142
title=Using Multiple Hash Functions to Improve IP Lookups
author=Broder Andrei
journal=Twentieth Annual Joint Conference of the IEEE Computer and Communications Societies
year=2001
tags=multiple hash functions, IP lookup, d-left hashing 
star=****
problem=High performance Internet routers require a mechanism for very efficient IP address look-ups
interest=Some techniques used to this end, such as binary search on levels, need to construct quickly a good hash table for the appropriate IP prefixes
hardness=
idea=obtaining good hash tables based on using multiple hashes of each input key (which is an IP address). The methods we describe are fast, simple, scalable, parallelizable, and flexible.  In particular, in instances where the goal is to have one hash bucket fit into a cache line, using multiple hashes proves extremely suitable
future=
comment=
other=the original idea of d-left hashing
---
id=143
title=Fast Sorted-Set Intersection using SIMD Instructions
author=Benjamin Schlegel
journal=Accelerating Data Management Systems using Modern Processor and Storage Architectures(ADMS)
year=2011
tags=sorted-set Intersection, SIMD
star=***
problem=
interest=
hardness=
idea=our algorithm requires more comparisons but less instructions than scalar algorithms that translates into a better overall speed. We achieve this by utilizing efficient single-instruction-multiple-data (SIMD) instructions that are available in many processors. We provide different sorted-set intersection algorithms for different integer data types. We propose versions that use uncompressed integer values as input and output as well as a version that uses a tailor-made data layout for even faster intersections
future=
comment=
other=
---
id=144
title=GPU merge path: a GPU merging algorithm
author=Green Oded
journal=Proceedings of the 26th ACM international conference on Supercomputing
year=2012
tags=Parallel algorithms, Parallel systems, Graphics processors, Measurement of multiple-processor systems, GPU merge path, merge-intersection, merge union operation
star=***
problem=compute the union of A and B
interest=
hardness=
idea=GPU partition stage and merge stage, load balance among SMs
future=
comment=
other=Our implementation is 10X faster than the fast parallel merge supplied in the CUDA Thrust library
---
id=145
title=Efficient Lists Intersection by CPU-GPU Cooperative Computing
author=Di Wu
journal=Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)
year=2010
tags=list Intersection, CPU-GPU Cooperative computing, single-core CPU, Multi-core CPU, many-core GPU
star=***
problem=Lists intersection is an important operation in modern web search engines. 
interest=Many prior studies have focused on the single-core or multi-core CPU platform or many-core GPU. 
hardness=
idea=a CPU-GPU cooperative model that can integrate the computing power of CPU and GPU to perform lists intersection more efficiently. In the so-called synchronous mode, queries are grouped into batches and processed by GPU for high throughput. We design a query-parallel GPU algorithm based on an element-thread mapping strategy for load balancing. In the traditional asynchronous model, queries are processed one-byone by CPU or GPU to gain perfect response time. We design an online scheduling algorithm to determine whether CPU or GPU processes the query faster. Regression analysis on a huge number of experimental results concludes a regression formula as the scheduling metric
future=
comment=
other=improvement of [id:347]
---
id=146
title=A New Data Layout For Set Intersection on GPUs
author=Rasmus Resen Amossen
journal=IEEE International Parallel & Distributed Processing Symposium
year=2011
tags=Set intersection, Frequent itemset mining, Sparse boolean matrix multiplication, Data layout, GPU, BATMAP, bitmap
star=***
problem=Set intersection is the core in a variety of problems, e.g. frequent itemset mining and sparse boolean matrix multiplication.
interest=It is well-known that large speed gains can, for some computational problems, be obtained by using a graphics processing unit (GPU) as a massively parallel computing device.
hardness=GPUs require highly regular control flow and memory access patterns, and for this reason previous GPU methods for intersecting sets have used a simple bitmap representation. This representation requires excessive space on sparse data sets
idea=a novel data layout, BATMAP, that is particularly well suited for parallel processing, and is compact even for sparse data.
future=
comment=Frequent itemset mining is one of the most important applications of set intersection. As a case-study on the potential of BATMAPs we focus on frequent pair mining, which is a core special case of frequent itemset mining. The main finding is that our method is able to achieve speedups over both Apriori and FP-growth when the number of distinct items is large, and the density of the problem instance is above 1%. Previous implementations of frequent itemset mining on GPU have not been able to show speedups over the best single-threaded implementations.
other=limitation of batmaps compared to bitmaps: the result of combining two batmaps is not a batmap, so it cannot directly support the intersection of more than two sets.
---
id=147
title=Distributed Power-law Graph Computing: Theoretical and Empirical Analysis
author=Cong Xie, Zhihua Zhang
journal=NIPS(CCF A+ conference of AI)
year=2014
tags=degree-based graph partitioning, distributed power-law graph computing, Theoretical and Empirical analysis, DBH(degree-based hashing)
star=*****
problem=machine learning based on distributed graph-computing (DGC) frameworks has attracted much attention from big data machine learning community
interest=In DGC frameworks, the graph partitioning (GP) strategy plays a key role to affect the performance, including the workload balance and communication cost.
hardness=the degree distributions of natural graphs from real applications follow skewed power laws, which makes GP a challenging task. Recently, many methods have been proposed to solve the GP problem. However, the existing GP methods cannot achieve satisfactory performance for applications with power-law graphs.
idea=a novel vertex-cut method, called degree-based hashing (DBH), for Graph Partitioning. DBH makes effective use of the skewed degree distributions for GP. We theoretically prove that DBH can achieve lower communication cost than existing methods and can simultaneously guarantee good workload balance
future=
comment=
other=
---
id=148
title=Tiles: A New Language Mechanism for Heterogeneous Parallelism
author=Yifeng Chen
journal=PPoPP(workshop)
year=2015
tags=Languages, Performance, concurrent programming structures, language constructs and features
star=****
problem=
interest=
hardness=
idea=This paper studies the essence of heterogeneity from the perspective of language mechanism design. The proposed mechanism, called tiles, is a program construct that bridges two relative levels of computation: an outer level of source data in larger, slower or more distributed memory and an inner level of data blocks in smaller, faster or more localized memory
future=
comment=
other=
---
id=149
title=PARRAY: A Unifying Array Representation for Heterogeneous Parallelism
author=Yifen chen
journal=PPoPP
year=2012
tags=PARRAY(Parallelizing ARRAYs), Parallel Programming, Array Representation, Heterogeneous Parallelism, GPU Cluster, Programming interface
star=****
problem=The current practice of software development requires combin- ing several low-level libraries like Pthread, OpenMP, CUDA and MPI.
interest=
hardness=Achieving productivity and portability is hard with different numbers and models of GPUs.
idea=PARRAY extends mainstream C programming with novel array types of the following features: 1) the dimensions of an array type are nested in a tree structure, conceptually reflecting the memory hierarchy; 2) the definition of an array type may contain references to other array types, allowing sophisticated array types to be created for parallelization; 3) threads also form arrays that allow programming in a Single-Program-Multiple-Codeblock (SPMC) style to unify various sophisticated communication patterns.
future=
comment=This leads to shorter, more portable and maintainable parallel codes, while the programmer still has con- trol over performance-related features necessary for deep manual optimization.
other=
---
id=150
title=Large-Scale FFT on GPU Clusters
author=Yifeng Chen
journal=ICS(International Conference on Supercomputing), CCF B Conference of Architecture area
year=2010
tags=FFT, GPU Clusters, Array Dimensions
star=***
problem=how to achieve substantial speedups for these more challenging tasks on a GPU cluster.
interest=Excellent acceleration is achievable for computation-intensive tasks (e.g. matrix multiplication and LINPACK) and bandwidth-intensive tasks with data locality (e.g. finite-difference simulation).
hardness=Bandwidth-intensive tasks such as large-scale FFTs without data locality are harder to accelerate, as the bottleneck often lies with the PCI between main memory and GPU device memory or the communication network be- tween workstation nodes. That means optimizing the performance of FFT for a single GPU device will not improve the overall performance.
idea=
future=
comment=
other=
---
id=151
title=S-PowerGraph: Streaming Graph Partitioning for Natural Graphs by Vertex-Cut
author=Cong Xie, Zhihua Zhang
journal=arXiv
year=2015
tags=streaming graph partitioning, natural graphs, vertex cut
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=152
title=NOVA: A Novel and Efficient Framework for Finding Subgraph Isomorphism Mappings in Large Graphs
author=
journal=
year=
tags=Subgraph Isomorphism, large graph
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=153
title=SAPPER: Subgraph Indexing and Approximate Matching in Large Graphs
author=Shijie Zhang
journal=VLDB
year=2010
tags=SAPPER, subgraph indexing, Approximate matching, large graphs, edit distance
star=****
problem=Due to the existence of noise (e.g., missing edges) in the large database graph, we investigate the problem of approximate subgraph indexing, i.e., finding the occurrences of a query graph in a large database graph with (possible) missing edges
interest=
hardness=
idea=Utilizing the hybrid neighborhood unit structures in the index, SAPPER takes advantage of pre-generated random spanning trees and a carefully designed graph enumeration order.
future=
comment=
other=
---
id=154
title=GADDI: Distance Index based Subgraph Matching in Biological Networks
author=Shijie Zhang
journal=EDBT
year=2009
tags=GADDI, Distance Index based Subgraph Matching, Biological Networks
star=***
problem=finding all the matches of a query graph in a given large graph of thousands of vertices, which is a very important task in many biological applications
interest=
hardness=
idea=a novel distance measurement which reintroduces the idea of frequent substructures in a single large graph. We devise the novel structure distance based approach (GADDI) to efficiently find matches of the query graph. GADDI is further optimized by the use of a dynamic matching scheme to minimize redundant calculations
future=
comment=
other=Most of the previous work focuses on indexing a set of small or medium sized database graphs (with only tens of vertices) and finding whether a query graph occurs in any of these
---
id=155
title=An In-depth Comparison of Subgraph Isomorphism Algorithms in Graph Databases  (survey, experimental paper)
author=Jinsoo Lee, Wook-Shin Han(the teacher)
journal=VLDB
year=2012
tags=Empirical analysis, NP-hard, Subgraph Isomorphism, graph databases, signature-based filtering, join order selection, survey
star=****
problem=they have not been empirically compared one another in most research work, it is not clear whether the later work outperforms the earlier work. Another problem is that reported comparisons were often done using the original authors’ binaries which were written in different programming environments
interest=many algorithms have been proposed to solve it in a reasonable time for real datasets using different join orders, pruning rules, and auxiliary neighborhood information.
hardness=
idea=we address these serious problems by re-implementing five state-of-the-art subgraph isomorphism algorithms in a common code base and by comparing them using many real-world datasets and their query loads.
future=
comment=Although there is no single winner for all experiments, to our surprise, QuickSI, the algorithm designed for handling small graphs, performs the best for many queries for both small and large data graphs (the AIDS and YEAST datasets) since the cost of its recursive call is the lowest.  QuickSI, VF2, and GADDI failed to find embeddings in trees (the NASA set) in a reasonable time, showing exponential behavior due to serious problems in their join order selection. GADDI shows very bad performance for many queries tested due to expensive NDS distance calculation and lowest pruning power. GraphQL is the only algorithm that completed all queries tested, although it is slower than QuickSI for most queries. SPath almost performed worse than GraphQL due to its large SPath neighborhood signature overhead and the serious problem in its join order selection.  We also note that all existing algorithms had problems in their join order selections, and signature-based pruning is only effective for some datasets. This calls for new subgraph algorithms which exploit both good join order selection and selective signature-based pruning.
other=Ullmann, VF2, QuickSI, GraphQL, SPath, GADDI
---
id=156
title=Combinatorial Optimization on Graphs of Bounded Treewidth
author=
journal=The Computer Journal
year=2008
tags=Combinatorial Optimization, graphs of bounded treewidth
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=157
title=A Dynamic Programming Framework for Combinatorial Optimization Problems on Graphs with Bounded Pathwidth
author=
journal=arXiv
year=2008
tags=dynamic programming, Combinatorial Optimization, graphs of bounded pathwidth
star=
problem=an algorithmic framework for solving a class of combinatorial optimization problems on graphs with bounded pathwidth
interest=The problems are NP-hard in general, but solvable in linear time on this type of graphs. The problems are relevant for assessing network reliability and improving the network’s performance and fault tolerance
hardness=
idea=dynamci programming
future=
comment=
other=
---
id=158
title=dynamic programming on Graphs with Bounded Treewidth
author=Hans L. Bodlaender
journal=International Colloquium on Automata, Languages, and Programming
year=1988
tags=dynamic programming, graphs with bounded Treewidth, bounded degree, partial k-trees, graph decision problems, restrictions of NP-complete problems, polynomial time algorithms, local condition compositions, C-LCC, C-ECC
star=*****
problem=the complexity of graph decision problems, restricted to the class of graphs with treewidth<=k.
interest=
hardness=
idea=
future=
comment=for several NP-complete problems, and subclasses of the graphs with bounded treewidth, polynomial algorithms have been obtained.
other=the decision problem of subgraph matching is solvable in polynomial time for data graphs with bounded tree-width and degree.
---
id=159
title=A Complete Anytime Algorithm for Treewidth
author=
journal=Proceedings of the 20th conference on Uncertainty in artificial intelligence(AUAI Press)
year=2004
tags=Treewidth computation
star=***
problem=we present a Branch and Bound algorithm called QuickBB for computing the treewidth of an undirected graph.
interest=
hardness=
idea=This algorithm performs a search in the space of perfect elimination ordering of vertices of the graph. The algorithm uses novel prun- ing and propagation techniques which are derived from the theory of graph minors and graph isomorphism. We present a new algorithm called minor-min-width for computing a lower bound on treewidth that is used within the branch and bound algo- rithm and which improves over earlier available lower bounds.
future=
comment=QuickBB also has good anytime performance, being able to generate a bet- ter upper bound on treewidth of some graphs whose optimal treewidth could not be computed up to now.
other=
---
id=160
title=Diameter and Treewidth in Minor-Closed Graph Families
author=David Eppstein
journal=arXiv
year=1999
tags=diameter, treewidth, minor-closed graph families
star=***
problem=We investigate the extent to which similar relations hold in other graph families.
interest=
hardness=
idea=treewidth is bounded by a function of the diameter in a minor-closed family, if and only if some apex graph does not belong to the family. In particular, the O(D) bound above can be extended to bounded-genus graphs
future=we extend several approximation algorithms and exact subgraph isomorphism algorithms from planar graphs to other graph families.
comment=
other=It is known that any planar graph with diameter D has treewidth O(D), and this fact has been used as the basis for several planar graph algorithms
---
id=161
title=Weighted Treewidth: Algorithmic Techniques and Results
author=Emgad Bachoore, Hans L. Bodlaender
journal=International Symposium on Algorithms and Computation
year=2007
tags=weighted Treewidth
star=***
problem=From the analysis of algorithms for probabilistic networks, it is known that a tree decomposition of the minimum treewidth may not be optimal for these algorithms
interest=
hardness=Instead of treewidth, we consider therefore the weighted treewidth of a weighted graph.
idea=we present a number of heuristics for determining upper and lower bounds on the weighted treewidth, and a branch and bound algorithm for finding the exact weighted treewidth for weighted graphs.
future=
comment=
other=
---
id=162
title=Subgraph Isomorphism in Planar Graphs and Related Problems
author=David Eppstein
journal=Journal of Graph Algorithms and Applications
year=1999
tags=Subgraph Isomorphism, Planar graphs
star=
problem=solve the subgraph isomorphism problem in planar graphs(both q and g are planar) in linear time, for any pattern of constant size.
interest=
hardness=
idea=partitioning the planar graph into pieces of small tree-width, and applying dynamic programming within each piece.
future=The same methods can be used to solve other planar graph problems including connectivity, diameter, girth, induced subgraph isomorphism, and shortest paths.
comment=
other=
---
id=163
title=GStream: a graph streaming processing method for large-scale graphs on GPUs
author=
journal=PPoPP(Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming)
year=2015
tags=gstream, graph streaming processing, large-scale graph, GPUs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=164
title=Finding Top-k Min-Cost Connected Trees in Databases
author=Bolin Ding, Jeffery Xu Yu, Shan Wang, Lu Qin, Xiao Zhang, Xuemin Lin
journal=ICDE(CCF A conference)
year=2007
tags=databases, top-k min-cost connected trees, steiner trees
star=****
problem=processing a l-keyword query against a relational database which can be modeled as a weighted graph
interest=the integration of database and information retrieval techniques will provide users with a wide range of high quality services
hardness=
idea=finding top-k minimum cost connected trees that contain at least one node in every subset Vi, and denote our problem as GST-k. When k = 1, it is known as a minimum cost group Steiner tree problem which is NP-Complete.
future=Our solution can handle graphs with a large number of nodes. OurGST-1 solution can be easily extended to support GST-k, which outperforms the existing GST-k solutions over both weighted undirected/directed graphs.
comment=The theory is beautiful but the experimental result is not so good; why the bound of iterration is the diameter?; why require the intersection of P1 and P2 is empty? does it influence the correctness, the efficiency? why the complexity is 3^l(for each label x, x has 3 possibilities, in P1 , in P2, or not in P1 and P2), if allowing overlapping between P1 and P2, does complexity change?
other=steiner tree: https://blog.csdn.net/wu_tongtong/article/details/78992913
---
id=165
title=Universal classes of hash functions
author=
journal=Journal of computer and system sciences
year=1979
tags=hash functions, theorectical bound
star=*****
problem=
interest=
hardness=
idea=an input independent average linear time Algorithm for storage and retrieval on keys
future=
comment=the ability to analyze the cost of storage and retrieval without worrying about the distribution of the input allows as corollaries improvements on the bounds of several Algorithms
other=hash functions:  https://en.wikipedia.org/wiki/Hash_function
---
id=166
title=A Comparative Experimental Study of Hash Functions Applied to Packet Sampling
author=
journal=Proc. of International Teletraffic Congress (ITC)
year=2005
tags=Network monitoring, Traffic measurements, Hash functions, Packet sampling
star=***
problem=Traffic measurements in high-speed links are challenging and risk introducing prohibitive costs in the monitoring infrastructure
interest=Packet sampling is an established technique to make these network measurements feasible. Hash based packet sampling is a technique that, in addition, enables new applications, like trajectory sampling and One Way Delay estimation, provided that the same hash function is used in all measurement points
hardness=Such applications require that the used hash functions have specific properties: uniformity of distribution, computation speed, and low collision probability. 
idea=a methodology for hash function comparison and related test results, which have been contributed to the IETF PSAMP (Packet SAMPling) working group.
future=
comment=
other=
---
id=167
title=Revisiting Co-Processing for Hash Joins on the Coupled CPU-GPU Architecture
author=Jiong He, Mian Lu, Bingsheng He
journal=VLDB
year=2013
tags=CoProcessing, hash join, coupled CPU-GPU Architecture(APU)
star=****
problem=hash joins, one of the most important join algorithms for main memory databases, on a coupled CPU-GPU architecture.(the fine-grained co-processing mechanisms on hash joins with and without partitioning.)
interest=Query co-processing on graphics processors (GPUs) has be- come an effective means to improve the performance of main memory databases.
hardness=the relatively low bandwidth and high latency of the PCI-e bus are usually bottleneck issues for co-processing.
idea=(1) the coupled architecture enables fine-grained co-processing and cache reuses, which are ineffi- cient on discrete CPU-GPU architectures; (2) the cost model can automatically guide the design and tuning knobs in the design space; (3) fine-grained co-processing achieves up to 53%, 35% and 28% performance improvement over CPU- only, GPU-only and conventional CPU-GPU co-processing, respectively
future=
comment=the strategy of dividing work of building hash table achieves wonderful balance on cpu-gpu; for hash-join, the big table will be divided called tiling method, and each tile is handled by a single kernel instead a kernel for all
other=coupled CPU-GPU architectures have received a lot of attention, e.g. AMD APUs with the CPU and the GPU integrated into a single chip.(coupled GPU usually less cores and lower latency than discrete GPU like Nvidia)
---
id=168
title=Local Algorithms for Hierarchical Dense Subgraph Discovery
author=
journal=VLDB
year=2019
tags=local Algorithms, h-index, dense subgraph, k-core, k-truss, nucleus decomposition
star=****
problem=Finding the dense regions of a graph and relations among them is a fundamental problem in network analysis
interest=Core and truss decompositions reveal dense subgraphs with hierarchical relations. The incremental nature of algorithms for computing these decompositions and the need for global information at each step of the algorithm hinders scalable parallelization and approximations since the densest regions are not revealed until the end
hardness=
idea=This work generalizes the iterative h-index computation for truss decomposition as well as nucleus decomposition which leverages higher-order structures to generalize core and truss decompositions. In addition, we prove convergence bounds on the number of iterations. We present a framework of local algorithms to obtain the core, truss, and nucleus decompositions.
future=
comment=Our algorithms are local, parallel, oㄦ high scalability, and enable approximations to explore time and quality trade-oṡ Our shared-memory implementation verifies the Exploringciency, scalability, and ectiveness of our local algorithms on real-world networks.
other=
---
id=169
title=Query Log Compression for Workload Analytics
author=
journal=VLDB
year=2019
tags=LOGR, query log Compression, Workload analytics, database, pattern mixture, log encodings,  information-theoretic bounds
star=****
problem=Analyzing database access logs is a key part of performance tuning, intrusion detection, benchmark development, and many other database administration tasks.
interest=
hardness=it is common for production databases to deal with millions or more queries each day, so these logs must be summarized before they can be used. Designing an appropriate summary encoding requires trading off between conciseness and information content; simple workload sampling may miss rare, but high impact queries
idea=LogR, a lossy log compression scheme suitable for use in many automated log analytics tools, as well as for human inspection. We formalize and analyze the space/fidelity trade-off in the context of a broader family of “pattern” and “pattern mixture” log encodings to which LogR belongs
future=
comment=We show through a series of experiments that LogR compressed encodings can be created efficiently, come with provable information-theoretic bounds on their accuracy, and outperform state-of-art log summarization strategies.
other=
---
id=170
title=Scalable Join Processing on Very Large RDF Graphs
author=
journal=SIGMOD
year=2009
tags=large RDF graph, join algorithm, query processing, Sideways Information Passing(SIP)
star=****
problem=
interest=the fine-grained and schema-relaxed use of RDF often entails star- and chain-shaped join queries with many input streams from index scans.
hardness=
idea=develop very light-weight methods for sideways information passing between separate joins at query run-time, to provide highly effective filters on the input streams of joins; improve previously proposed algorithms for join-order optimization by more accurate selectivity estimations for very large RDF graphs.
future=
comment=
other=implemented on open-source RDF-3x; We performed cold-cache experiments by dropping all file-system caches before restarting the various systems and running the queries. We repeated this procedure ten times and measured the average execution time and the standard deviation for each query (notation: meandeviation). For warm-cache experiments we ran the queries ten times without dropping the caches.
---
id=171
title=Hornet: An efficient data structure for dynamic sparse graphs and matrices on GPUs
author=Federico Busato
journal=HPEC
year=2018
tags=hornet data structure, hornetsnest, graph data structure, dynamic sparse graphs and matrices, GPU, CSR, B+ tree, graph algorithms(bfs, sssp...), Dynamic Graph Structures, GPU Computing, Graph Analytics, graph stream
star=****
problem=
interest=Sparse data computations are ubiquitous in science and engineering.
hardness=Unlike their dense data counterparts, sparse data computations have less locality and more irregularity in their execution, making them significantly more challenging to parallelize and optimize;  Many of the existing formats for sparse data representations on parallel architectures are restricted to static data problems, while those for dynamic data suffer from inefficiency both in terms of performance and memory footprint.
idea=This work presents Hornet, a novel data representation that targets dynamic data problems. Hornet is scalable with the input size, and does not require any data re-allocation or re-initialization during the data evolution. We show a Hornet implementation for GPU architectures and compare it to the most widely used static and dynamic data structures.
future=
comment=improvement of CSR and support high rate updates; better sssp performance than Gunrock(>nvgraph); not compare with GPMA [id:24]
other=it also supports grah stream computing on GPU, hornetsnest; also introduces counterparts like cuSTINGER ...
---
id=172
title=Analyzing CUDA workloads using a detailed GPU simulator(gpgpu-sim)
author=
journal=IEEE International Symposium on Performance Analysis of Systems and Software
year=2009
tags=gpgpu-sim
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=173
title=SketchML: Accelerating Distributed Machine Learning with Data Sketches
author=
journal=SIGMOD
year=2018
tags=Distributed Machine Learning, Stochastic Gradient Descent, Quantification, Quantile Sketch, Frequency Sketch,probabilistic data structure
star=****
problem=is there a compression method that can efficiently handle a sparse and nonuniform gradient consisting of key-value pairs?
interest=Since many distributed ML algorithms trained by stochastic gradient descent (SGD) involve communicating gradients through the network, it is important to compress the transferred gradient
hardness=A category of low-precision algorithms can significantly reduce the size of gradients, at the expense of some precision loss.existing low-precision methods are not suitable for many cases where the gradients are sparse and nonuniformly distributed
idea=quantile-bucket quantification method that uses a quantile sketch to sort gradient values into buckets and encodes them with the bucket indexes; To further compress the bucket indexes, our second contribution is a sketch algorithm, namely MinMaxSketch.  MinMaxSketch builds a set of hash tables and solves hash collisions with a MinMax strategy;delta-binary encoding method that calculates the increment of the gradient keys and stores them with fewer bytes
future=
comment=the first effort combining data sketch with ML
other=
---
id=174
title=Single-pass Parallel Prefix Scan with Decoupled Look-back
author=Duane Merrill, Michael Garland
journal=NVIDIA Technical Report, funding from the Defense Advanced Research Projects Agency (DARPA)
year=2013
tags=CUB(cuda unbounded),NVlabs(Nvidia Research),prefix sum,prefix scan
star=****
problem=a work-efficient, communication-avoiding, single-pass method for the parallel computation of prefix scan
interest=
hardness=
idea=2n data movement,embodies a decoupled look-back strategy that performs redundant work to dissociate local computation from the latencies of global prefix propagation
future=
comment=the single-pass nature of our method allows it to be adapted for (1) in-place compaction behavior, and (2) in-situ global allocation within computations that oversubscribe the processor
other=this is the paper of CUB(cuda unbounded)
---
id=175
title=GPU LSM: A Dynamic Dictionary Data Structure for the GPU
author=Saman Ashkiani, Shengren Li, John D. Owens
journal=IPDPS
year=2018
tags=GPU, dynamic dictionary data structure, Log Structured Merge tree(LSM), dynamic graph, stream updates, LSM on GPU
star=***
problem=
interest=
hardness=
idea=
future=
comment=GPU LSM is the first dynamic general-purpose dictionary data structure for the GPU.The trade-off for the dynamic updates is that the sorted array is almost twice as fast on retrievals
other=an implementation of LSM on GPU
---
id=176
title=The Log-Structured Merge-Tree (LSM-Tree)
author=
journal=
year=1996
tags=LSM-Tree
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=177
title=Cache-oblivious streaming B-trees
author=
journal=
year=2007
tags=B-tree, Cache-oblivious
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=178
title=Algorithmic Complexity of Power Law Networks
author=Paweł Brach
journal=SODA(ACM-SIAM Symposium on Discrete Algorithms), CCF B conference of computer science theory area
year=2016
tags=Algorithm complexity, power law graph, relaxed definition of power law, generalized power law distribution
star=****
problem=
interest=the majority of real-world networks are scale-free and follow power law degree distribution. The aim of this paper is to study the algorithmic complexity of such “typical” networks
hardness=
idea=the num of [2^k,2^(k+1)) is  bounded by a similar formula.
future=
comment=
other=
---
id=179
title=Computing Machinery and Intelligence
author=Alan M Turing
journal=Mind
year=1950
tags=Turing Test, computing Machinery, artificial Intelligence
star=*****
problem=what is Intelligence
interest=
hardness=
idea=
future=
comment=
other=this the origin of famous Turing Test
---
id=180
title=LESSONS LEARNED FROM CLAUDE SHANNON
author=Robert G. Gallager
journal=
year=1998
tags=Claude Shannon, Lessons
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=181
title=First Draft Report on the EDVAC
author=John von Neumann
journal=
year=1945
tags=EDVAC, computer design, computer architecture, computing machine
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=this is the origin idea and design of computers by Von Neumann
---
id=182
title=Parallel Graph Coloring with Applications to the Incomplete-LU Factorization on the GPU 
author=Maxim Naumov (NVIDIA)
journal=Nvidia Technical Report
year=2015
tags=MKL, graph coloring,Incomplete-LU Factorization, GPU, Algorithms and Numerical Methods,High Performance Computing
star=***
problem=
interest=
hardness=
idea=implement graph coloring based on different heuristics and showcase their performance on the GPU. We also present a comprehensive comparison of level-scheduling and graph coloring approaches for the incomplete-LU factorization and triangular solve
future=
comment=incomplete-LU factorization based on graph coloring can achieve a speedup of almost 8x on the GPU over the reference MKL implementation on the CPU
other=
---
id=183
title=Parallel Complexity of Forward and Backward Propagation 
author=Maxim Naumov (NVIDIA)
journal=Nvidia Technical Report
year=2017
tags=Algorithms and Numerical Methods,Machine Learning and Artificial Intelligence, Forward and Backward Propagation, parallel Complexity
star=****
problem=
interest= the forward and backward propagation can be formulated as a solution of lower and upper triangular systems of equations.
hardness=For standard feedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems are always block bi-diagonal, while for a general computation graph (directed acyclic graph) they can have a more complex triangular sparsity pattern.
idea=We discuss direct and iterative parallel algorithms that can be used for their solution and interpreted as different ways of performing model parallelism. Also, we show that for FNNs and RNNs with k layers and t time steps the backward propagation can be performed in parallel in O(log k) and O(log k log t) steps, respectively. Finally, we outline the generalization of this technique using Jacobians that potentially allows us to handle arbitrary layers.
future=
comment=
other=
---
id=184
title=Parallel Jaccard and Related Graph Clustering Techniques 
author=Alexandre Fender (NVIDIA)
journal=Proceedings of the 8th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems (ScalA '17)')
year=2017
tags=Algorithms and Numerical Methods, High Performance Computing, Machine Learning and Artificial Intelligence, Jaccard, graph Clustering
star=***
problem=generalize Jaccard and related measures, often used as similarity coefficients between two sets. We define Jaccard, Dice-Sorensen and Tversky edge weights on a graph and generalize them to account for vertex weights
interest=
hardness=
idea=develop an efficient parallel algorithm for computing Jaccard edge and PageRank vertex weights. We highlight that the weights computation can obtain more than 10x speedup on the GPU versus CPU on large realistic data sets. Also, we show that finding a minimum balanced cut for modified weights can be related to minimizing the sum of ratios of the intersection and union of nodes on the boundary of clusters
future=
comment=the novel weights can improve the quality of the graph clustering by about 15% and 80% for multi-level and spectral graph partitioning and clustering schemes, respectively.
other=
---
id=185
title=Parallel Depth-First Search for Directed Acyclic Graphs 
author=Maxim Naumov (NVIDIA)
journal=NVIDIA Technical report
year=2017
tags=High Performance Computing, dorected Acyclic graph, parallel depth-first search(dfs)
star=***
problem=
interest=Depth-First Search (DFS) is a pervasive algorithm, often used as a building block for topological sort, connectivity and planarity testing, among many other applications
hardness=
idea=We propose a novel work-efficient parallel algorithm for the DFS traversal of directed acyclic graph (DAG). The algorithm traverses the entire DAG in a BFS-like fashion no more than three times. As a result it finds the DFS pre-order (discovery) and post-order (finish time) as well as the parent relationship associated with every node in a DAG
future=
comment=We analyse the runtime and work complexity of this novel parallel algorithm
other=its CUDA implementation on the GPU outperforms sequential DFS on the CPU by up to 6x in our experiments.
---
id=186
title=A Dynamic Hash Table for the GPU
author=Saman Ashkiani, John D. Owens
journal=arXiv
year=2018
tags=dynamic hash table, GPU, dynamic memory allocation on GPU
star=***
problem=fully concurrent dynamic hash table for GPUs with comparable performance to the state of the art static hash tables
interest=
hardness=
idea=warp-cooperative work sharing strategy that reduces branch divergence and provides an efficient alternative to the traditional way of per-thread (or per-warp) work assignment and processing. By using this strategy, we build a dynamic nonblocking concurrent linked list, the slab list, that supports asynchronous, concurrent updates (insertions and deletions) as well as search queries. We use the slab list to implement a dynamic hash table with chaining (the slab hash). We also design a warp-synchronous dynamic memory allocator, SlabAlloc, that suits the high performance needs of the slab hash.
future=
comment=
other=this paper talks about dynamic memory allocation on GPU and give a survey
---
id=187
title=DUALSIM: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine
author=Kim H, Lee J, Wook-Shin Han(the teacher)
journal=International Conference on Management of Data. ACM. (SIGMOD)
year=2016
tags=parallel subgraph Enumeration, single machine, DUALSIM
star=****
problem=Can subgraph enumeration be done disk-based, on a single machine in a way that is scalable and efficient? 
interest=used in network motif discovery, graphlet kernel computation, subgraph frequency(frequent patterns)
hardness=Existing methods fail due to exponential partial solutions; Disk access one of costliest bottlenecks; CPU stall also notable bottleneck
idea=DualSim does not maintain explosive partials;Red Black Ivory query graph transformation
future=
comment=
other=
---
id=188
title=TurboGraph: A fast parallel graph engine handling billion-scale graphs in a single PC
author=Wook-Shin Han, Sangyeon Lee
journal=SIGKDD
year=2013
tags=billion-scale graph, single PC, singel machine, parallel graph engine, TurboGraph, bfs, Graph processing, Big data, Parallelism, Pin-and-slide
star=****
problem=a general, disk-based graph engine called TurboGraph to process billion-scale graphs very efficiently by using modern hardware on a single PC; a novel parallel execution model, called pin-andslide.  TurboGraph also provides engine-level operators such as BFS which are implemented under the pin-and-slide model
interest=
hardness=Although GraphChi significantly outperforms all representative (disk-based) distributed graph engines(GBase and Pregel, GraphLab, PowerGraph), we observe that GraphChi still has serious performance problems for many important types of graph queries due to 1) limited parallelism and 2) separate steps for I/O processing and CPU processing
idea=full parallelism including multicore parallelism and FlashSSD IO parallelism; full overlap of CPU processing and I/O processing as much as possible
future=
comment=
other=homepage  https://sites.google.com/a/dblab.postech.ac.kr/postechdblab/home/people/professor-1
---
id=189
title=TurboGraph++: A Scalable and Fast Graph Analytics System
author=Seongyun Ko, Wook-Shin Han
journal=SIGMOD
year=2018
tags=TurboGraph++, distributed  graph analytic system
star=****
problem=a scalable and fast graph analytics system which efficiently processes large graphs by exploiting external memory for scale-up without compromising efficiency
interest=
hardness=Existing distributed graph analytics systems are categorized into two main groups: those that focus on efficiency with a risk of out-ofmemory error and those that focus on scale-up with a fixed memory budget and a sacrifice in performance. While the former group keeps a partitioned graph resident in memory of each machine and uses an in-memory processing technique, the latter stores the partitioned graph in external memory of each machine and exploits a streaming processing technique. Gemini and Chaos are the state-of-the-art distributed graph systems in each group, respectively.
idea=a new graph processing abstraction for efficiently supporting neighborhood analytics that requires processing multi-hop neighborhoods of vertices, such as triangle counting and local clustering coefficient computation, with a fixed memory budget;  a balanced and bufferaware partitioning scheme for ensuring balanced workloads across machines with reasonable cost; leverages three-level parallel and overlapping processing for fully utilizing three hardware resources, CPU, disk, and network, in a cluster
future=
comment=TurboGraph++ is designed to scale well to handle large-scale graphs using 25 machines, like Chaos, while its performance is comparable to Gemini.
other=
---
id=190
title=efficient error recovery for reliable multicast
author=Zhen Xiao (pku teacher)
journal=Cornell University
year=2001
tags=phD graduate paper, distributed system, error recovery
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=the homepage  http://net.pku.edu.cn/vc/index_chinese.php
---
id=191
title=Token-ordered LRU: an effective page replacement policy and its implementation in Linux systems
author=Song Jiang, Xiaodong Zhang(the teacher)
journal=Performance of Evaluation
year=2004
tags=Process thrashing, Global LRU replacement, Load control, Performance evaluation, page replacement policy, Linux systems
star=****
problem=the process thrashing in a single node or a small number of nodes could severely affect other nodes running coordinating processes, even crash the whole system. In this paper, we focus on how to improve the page replacement algorithm running on one node
interest=Most computer systems use a global page replacement policy based on the LRU principle to approximately select a Least Recently Used page for a replacement in the entire user memory space
hardness=During execution interactions, a memory page can be marked as LRU even when its program is conducting page faults. We define the LRU pages under such a condition as false LRU pages because these LRU pages are not produced by program memory reference delays, which is inconsistent with the LRU principle. False LRU pages can significantly increase page faults, even cause system thrashing. This poses a more serious risk in a large parallel systems with distributed memories because of the existence of coordination among processes running on individual node
idea=
future=
comment=
other=homepage of teacher   http://web.cse.ohio-state.edu/~zhang.574/
---
id=192
title=AA-Sort: A New Parallel Sorting Algorithm for Multi-Core SIMD Processors
author=Hiroshi Inoue
journal=International Conference on Parallel Architecture & Compilation Techniques(PACT)
year=2007
tags=simd, sse, avx2, multi-core, parallel sorting
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=193
title=An Efficient Implementation of the Bellman-Ford Algorithm for Kepler GPU Architectures (H-BF)
author=federico Busato
journal=TPDS (CCF A journal)
year=2016
tags=Bellman-Ford, Nvidia Kepler GPU, Maxwell Architecture, SSSP(single-source shortest path) with negative weights, CUDA, H-BF, load balance, new features, dynamic parallelism, warp shuffle instructions, 64-bit atomic instructions, cache modifiers, dynamic virtual warps, virtual warp programming, complete duplicate removal
star=****
problem=This article presents a parallel implementation of the Bellman-Ford algorithm that exploits the architectural characteristics of recent GPU architectures (i.e., NVIDIA Kepler, Maxwell) to improve both performance and work efficiency
interest=Finding the shortest paths from a single source to all other vertices is a common problem in graph analysis. The Bellman-Ford’s algorithm is the solution that solves such a single-source shortest path (SSSP) problem and better applies to be parallelized for many-core architectures.
hardness=the high degree of parallelism is guaranteed at the cost of low work efficiency, which, compared to similar algorithms in literature (e.g., Dijkstra’s) involves much more redundant work and a consequent waste of power consumption.
idea=different optimizations to the implementation, which are oriented both to the algorithm (edge classification and complete duplicate removal using 64-bit atomic operations) and to the architecture (memory coalesce, dynamic virtual warp, and dynamic parallelism); the appropriate size of dynamic virtual warps is re-computed in each iteration.
future=An OpenCL implementation of the proposed solution is currently under study. The challenge is to observe how much the performance of the OpenCL and CUDA implementations differ since they provide different low-level instructions as well as the opportunity of implementing different hardwareoriented techniques.
comment=This article presented H-BF, a parallel implementation of the Bellman-Ford algorithm for Kepler GPU architectures; Outperform Davidson's work [id:32]. Reached state-of-art performance.     The article presented an analysis of the impact of the proposed optimization strategies over different graph characteristics to understand how they impact on the H-BF work efficiency.
other=based on BFS-4K ([id:20] of gpu.list)  ;  The code:   http://profs.sci.univr.it/%7Ebombieri/H-BF/index.html       ;      Warp shuffle instructions are another new feature of Kepler used in this work. They implement very efficient communication among threads within a warp. With shuffle instructions, threads within a warp can directly access to other thread registers by skipping shared memory accesses.  Thread communication via warp shuffle allows the amount of shared memory required for blocks to be reduced with consequent general improvements of performance;
---
id=194
title=Corolla: GPU-Accelerated FPGA Routing Based on Subgraph Dynamic Expansion
author=Minghua Shen, Guojie Luo
journal=FPGA
year=2017
tags=Corolla, gpu, fpga routing, Subgraph dynamic expansion
star=***
problem=the long routing time imposes a barrier on FPGA computing, which signficantly hinders the design produc- tivity. Existing attempts of parallelizing the FPGA routing either do not fully exploit the parallelism or suㄦ from an excessive quality loss. Massive parallelism using GPUs has the potential to solve this issue but faces non-trivial challenges
interest=FPGAs are increasingly popular as application-specific accelerators because they lead to a good balance between fexibility and energy Exploringciency, compared to CPUs and ASICs.
hardness=
idea=Corolla enables applying the GPU-friendly shortest path algorithm in FPGA routing, leveraging the idea of problem size reduction by limiting the search in routing subgraphs. We maintain the convergence after problem size reduction using the dynamic expansion of the routing resource subgraphs. In addition, Corolla explores the fine-grained single-net parallelism and proposes a hybrid approach to combine the static and dynamic parallelism on GPU. To explore the coarse-grained multi-net parallelism, Corolla proposes an ective method to parallelize mutli-net routing while preserving the equivalent routing results as the original single-net routing.
future=
comment=
other=
---
id=195
title=Accelerating Large-Scale Single-Source Shortest Path on FPGA
author=Shijie Zhou
journal=IEEE International Parallel and Distributed Processing Symposium Workshops
year=2015
tags=sssp, fpga, Bellman-Ford, external memory
star=***
problem=large-scale graphs involve millions or even billions of vertices, making efficient parallel graph processing challenging
interest=propose a single-FPGA based design to accelerate SSSP for massive graphs
hardness=graph is stored in external memory, which is more realistic for processing largescale graphs. Using the available external memory bandwidth, our design achieves the maximum data parallelism to concurrently process multiple edges in each clock cycle, regardless of data dependencies.
idea=
future=
comment=
other=
---
id=196
title=An FPGA Implementation for Solving the Large Single-Source-Shortest-Path Problem
author=Guoqing Lei, Yong Dou, Rongchun Li, Fei Xia
journal=IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS—
year=2016
tags=Field-programmable gate arrays (FPGAs), single source shortest path (SSSP), systolic array priority queue (SAPQ), internal memory, Dijkstra
star=***
problem=the existing SSSP implementations on field-programmable gate arrays (FPGAs) are incapable of processing large graphs by storing the graph and results in internal memories
interest=
hardness=
idea=a parallel FPGA implementation to solve the SSSP problem, which is derived from a variant of the “eager” Dijkstra algorithm. In order to process a large graph problem, an extended systolic array priority queue called ExSAPQ is proposed to allow large-scale priority queue processing
future=
comment=
other=
---
id=197
title=LIRS: An Efficient Low Interreference Recency Set Replacement Policy to Improve Buffer Cache Performance
author=Song Jiang, Xiaodong zhang
journal=Acm Sigmetrics Performance Evaluation Review
year=2002
tags=LRU replacement, LIRS, buffer cache Performance, replacement policy
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=198
title=a permutation-based page interleaving scheme to reduce row-buffer conflicts and exploit data locality
author=zhao zhang, Xiaodong Zhang
journal=Proceedings of the 33rd annual ACM/IEEE international symposium on Micro architecture. ACM
year=2000
tags=page interleaving scheme, row-buffer conflicts, data locality
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=The Permutation-based Page Interleaving has been Widely Used in Computers for Fast Memory Accesses 
---
id=199
title=Spark-GPU: an accelerated in-memory data processing engine on clusters
author=Yuan yuan, Xiaodong zhang
journal=IEEE International Conference on Big Data. IEEE
year=2017
tags=gpu, spark, in-memory data processing engine on clusters, Distributed computing
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=200
title=Mega-KV: case for GPUs to maximize the throughput of in-memory key-value stores
author=Kai Zhang, Xiaodong zhang
journal=VLDB
year=2015
tags=in-memory key-value stores, Mega-KV, GPU
star=****
problem=In-memory key-value stores have several unique properties that include (1) data intensive operations de- manding high memory bandwidth for fast data accesses, (2) high data parallelism and simple computing operations de- manding many slim parallel computing units, and (3) a large working set.
interest=In-memory key-value stores play a critical role in data pro- cessing to provide high throughput and low latency data accesses.
hardness=As data volume continues to increase, our ex- periments show that conventional and general-purpose multicore systems are increasingly mismatched to the special properties of key-value stores because they do not provide massive data parallelism and high memory bandwidth; the powerful but the limited number of computing cores do not satisfy the demand of the unique data processing task; and the cache hierarchy may not well benefit to the large working set.
idea=a GPU-based in-memory key-value store system that achieves high per- formance and high throughput. Effectively utilizing the high memory bandwidth and latency hiding capability of GPUs, Mega-KV provides fast data accesses and significantly boosts overall performance.
future=
comment=
other=
---
id=201
title=Concurrent analytical query processing with GPUs
author=Kaibo Wang, Kai zhang, Xiaodong zhang
journal=VLDB
year=2014
tags=GPU, Concurrent query processing
star=****
problem=Sharing GPUs among concurrent queries is not supported, causing serious resource underutilization
interest=Based on the profiling of an open-source GPU query engine running commonly used single- query data warehousing workloads, we observe that the utilization of main GPU resources is only up to 25%. The underutilization leads to low system throughput.
hardness=
idea=To Exploringciently share GPUs among concurrent queries for high throughput, the major challenge is to provide software support to control and resolve resource contention incurred by the sharing. Our solution relies on GPU query scheduling and device memory swapping policies to address this challenge.
future=
comment=
other=
---
id=202
title=On graph query optimization in large networks  (Spath)
author=Peixiang Zhao, Jiawei Han
journal=VLDB
year=2010
tags=SPath,subgraph isomorphism, subgraph matching
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=203
title=Grami: Frequent subgraph and pattern mining in a single large graph
author=Elseidy Mohammed
journal=VLDB
year=2014
tags=frequent subgraph and pattern mining
star=****
problem=Mining frequent subgraphs is an important operation on graphs; it is defined as finding all subgraphs that appear frequently in a database according to a given frequency threshold
interest=
hardness=
idea=
future=
comment=
other=
---
id=204
title=Scalable subgraph enumeration in mapreduce
author=Lai Longbin, Qin L
journal=VLDB
year=2015
tags=subgraph enumeration, MapReduce, Distributed computing, parallel algorithm
star=****
problem=Subgraph enumeration, which aims to find all the subgraphs of a large data graph that are isomorphic to a given pattern graph, is a fundamental graph problem with a wide range of applications
interest=
hardness=
idea=
future=
comment=
other=
---
id=205
title=NScale: neighborhood-centric large-scale graph analytics in the cloud
author=Quamar Abdul, Amol Deshpande
journal=VLDB
year=2016
tags=graph analytics, cloud computing, neighborhood-centric
star=****
problem=There is an increasing interest in executing complex analyses over large graphs, many of which require processing a large number of multi-hop neighborhoods or subgraphs. 
interest=
hardness=
idea=
future=
comment=
other=
---
id=206
title=Taming subgraph isomorphism for RDF query processing  (TurboHom++)
author=Kim Jinha, Wook-Shin Han(the teacher)
journal=VLDB
year=2015
tags=RDF query processing, subgraph isomorphism, subgraph matching, TurboHom++, embedding technique, type-aware transformation
star=****
problem=The core function of processing RDF data is subgraph pattern matching. There have been two completely different directions for supporting efficient subgraph pattern matching. One direction is to develop specialized RDF query processing engines exploiting the properties of RDF data for the last decade, while the other direction is to develop efficient subgraph isomorphism algorithms for general, labeled graphs for over 30 years.
interest=RDF data are used to model knowledge in various areas such as life sciences, Semantic Web, bioinformatics, and social graphs. The size of real RDF data reaches billions of triples. This calls for a framework for efficiently processing RDF data. The core function of processing RDF data is subgraph pattern matching.
hardness=Although both directions have a similar goal (i.e., finding subgraphs in data graphs for a given query graph), they have been independently researched without clear reason. We argue that a subgraph isomorphism algorithm can be easily modified to handle the graph homomorphism, which is the RDF pattern matching semantics, by just removing the injectivity constraint
idea=based on the state-of-the-art subgraph isomorphism algorithm, we propose an in-memory solution, TurboHOM++, which is tamed for the RDF processing, and we compare it with the representative RDF processing engines for several RDF benchmarks in a server machine where billions of triples can be loaded in memory.  In order to speed up TurboHOM++, we also provide a simple yet effective transformation and a series of optimization techniques; By transforming RDF graphs into labeled graphs, we can apply subgraph homomorphism methods to RDF query processing;   In type-aware transformation, by embedding the types of an entity (i.e., a subject or object) into a vertex label set, we can eliminate corresponding query vertices/edges from a query graph.  With type-aware transformation, the query graph size decreases, its topology becomes simpler than the original query, and thus, this transformation improves performance accordingly by reducing the amount of graph exploration.
future=
comment=embedding technique that uses triples as vertex attributes; this approach opens a new direction for RDF processing so that both traditional directions can merge or benefit from each other;  eliminates corresponding query vertices/edges from a query graph by embedding the types of an entity into a vertex label set to boosting query performance
other=
---
id=207
title=Durable graph pattern queries on historical graphs
author=Semertzidis Konstantinos
journal=ICDE
year=2016
tags=durable graph pattern matching, historical graphs, subgraph matching
star=****
problem=we focus on labeled graphs that evolve over time. Given a sequence of graph snapshots representing the state of the graph at different time instants, we seek to find the most durable matches of an input graph pattern query
interest=
hardness=
idea=
future=
comment=
other=
---
id=208
title=Functional dependencies for graphs
author=Wenfei Fan, Yinghui wu
journal=Proceedings of the 2016 International Conference on Management of Data. ACM
year=2016
tags=Functional dependencies for graphs
star=****
problem=a class of functional dependencies for graphs, referred to as GFDs. GFDs capture both attribute-value dependencies and topological structures of entities, and subsume conditional functional dependencies (CFDs) as a special case
interest=
hardness=
idea=
future=
comment=
other=
---
id=209
title=Indexing query graphs to speed up graph query processing
author=Wang Jing
journal=EDBT
year=2016
tags=graph query processing, indexing query graphs, historical information
star=***
problem=
interest=Subgraph/supergraph queries although central to graph an-alytics, are costly as they entail the NP-Complete problem of subgraph isomorphism.
hardness=
idea=a fresh solution, the novel principle of which is to acquire and utilize knowledge from the results of previously executed queries
future=
comment=
other=
---
id=210
title=Subgraph matching with set similarity in a large graph database
author=Liang Hong, Lei Zou
journal=TKDE
year=2015
tags=Subgraph matching, set similarity, graph database
star=***
problem=study a subgraph matching with set similarity (SMS2) query over a large graph database, which retrieves subgraphs that are structurally isomorphic to the query graph, and meanwhile satisfy the condition of vertex pair matching with the (dynamic) weighted set similarity
interest=In real-world graphs such as social networks, Semantic Web and biological networks, each vertex usually contains rich information, which can be modeled by a set of tokens or elements.
hardness=
idea=
future=
comment=
other=
---
id=211
title=Diversified top-k subgraph querying in a large graph
author=Zhengwei Yang
journal=In Proceedings of the 2016 International Conference on Management of Data
year=2016
tags=Diversified top-k subgraph querying, subgraph matching
star=***
problem=top-k diversified results are useful since the number of matching subgraphs can be very large
interest=
hardness=
idea=
future=
comment=
other=
---
id=212
title=Efficient and scalable labeled subgraph matching using SGMatch
author=CR Rivero, HM Jamil
journal=Knowledge and Information Systems
year=2017
tags=labeled subgraph matching, SGMatch, subgraph isomorphism
star=***
problem=An open research question is whether graphs can be matched based on parts and local solutions can be combined to reach a global matching
interest=
hardness=
idea=we present an approach based on graph decomposition called SGMatch to match graphs. We represent graphs in smaller units called graphlets and develop a matching technique to leverage this representation. Pruning strategies use a new notion of edge covering called minimum hub cover and metadata, such as statistics and inverted indices, to reduce the number of matching candidates
future=
comment=Our evaluation of SGMatch versus contemporary algorithms, i.e., VF2, GraphQL, QuickSI, GADDI, or SPath, shows that SGMatch substantially improves the performance of current state-of-the-art techniques for larger query graphs with different structures, i.e., cliques, paths or subgraphs.
other=
---
id=213
title=PGX.ISO: parallel and efficient in-memory engine for subgraph isomorphism
author=Raghavan Raman
journal=In Proceedings of Workshop on GRAph Data management Experiences and Systems
year=2014
tags=in-memory, subgraph isomorphism, PGX.ISO, parallel algorithms
star=***
problem=
interest=
hardness=
idea=Graph matching query language GMQL; breadth-first search for better parallelization
future=
comment=
other=the work of Oracle
---
id=214
title=Dualiso: An algorithm for subgraph pattern matching on very large labeled graphs
author=M Saltz
journal=In 2014 IEEE International Congress on Big Data
year=2014
tags=Dualiso, subgraph matching, large labeled graphs
star=***
problem=This paper presents a conceptually simple, memory-efficient, pruning-based algorithm for the subgraph isomorphism problem that outperforms commonly used algorithms on large graphs. The high performance is due in large part to the effectiveness of the pruning algorithm, which in many cases removes a large percentage of the vertices not found in isomorphic matches. 
interest=
hardness=
idea=
future=
comment=
other=
---
id=215
title=Efficient graph computation on hybrid CPU and GPU systems
author=Tao Zhang
journal=the journal of Supercomputing
year=2015
tags=graph computation, hybrid cpu and gpu system, non-distributed computing
star=***
problem=
interest=efficient non-distributed platforms require less hardware resource and can achieve better energy efficiency than distributed ones
hardness=Although distributed graph engines such as GBase and Pregel handle billion-scale graphs, users need to be skilled at managing and tuning a distributed system in a cluster, which is a non-trivial job for ordinary users. Furthermore, these distributed systems need many machines in a cluster in order to provide reasonable performance
idea=a general, disk-based graph engine called gGraph to process billion-scale graphs efficiently by utilizing both CPUs and GPUs in a single PC. GGraph exploits full parallelism and full overlap of computation and I/O processing as much as possible
future=
comment=Experiment results show that gGraph outperforms GraphChi and PowerGraph. In addition, gGraph achieves the best energy efficiency among all evaluated platforms.
other=
---
id=216
title=A review on algorithms for maximum clique problems
author=Qinghua Wu, jin-Kao Hao
journal=European Journal of Operational Research
year=2015
tags=maximum clique, Experimental paper, review, survey
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=217
title=Finding the maximum clique in massive graphs
author=Can Lu, Jeffrey Xu Yu(the teacher), Hao Wei, Yikai Zhang
journal=VLDB
year=2017
tags=maximum clique, massive graphs, randomized graph algorithm
star=****
problem=algorithms designed for the maximum clique problem are expensive to deal with real-world networks
interest=the maximum clique problem is known to have direct applications in various fields, such as community search in social networks and social media, team formation in expert networks, gene expression and motif discovery in bioinformatics and anomaly detection in complex networks, revealing the structure and function of networks
hardness=
idea=devise a randomized algorithm for the maximum clique problem. Different from previous algorithms that search from each vertex one after another, our approach RMC, for the randomized maximum clique problem, employs a binary search while maintaining a lower bound and upper bound of w(G)
future=
comment=
other=homepage   http://www.se.cuhk.edu.hk/research/information.html#4 ;   diverse relaxations of clique are mentioned in this paper: quasi-clique, k-core, k-edge-connectivity, dense subgraph.
---
id=218
title=FAST: Fast Architecture Sensitive Tree Search on Modern CPUs and GPUs
author=Changkyu Kim (Throughput Computing Lab, Intel Corporation)
journal=SIGMOD
year=2010
tags=FAST, Architecture sensitive tree search, binary search, GPU, CPU, SIMD(SSE, AVX2), cache-friendly
star=****
problem=FAST, an extremely fast architecture sensitive layout of the index tree
interest=In-memory tree structured index search is a fundamental database operation. Modern processors provide tremendous computing power by integrating multiple cores, each with wide vector units. There has been much work to exploit modern processor architectures for database primitives like scan, sort, join and aggregation.
hardness=unlike other primitives, tree search presents significant challenges due to irregular and unpredictable data accesses in tree traversal
idea=FAST is a binary tree logically organized to optimize for architecture features like page size, cache line size, and SIMD width of the underlying hardware. FAST eliminates impact of memory latency, and exploits thread-level and datalevel parallelism on both CPUs and GPUs to achieve 50 million (CPU) and 85 million (GPU) queries per second, 5X (CPU) and 1.7X (GPU) faster than the best previously reported performance on the same architectures. FAST supports efficient bulk updates by rebuilding index trees in less than 0.1 seconds for datasets as large as 64M keys and naturally integrates compression techniques
future=
comment=the key compression technique is very trival and not practical
other=
---
id=219
title=Relatedness-based Multi-Entity Summarization
author=Kalpa Gunaratna
journal=IJCAI  (CCF A conference)
year=2017
tags=Relatedness-based, Multi-Entity Summarization
star=****
problem=
interest=Representing world knowledge in a machine processable format is important as entities and their descriptions have fueled tremendous growth in knowledge-rich information processing platforms, services, and systems. Prominent applications of knowledge graphs include search engines (e.g., Google Search and Microsoft Bing), email clients (e.g., Gmail), and intelligent personal assistants (e.g., Google Now, Amazon Echo, and Apple’s Siri)
hardness=
idea=summarize facts about a collection of entities by analyzing their relatedness in preference to summarizing each entity in isolation. Specifically, we generate informative entity summaries by selecting: (i) inter-entity facts that are similar and (ii) intra-entity facts that are important and diverse. We employ a constrained knapsack problem solving approach to efficiently compute entity summaries
future=
comment=We perform both qualitative and quantitative experiments and demonstrate that our approach yields promising results compared to two other stand-alone state-of-the-art entity summarization approaches
other=
---
id=220
title=FACES: Diversity-Aware Entity Summarization Using Incremental Hierarchical Conceptual Clustering
author=kalpa Gunaratna
journal=AAAI
year=2015
tags=FACES, Diversity-Aware entity Summarization, Incremental Hierarchical Conceptual Clustering
star=****
problem=Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest
interest=Semantic Web documents that encode facts about entities on the Web have been growing rapidly in size and evolving over time.
hardness=
idea=explore automatic summarization techniques that characterize and enable identification of an entity and create summaries that are human friendly. Specifically, we highlight the importance of diversified (faceted) summaries by combining three dimensions: diversity, uniqueness, and popularity.  Our novel diversity-aware entity summarization approach mimics human conceptual clustering techniques to group facts, and picks representative facts from each group to form concise (i.e., short) and comprehensive (i.e., improved coverage through diversity) summaries.
future=
comment=We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization
other=Linking Open Data(LOD)
---
id=221
title=NetLSD: Hearing the Shape of a Graph
author=Anton Tsitsulin
journal=SIGKDD
year=2018
tags=NetLSD, graph property, graph comparison, graph similarity, Laplacian spectrum
star=****
problem=Comparison among graphs is ubiquitous in graph analytics
interest=it is a hard task in terms of the expressiveness of the employed similarity measure and the efficiency of its computation
hardness=Ideally, graph comparison should be invariant to the order of nodes and the sizes of compared graphs, adaptive to the scale of graph patterns, and scalable. Unfortunately, these properties have not been addressed together. Graph comparisons still rely on direct approaches, graph kernels, or representation-based methods, which are all inefficient and impractical for large graph collections.
idea=NetLSD (Network Laplacian Spectral Descriptor), a permutation- and size-invariant, scale-adaptive, and scalably computable graph representation method that allows for straightforward comparisons. NetLSD hears the shape of a graph by extracting a compact signature that inherits the formal properties of the Laplacian spectrum, specifically its heat or wave kernel
future=
comment=NetLSD is the first expressive graph representation that allows for efficient comparisons of large graphs
other=
---
id=222
title=An Optimal and Progressive Approach to Online Search of Top-k Important Communities
author=Fei Bi, Lijun Chang, Xuemin Lin, Wenjie Zhang
journal=VLDB
year=2017
tags=community search, top-k important communities, social network
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=223
title= Efficient String Similarity Search: A Cross Pivotal Based Approach 
author=Fei Bi, Lijun Chang, Wenjie Zhang, Xuemin Lin
journal=DASFAA
year=2015
tags=String Similarity search
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=224
title=Literature Survey on Finding Influential Communities in Large Scale Networks
author=
journal=arXiv
year=2019
tags=Literature survey, Influential Communities, large social networks
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=225
title=Dynamic Top-K Interesting Subgraph Query on Large-Scale Labeled Graphs
author=
journal=School of Information, Liaoning University
year=2019
tags=dynamic top-k, Subgraph query, large-scale labeled graphs
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=226
title=Relaxed Operator Fusion for In-Memory Databases: Making Compilation, Vectorization, and Prefetching Work Together At Last
author=Prashanth Menon, Todd C. Mowry, Andrew Pavlo
journal=VLDB
year=2017
tags=relaxed Operator fusion, in-memory databases, Compilation-Vectorization-Prefetching work together, just-in-time compilation(JIT), relational database, query optimization, SIMD Vectorization, tactful materialization, inter-tuple parallelism
star=****
problem=Because disk accesses are no longer the principle bottleneck in such systems, the focus in designing query execution engines has shifted to optimizing CPU performance.
interest=In-memory database management systems (DBMSs) are a key component of modern on-line analytic processing (OLAP) applications, since they provide low-latency access to large volumes of data
hardness=The state-of-the-art in query compilation is to fuse operators together in a query plan to minimize materialization overhead by passing tuples efficiently between operators
idea=Our empirical analysis shows, however, that more tactful materialization yields better performance.  We present a query processing model called “relaxed operator fusion” that allows the DBMS to introduce staging points in the query plan where intermediate results are temporarily materialized.  This allows the DBMS to take advantage of inter-tuple parallelism inherent in the plan using a combination of prefetching and SIMD vectorization to support faster query execution on data sets that exceed the size of CPU-level caches
future=
comment=Recent systems have revived an older technique of using just-in-time (JIT) compilation to execute queries as native code instead of interpreting a plan
other=
---
id=227
title=A Formal Semantics of SQL Queries, Its Validation, and Applications
author=Paolo Guagliardo, Leonid Libkin(School of Informatics, University of Edinburgh)
journal=VLDB
year=2018
tags=SQL queries, formal Semantics, Validation and Applications, bag Semantics and nulls, SELECT-FROM-WHERE
star=****
problem=While formal semantics of theoretical languages underlying SQL have been provided in the past, they all made simplifying assumptions ranging from changes in the syntax to omitting bag semantics and nulls. This situation is reminiscent of what happens in the field of programming languages, where semantics of formal calculi underlying the main features of languages are abundant, but formal semantics of real languages that people use are few and far between.
interest=
hardness=
idea=We consider the basic class of SQL queries – essentially SELECT-FROM-WHERE queries with subqueries, set/bag operations, and nulls – and define a formal semantics for it, without any departures from the real language. This fragment already requires decisions related to the data model and handling variable names that are normally disregarded by simplified semantics
future=
comment=We give two applications of the semantics. One is the first formal proof of the equivalence of basic SQL and relational algebra that extends to bag semantics and nulls. The other application looks at the three-valued logic employed by SQL, which is universally assumed to be necessary to handle nulls.  We prove however that this is not so, as three-valued logic does not add expressive power: every SQL query in our fragment can be evaluated under the usual two-valued Boolean semantics of conditions.
other=
---
id=228
title=Cloud Computing Applications for Smart Grid: A Survey
author=
journal=TPDS
year=2015
tags=cloud computing Applications, smart grid, survey
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=229
title=Towards Low-Latency Batched Stream Processing by Pre-Scheduling
author=Hai Jin
journal=TPDS
year=2019
tags=Batch Processing Computers, Cluster Computing, Parallel Processing, Scheduling, Task Scheduling, Apache Spark Streaming, Post Scheduling Methods, Batched Stream Processing Jobs, Pre Scheduling Straggler Mitigation Framework, Task Analysis, Batch Production Systems, Sparks, Cloning, Data Models, Fault Tolerance, Fault Tolerant Systems, Stream Processing, Recurring Jobs, Straggler, Scheduling, Data Assignment, Low-Latency batched stream processing, Pre-Scheduling
star=****
problem=In batched stream processing frameworks, straggler, happened due to the uneven task execution time, has been regarded as a major hurdle of latency-sensitive applications. 
interest=Many stream processing frameworks have been developed to meet the requirements of real-time processing. Among them, batched stream processing frameworks are widely advocated with the consideration of their fault-tolerance, high throughput and unified runtime with batch processing.
hardness=Existing straggler mitigation techniques, operating in either reactive or proactive manner, are all post-scheduling methods, and therefore inevitably result in high resource overhead or long job completion time.
idea=We notice that batched stream processing jobs are usually recurring with predictable characteristics. By exploring such a heuristic, we present a pre-scheduling straggler mitigation framework called Lever. Lever first identifies potential stragglers and evaluates nodes' capacity by analyzing execution information of historical jobs. Then, Lever carefully pre-schedules job input data to each node before task scheduling so as to mitigate potential stragglers.
future=
comment=We implement Lever and contribute it as an extension of Apache Spark Streaming. 
other=
---
id=230
title=Online Diagnosis of Performance Variation in HPC Systems Using Machine Learning
author=Ozan Tuncer
journal=TPDS
year=2019
tags=Fault Diagnosis, Feature Extraction, Learning Artificial Intelligence, Parallel Processing, Software Fault Tolerance, Software Performance Evaluation, System Monitoring, Time Series, High Performance Computing Systems, System Monitoring, Performance Anomalies, Time Series Data, Anomaly Signature Extraction, Anomaly Detection, HPC System Resiliency, Shared Resource Contention, Machine Learning, Anomaly Diagnosis, HPC System Performance, Feature Extraction, Measurement, Runtime, Anomaly Detection, Machine Learning, Monitoring, Time Series Analysis, High Performance Computing, Anomaly Detection, Machine Learning, Performance Variation, machine learning, HPC(high-performance computing), Online Diagnosis of Performance variation
star=****
problem=As the size and complexity of high performance computing (HPC) systems grow in line with advancements in hardware and software technology, HPC systems increasingly suffer from performance variations due to shared resource contention as well as software- and hardware-related problems. Such performance variations can lead to failures and inefficiencies, which impact the cost and resilience of HPC systems. 
interest=
hardness=To minimize the impact of performance variations, one must quickly and accurately detect and diagnose the anomalies that cause the variations and take mitigating actions. However, it is difficult to identify anomalies based on the voluminous, high-dimensional, and noisy data collected by system monitoring infrastructures. 
idea= a novel machine learning based framework to automatically diagnose performance anomalies at runtime. Our framework leverages historical resource usage data to extract signatures of previously-observed anomalies. We first convert collected time series data into easy-to-compute statistical features. We then identify the features that are required to detect anomalies, and extract the signatures of these anomalies. At runtime, we use these signatures to diagnose anomalies with negligible overhead
future=
comment=
other=
---
id=231
title=A Distributed Multilevel Force-Directed Algorithm
author=Alessio Arleo
journal=TPDS
year=2019
tags=Cloud Computing, Data Visualisation, Directed Graphs, Distributed Multilevel Force Directed Algorithm, Multi Gi LA, Vertex Centric Computation Paradigm, Apache Giraph, Graph Visualization Algorithm, Cloud Computing, Layout, Force, Partitioning Algorithms, Computational Modeling, Sun, Electronic Mail, Distributed Graph Visualization Algorithms, Visual Analytics, Large And Complex Networks, Force-Directed, Distributed Multilevel Algorithm
star=****
problem=This creates the need of developing efficient and effective algorithms that automatically compute graph layouts
interest=The use of graph visualization approaches to present and analyze complex data is taking a leading role in conveying information and knowledge to users in many application domains.
hardness=force-directed algorithms are arguably among the most popular graph layout techniques. Aimed at leveraging the potential of modern distributed graph algorithms platforms
idea=Multi-GiLA, the first multilevel force-directed graph visualization algorithm based on a vertex-centric computation paradigm. We implemented Multi-GiLA using the Apache Giraph platform. 
future=
comment=
other=
---
id=232
title=Persistent Octrees for Parallel Mesh Refinement through Non-Volatile Byte-Addressable Memory (DPM-octree)
author=Bao Nguyen
journal=TPDS
year=2019
tags=Mesh Generation, Octrees, Parallel Processing, Random Access Storage, In Memory Storage, Multiversion Data Structure, DPM Octree Layout, NVBM Induced Memory, In Memory Octant Recovery, DPM Octree Scales, Mesh Elements, Parallel Mesh Refinement, Nonvolatile Byte Addressable Memory, Adaptive Mesh Refinement, Octree Data Structures, Meshing Algorithms, In Core Algorithms, Out Of Core Algorithms, Distributed Persistent Merged Octree, Fluid Dynamics Simulation, Gerris Software, Erasure Coding, Parity Trees, Feature Directed Sampling Approach, Octrees, Random Access Memory, Data Models, Nonvolatile Memory, Computational Modeling, Three Dimensional Displays, Octree, Adaptive Mesh Refinement, Non Volatile Byte Addressable Memory(NVBM), DPM-octree, Simulation of fluid dynamics
star=****
problem=
interest=Adaptive mesh refinement based on octree data structures has enabled efficient simulations of complex physical phenomena. 
hardness=Existing meshing algorithms were proposed with the assumption that computer memory is volatile. Consequently, for failure recovery, in-core algorithms need to save memory states as snapshots with slow file I/O, while out-of-core algorithms store octants on disk for persistence. However, neither was designed to best exploit the unique characteristics of non-volatile byte-addressable memory (NVBM). 
idea=a novel data structure, the Distributed Persistent Merged octree (DPM-octree), for both meshing and in-memory storage of persistent octrees using NVBM. DPM-octree is a multi-version data structure that can recover from failures using an earlier persistent version stored in NVBM. In addition, we design a feature-directed sampling approach to help dynamically transform the DPM-octree layout for reducing NVBM-induced memory write latency. DPM-octree uses parity trees which are created using erasure coding and stored in NVBM to support low-latency in-memory octant recovery after data loss.
future=
comment=DPM-octree has been successfully integrated with the Gerris software for simulation of fluid dynamics.
other=
---
id=233
title=Effective Extensible Programming: Unleashing Julia on GPUs
author=Tim Besard
journal=TPDS
year=2019
tags=Graphics Processing Units(GPU), High Level Languages, Parallel Architectures, Parallel Programming, Program Compilers, Application Code, High Level Julia Programming Language, GPU Programming, Application Performance, Effective Extensible Programming, Accelerators, Popular Devices, Parallelizable Applications, Efficient Device Code, Low Level Programming Language, High Level Language Ecosystem, Compiler Infrastructure, Existing Programming Language, NVIDIA GP Us, NVIDIA CUDA Toolkit, Graphics Processing Units, Programming, Hardware, High Level Languages, Libraries, Graphics Processors, Very High Level Languages, Code Generation, Retargetable Compilers
star=****
problem=
interest=GPUs and other accelerators are popular devices for accelerating compute-intensive, parallelizable applications. 
hardness=However, programming these devices is a difficult task. Writing efficient device code is challenging, and is typically done in a low-level programming language. High-level languages are rarely supported, or do not integrate with the rest of the high-level language ecosystem. 
idea=compiler infrastructure to efficiently add support for new hardware or environments to an existing programming language. We evaluate our approach by adding support for NVIDIA GPUs to the Julia programming language. By integrating with the existing compiler, we significantly lower the cost to implement and maintain the new compiler, and facilitate reuse of existing application code. Moreover, use of the high-level Julia programming language enables new and dynamic approaches for GPU programming. This greatly improves programmer productivity, while maintaining application performance similar to that of the official NVIDIA CUDA toolkit.
future=
comment=
other=
---
id=234
title=Visibility Rendering Order: Improving Energy Efficiency on Mobile GPUs through Frame Coherence (VRO)
author=Enrique de Lucas
journal=TPDS
year=2019
tags=Graphics Processing Units, Rendering Computer Graphics, Pipelines, Geometry, Hardware, Image Color Analysis, Color, mobile GPU, Graphics Pipeline, Energy Efficiency, Rasterization, Rendering, Fragment Processing, Pixel Shading, Occlusion Culling, Visibility, Tile Based Deferred Rendering, Tile Based Rendering, Topological Order, Visibility Rendering Order (VRO)
star=****
problem=During real-time graphics rendering, objects are processed by the GPU in the order they are submitted by the CPU, and occluded surfaces are often processed even though they will end up not being part of the final image, thus wasting precious time and energy. 
interest=
hardness=To help discard occluded surfaces, most current GPUs include an Early-Depth test before the fragment processing stage. However, to be effective it requires that opaque objects are processed in a front-to-back order. Depth sorting and other occlusion culling techniques at the object level incur overheads that are only offset for applications having substantial depth and/or fragment shading complexity, which is often not the case in mobile workloads. 
idea= a novel architectural technique for GPUs, Visibility Rendering Order (VRO), which reorders objects front-to-back entirely in hardware by exploiting the fact that the objects in graphics animated applications tend to keep its relative depth order across consecutive frames (temporal coherence). Since order relationships are already tested by the Depth Test, VRO incurs minimal energy overheads because it just requires adding a small hardware to capture that information and use it later to guide the rendering of the following frame. Moreover, unlike other approaches, this unit works in parallel with the graphics pipeline without any performance overhead.
future=
comment=
other=
---
id=235
title=Parallel Personalized PageRank on Dynamic Graphs   (PPR)
author=Wentian Guo, Yuchen Li, Mo Sha
journal=VLDB
year=2018
tags=PPR, parallel Personalized PageRank, Dynamic Graph
star=****
problem=Personalized PageRank (PPR) is a well-known proximity measure in graphs
interest=
hardness=To meet the need for dynamic PPR maintenance, recent works have proposed a local update scheme to support incremental computation. Nevertheless, sequential execution of the scheme is still too slow for highspeed stream processing
idea=design a parallel approach for dynamic PPR computation.  First, as updates always come in batches, we devise a batch processing method to reduce synchronization cost among every single update and enable more parallelism for iterative parallel execution; devise novel optimization techniques to e↵ectively reduce runtime overheads for parallel processes
future=
comment=Our theoretical analysis shows that the parallel approach has the same asymptotic complexity as the sequential approach; Experimental evaluation shows that our parallel algorithm can achieve orders of magnitude speedups on GPUs and multi-core CPUs compared with the state-of-the-art sequential algorithm.
other=
---
id=236
title=Synthesizing Entity Matching Rules by Examples
author=Rohit Singh
journal=VLDB
year=2018
tags=entity matching rules(EM), program Synthesis, General Boolean formula(GBF), machine learning
star=****
problem=how to synthesize entity matching rules from positive-negative matching examples
interest=Entity matching (EM) is a critical part of data integration
hardness=
idea=The core of our solution is program synthesis, a powerful tool to automatically generate rules (or programs) that satisfy a given high-level specication, via a predefined grammar.
future=
comment=Extensive experiments show that we outperform other interpretable rules (e.g., decision trees with low depth) in effectiveness, and are comparable with non-interpretable tools (e.g., decision trees with high depth, gradient-boosting trees, random forests and SVM).
other=
---
id=237
title=Stylus: A Strongly-Typed Store for Serving Massive RDF Data
author=Liang He, Bin Shao, Yatao Li
journal=VLDB
year=2018
tags=Stylus, Strongly-Typed store, massive RDF data, sparql query processing, graph database, materialized join strategy, Twig, XTwig
star=****
problem=Despite the flexibility of RDF triples, it is challenging to serve SPARQL queries on RDF data efficiently by directly managing triples
interest=RDF is one of the most commonly used knowledge representation forms.
hardness=First, heavy joins on a large number of triples are needed for query processing, resulting in a large number of data scans and large redundant intermediate results; Second, weakly-typed triple representation provides suboptimal random access – typically with logarithmic complexity;   This data access challenge, unfortunately, cannot be easily met by a better query optimizer as large graph processing is extremely I/O-intensive.
idea=strongly-typed graph representation is the key to high-performance RDF query processing. We propose Stylus – a strongly-typed store for serving massive RDF data. Stylus exploits a strongly-typed storage scheme to boost the performance of RDF query processing. The storage scheme is essentially a materialized join view on entities, it thus can eliminate a large number of unnecessary joins on triples. Moreover, it is equipped with a compact representation for intermediate results and an efficient graphdecomposition based query planner
future=
comment=
other=
---
id=238
title=Interleaving with Coroutines: A Practical Approach for Robust Index Joins
author=Georgios Psaropoulos
journal=VLDB
year=2018
tags=robust index join, Interleaving with Coroutines, instruction stream Interleaving, cache miss, CPU architecture, hardware optimization, CSB+-tree
star=****
problem=
interest=robust index join performance becomes possible with instruction stream interleaving: given a group of lookups, we can hide cache misses in one lookup with instructions from other lookups by switching among their respective instruction streams upon a cache miss.
hardness=Index join performance is determined by the efficiency of the lookup operation on the involved index. Although database indexes are highly optimized to leverage processor caches, main memory accesses inevitably increase lookup runtime when the index outsizes the last-level cache; hence, index join performance drops.
idea=propose interleaving with coroutines for any type of index join. We showcase our proposal on SAP HANA by implementing binary search and CSB+-tree traversal for an instance of index join related to dictionary compression.  Coroutine implementations not only perform similarly to prior interleaving techniques, but also resemble the original code closely, while supporting both interleaved and non-interleaved execution
future=
comment=
other=
---
id=239
title=The Part-Time Parliament   (Paxos)
author=Leslie Lamport  (digital equipment corporation)
journal=ACM Transactions on computer system
year=1998
tags=Paxos, Distributed systems, network operating systems, reliability, fault-tolerance, State machines, three-phase commit, voting
star=*****
problem=
interest=
hardness=
idea=
future=
comment=
other=also see [id:240], http://lamport.azurewebsites.net/pubs/pubs.html#lamport-paxos      https://blog.csdn.net/voidccc/article/details/39647787
---
id=240
title=Paxos Made simple  (a brief introduction)
author=Leslie Lamport
journal=
year=2001
tags=Paxos, Distributed systems, network operating systems, reliability, fault-tolerance, State machines, three-phase commit, voting
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=also see [id:239]
---
id=241
title=Pregel: A System for Large-Scale Graph Processing
author=Grzegorz Malewicz  (Google Inc)
journal=SIGMOD
year=2010
tags=Distributed computing, graph algorithms, pregel, Distributed systems, compute models
star=*****
problem=The scale of these graphs|in some cases billions of vertices, trillions of edges|poses challenges to their ecient processing
interest=Many practical computing problems concern large graphs.  Standard examples include the Web graph and various social networks
hardness=
idea=a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertexcentric approach is exible enough to express a broad set of algorithms. The model has been designed for ecient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier.
future=
comment=Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.
other=
---
id=242
title=A Comparison of Adaptive Radix Trees and Hash Tables (Experimental paper)
author=Victor Alvarez
journal=ICDE
year=2015
tags=Adaptive radix trees, hash table, data structure, ARTful, FAST, B+-trees, Judy Array, survey, experimental paper
star=****
problem=
interest=With prices of main memory constantly decreasing, people nowadays are more interested in performing their computations in main memory, and leave high I/O costs of traditional disk-based systems out of the equation. This change of paradigm, however, represents new challenges to the way data should be stored and indexed in main memory in order to be processed efficiently.
hardness=Traditional data structures, like the venerable B-tree, were designed to work on disk-based systems, but they are no longer the way to go in main-memory systems, at least not in their original form, due to the poor cache utilization of the systems they run on. Because of this, in particular, during the last decade there has been a considerable amount of research on index data structures for main-memory systems. Among the most recent and most interesting data structures for main-memory systems there is the recently-proposed adaptive radix tree ARTful (ART for short)
idea=a thorough experimental comparison between ART, Judy, two variants of hashing via quadratic probing, and three variants of Cuckoo hashing. These hashing schemes are known to be very efficient. For our study we consider whether the data structures are to be used as a non-covering index (relying on an additional store), or as a covering index (covering key-value pairs). We consider both OLAP and OLTP scenarios. Our experiments strongly indicate that neither ART nor Judy are competitive to the aforementioned hashing schemes in terms of performance, and, in the case of ART, sometimes not even in terms of space.
future=
comment=The authors of ART presented experiments that indicate that ART was clearly a better choice over other recent tree-based data structures like FAST and B+-trees. However, ART was not the first adaptive radix tree. To the best of our knowledge, the first was the Judy Array (Judy for short), and a comparison between ART and Judy was not shown. Moreover, the same set of experiments indicated that only a hash table was competitive to ART. The hash table used by the authors of ART in their study was a chained hash table, but this kind of hash tables can be suboptimal in terms of space and performance due to their potentially high use of pointers.
other=
---
id=243
title=Hybrid FPGA approach for a B+ tree in a Semantic Web database system
author=Dennis Heinrich
journal=ReCoSoC
year=2015
tags=hybrid FPGA(Field programmable Gate Array), B+ tree, Bplus tree, Semantic web database system
star=***
problem=a hybrid index structure which is allocated in a Field Programmable Gate Array (FPGA) and a traditional CPU-based host system
interest=
hardness=
idea= The lower levels of the B + -tree, especially the leaves where the values are stored, are located on the host system while the root and the most upper levels with the interior nodes are stored on the FPGA. We speed up the search in the upper levels of our hybrid index by applying an FPGA accelerated parallel search.
future=
comment=
other=
---
id=244
title=The Ubiquity of Large Graphs and Surprising Challenges of Graph Processing   (survey)
author=Siddhartha Sahu, M. Tamer Ozsu  (Waterloo University)
journal=VLDB
year=2018
tags=Ubiquity of large graphs, Surprising Challenges of graph processing, survey, database system, RDBMSes
star=****
problem=In spite of this prevalence, there is little research about how graphs are actually used in practice.
interest=Graph processing is becoming increasingly prevalent across many application domains.
hardness=We conducted an online survey aimed at understanding: (i) the types of graphs users have; (ii) the graph computations users run; (iii) the types of graph software users use; and (iv) the major challenges users face when processing their graphs.
idea=We describe the participants’ responses to our questions highlighting common patterns and challenges.  We further reviewed user feedback in the mailing lists, bug reports, and feature requests in the source repositories of a large suite of software products for processing graphs. Through our review, we were able to answer some new questions that were raised by participants’ responses and identify specific challenges that users face when using different classes of graph software
future=
comment=The participants’ responses and data we obtained revealed surprising facts about graph processing in practice. In particular, real-world graphs represent a very diverse range of entities and are often very large, and scalability and visualization are undeniably the most pressing challenges faced by participants. We hope these findings can guide future research.
other=
---
id=245
title=Clustering Stream Data by Exploring the Evolution of Density Mountain  (EDMStream)
author=Shufeng Gong, Ge Yu
journal=VLDB
year=2018
tags=clustering stream data, Evolution of density mountain, EDMStream, DStream, MR-Stream, DBSTREAM, DenStream
star=****
problem=Stream clustering is a fundamental problem in many streaming data analysis applications.
interest=
hardness=Comparing to classical batch-mode clustering, there are two key challenges in stream clustering: (i) Given that input data are changing continuously, how to incrementally update their clustering results efficiently? (ii) Given that clusters continuously evolve with the evolution of data, how to capture the cluster evolution activities? Unfortunately, most of existing stream clustering algorithms can neither update the cluster result in real-time nor track the evolution of clusters.
idea=a stream clustering algorithm EDMStream by exploring the Evolution of DensityMountain.  The density mountain is used to abstract the data distribution, the changes of which indicate data distribution evolution. We track the evolution of clusters by monitoring the changes of density mountains. We further provide efficient data structures and filtering schemes to ensure that the update of density mountains is in real-time, which makes online clustering possible.
future=
comment=comparing to the state-of-the-art stream clustering algorithms, e.g., DStream, DenStream, DBSTREAM and MR-Stream, our algorithm is able to response to a cluster update much faster (say 7-15x faster than the best of the competitors) and at the same time achieve comparable cluster quality.  Furthermore, EDMStream successfully captures the cluster evolution activities.
other=
---
id=246
title=Froid: Optimization of Imperative Programs in a Relational Database
author=Karthik Ramachandra  (Microsoft Gray Systems Lab)
journal=VLDB
year=2018
tags=Froid, Imperative Programs, Relational Database, declarative SQL query, RDBMS, User Defined Functions(UDFs), relational algebraic expressions
star=****
problem=While the evaluation of declarative SQL has received a lot of attention resulting in highly sophisticated techniques, the evaluation of imperative programs has remained nave and highly inecient.
interest=For decades, RDBMSs have supported declarative SQL as well as imperative functions and procedures as ways for users to express data processing tasks;   Imperative programs oer several benets over SQL and hence are often preferred and widely used.
hardness=But unfortunately, their abysmal performance discourages, and even prohibits their use in many situations. We address this important problem that has hitherto received little attention
idea=Froid, an extensible framework for optimizing imperative programs in relational databases. Froid's novel approach automatically transforms entire User Defined Functions (UDFs) into relational algebraic expressions, and embeds them into the calling SQL query. This form is now amenable to cost-based optimization and results in ef- cient, set-oriented, parallel plans as opposed to inecient, iterative, serial execution of UDFs.
future=
comment=Froid's approach additionally brings the benets of many compiler optimizations to UDFs with no additional implementation eort. We describe the design of Froid and present our experimental evaluation that demonstrates performance improvements of up to multiple orders of magnitude on real workloads.
other=functional, declarative and imperative programming: https://stackoverflow.com/questions/602444/functional-declarative-and-imperative-programming
---
id=247
title=An Experimental Study on Hub Labeling based Shortest Path Algorithms (experimental paper, survey)
author=Ye Li
journal=VLDB
year=2018
tags=survey, experiments paper, hub labeling(HL), Shortest path Algorithms, Signicant path based Hub Pushing (SHP)
star=****
problem=Shortest path distance retrieval is a core component in many important applications
interest=For a decade, hub labeling (HL) techniques have been considered as a practical solution with fast query response time (e.g., 1-3 orders of magnitude faster), competitive indexing time, and slightly larger storage overhead (e.g., several times larger). These techniques enhance query throughput up to hundred thousands queries per second, which is particularly helpful in large user environment.
hardness=Despite the importance of HL techniques, we are not aware of any comprehensive experimental study on HL techniques. Thus it is dicult for a practitioner to adopt HL techniques for her applications.
idea=a comprehensive experimental study on the state-of-the-art HL technique with analysis of their eciency, eectiveness and applicability.  From insightful summary of dierent HL techniques, we further develop a simple yet eective HL techniques called Signicant path based Hub Pushing (SHP) which greatly improves indexing time of previous techniques while retains good query performance.
future=
comment=We also complement extensive comparisons between HL techniques and other shortest path solutions to demonstrate robustness and eciency of HL techniques.
other=
---
id=248
title=SQL Statement Logging for Making SQLite Truly Lite
author=Jong-Hyeok Park
journal=VLDB
year=2018
tags=SQL Statement logging, vanilla SQLite, SQLite/SSL, strong update locality, SQLite-based mobile application, SQLite/PPL, IO efficiency, byte-addressable NVM(non-volatile memory), WAL journal mode
star=****
problem=forced it to take less-complicated transactional schemes, such as physical page logging, journaling, and force commit, which in turn cause excessive write amplification. Thus, the write IO cost in SQLite is not lightweight at all.
interest=The lightweight codebase of SQLite was helpful in making it become the de-facto standard database in most mobile devices
hardness=
idea=to make SQLite truly lite in terms of IO efficiency for the transactional support, we propose SQLite/SSL, a per-transaction SQL statement logging scheme: when a transaction commits, SQLite/SSL ensures its durability by storing only SQL statements of small size, thus writing less and performing faster at no compromise of transactional solidity. Our main contribution is to show that, based on the observation that mobile transactions tend to be short and exhibit strong update locality, logical logging can, though long discarded, become an elegant and perfect fit for SQLite-based mobile applications. Further, we leverage the WAL journal mode in vanilla SQLite as a transaction-consistent checkpoint mechanism which is indispensable in any logical logging scheme. In addition, we show for the first time that byte-addressable NVM (non-volatile memory) in host-side can realize the full potential of logical logging because it allows to store fine-grained logs quickly.
future=
comment=We have prototyped SQLite/SSL by augmenting vanilla SQLite with a transaction-consistent checkpoint mechanism and a redo-only recovery logic, and have evaluated its performance using a set of synthetic and real workloads. When a real NVMboard is used as its log device, SQLite/SSL can outperform vanilla SQLite’s WAL mode by up to 300x and also outperform the state-of-the-arts SQLite/PPL scheme by several folds in terms of IO time.
other=
---
id=249
title=Cardinality Estimation: An Experimental Survey    (survey, experimental paper)
author=Hazar Harmouch
journal=VLDB
year=2018
tags=Cardinality Estimation, Experimental paper, survey, zeroth-frequency moment, data preparation, data profiling, data distribution, the number of distinct values in each column, 
star=****
problem=Cardinality estimation itself has been an active research topic in the past decades due to its many applications.
interest=Data preparation and data profiling comprise many both basic and complex tasks to analyze a dataset at hand and extract metadata, such as data distributions, key candidates, and functional dependencies;  Among the most important types of metadata is the number of distinct values in a column, also known as the zeroth-frequency moment.
hardness=review the literature of cardinality estimation and to present a detailed experimental study of twelve algorithms, scaling far beyond the original experiments
idea=First, we outline and classify approaches to solve the problem of cardinality estimation we describe their main idea, error-guarantees, advantages, and disadvantages. Our experimental survey then compares the performance all twelve cardinality estimation algorithms. We evaluate the algorithms' accuracy, runtime, and memory consumption using synthetic and real-world datasets.
future=
comment=Our results show that dierent algorithms excel in dierent in categories, and we highlight their trade-os.
other=
---
id=250
title=Clustering Uncertain Graphs
author=Matteo Ceccarello
journal=VLDB
year=2018
tags=Uncertain graphs, clustering, probability, NP-hardness, maximizing the minimum connection probability, approximation guarantee
star=****
problem=a probability space whose outcomes (referred to as possible worlds), each edge occurs with probability p(e)
interest=These graphs naturally arise in many application domains where data management systems are required to cope with uncertainty in interrelated data, such as computational biology, social network analysis, network reliability, and privacy enforcement, among the others. For this reason, it is important to devise fundamental querying and mining primitives for uncertain graphs.
hardness=
idea=This paper contributes to this endeavor with the development of novel strategies for clustering uncertain graphs. Specifically, given an uncertain graph G and an integer k, we aim at partitioning its nodes into k clusters, each featuring a distinguished center node, so to maximize the minimum/average connection probability of any node to its cluster’s center, in a random possible world.
future=
comment=We assess the NP-hardness of maximizing the minimum connection probability, even in the presence of an oracle for the connection probabilities, and develop efficient approximation algorithms for both problems and some useful variants.  Unlike previous works in the literature, our algorithms feature provable approximation guarantees and are capable to keep the granularity of the returned clustering under control.  Our theoretical findings are complemented with several experiments that compare our algorithms against some relevant competitors, with respect to both running-time and quality of the returned clusterings.
other=
---
id=251
title=Concurrent Log-Structured Memory for Many-Core Key-Value Stores (Nibble)
author=Alexander Merritt
journal=VLDB
year=2018
tags=key-value stores, many-core, concurrent Log-Structured memory, Nibble, multi-head log, distributed epoch, Rust
star=****
problem=
interest=Key-value stores are an important tool in managing and accessing large in-memory data sets. As many applications benefit from having as much of their working state fit into main memory, an important design of the memory management of modern key-value stores is the use of log-structured approaches, enabling ecient use of the memory capacity, by compacting objects to avoid fragmented states.
hardness=with the emergence of thousand-core and peta-byte memory platforms (DRAM or future storage-class memories) logstructured designs struggle to scale, preventing parallel applications from exploiting the full capabilities of the hardware: careful coordination is required for background activities (compacting and organizing memory) to remain asynchronous with respect to the use of the interface, and for insertion operations to avoid contending for centralized resources such as the log head and memory pools.
idea=the design of a log-structured key-value store called Nibble that incorporates a multi-head log for supporting concurrent writes, a novel distributed epoch mechanism for scalable memory reclamation, and an optimistic concurrency index.
future=
comment=Nibble scales linearly in uniform YCSB workloads, matching competitive nonlog- structured key-value stores for write- dominated traces at 50 million operations per second on 1 TiB-sized working sets. Our memory analysis shows Nibble is ecient, requiring less than 10% additional capacity, whereas memory use by non-log-structured key-value store designs may be as high as 2x.
other=
---
id=252
title=BzTree: A High-Performance Latch-free Range Index for Non-Volatile Memory
author=Joy Arulraj
journal=VLDB
year=2018
tags=new hardware, Non-Volatile memory(NVM), BzTree, Latch-free Range Index, Bw-tree, skip lists
star=****
problem=To achieve high performance NVM-resident indexes also need to be latch-free
interest=Storing a database (rows and indexes) entirely in non-volatile memory (NVM) potentially enables both high performance and fast recovery. To fully exploit parallelism on modern CPUs, modern main-memory databases use latch-free (lock-free) index structures, e.g. Bw-tree or skip lists.
hardness=
idea=BzTree, a latch-free B-tree index designed for NVM.  The BzTree uses a persistent multi-word compare-and-swap operation (PMwCAS) as a core building block, enabling an index design that has several important advantages compared with competing index structures such as the Bw-tree.
future=
comment=First, the BzTree is latch-free yet simple to implement. Second, the BzTree is fast - showing up to 2x higher throughput than the Bw-tree in our experiments.  Third, the BzTree does not require any special-purpose recovery code. Recovery is near-instantaneous and only involves rolling back (or forward) any PMwCAS operations that were in-flight during failure
other=
---
id=253
title=Contention-Aware Lock Scheduling for Transactional Databases
author=Boyu Tian, Jiamin Huang
journal=VLDB
year=2018
tags=LDSF, bLDSF, FIFO, Contention-Aware lock Scheduling, Transactional databases, TPC-C, practical and used by MySQL, lock selection
star=****
problem=When there are multiple lock requests on the same object, which one(s) should be granted first?
interest=Lock managers are among the most studied components in concurrency control and transactional systems.
hardness=Nearly all existing systems rely on a FIFO (first in, first out) strategy to decide which transaction(s) to grant the lock to.
idea=the lock scheduling choices have significant ramifications on the overall performance of a transactional system. Despite the large body of research on job scheduling outside the database context, lock scheduling presents subtle but challenging requirements that render existing results on scheduling inapt for a transactional database. By carefully studying this problem, we present the concept of contention-aware scheduling, show the hardness of the problem, and propose novel lock scheduling algorithms (LDSF and bLDSF), which guarantee a constant factor approximation of the best scheduling
future=
comment=extensive experiments using a popular database on both TPC-C and a microbenchmark. Compared to FIFO—the default scheduler in most database systems—our bLDSF algorithm yields up to 300x speedup in overall transaction latency. Alternatively, our LDSF algorithm, which is simpler and achieves comparable performance to bLDSF, has already been adopted by open-source community, and was chosen as the default scheduling strategy in MySQL 8.0.3+.
other=
---
id=254
title=Domain-Aware Multi-Truth Discovery from Conflicting Sources
author=Xuemin Lin, Lei Chen
journal=VLDB
year=2018
tags=Domain-Aware, multi-truth Discovery, Conflicting sources, Big Data era, truth discovery, Bayesian
star=****
problem=The most significant challenge for this task is to estimate source reliability and select the answers supported by high quality sources
interest=In the Big Data era, truth discovery has served as a promising technique to solve conflicts in the facts provided by numerous data sources.
hardness=existing works assume that one data source has the same reliability on any kinds of entity, ignoring the possibility that a source may vary in reliability on different domains.
idea=To capture the influence of various levels of expertise in different domains, we integrate domain expertise knowledge to achieve a more precise estimation of source reliability. We propose to infer the domain expertise of a data source based on its data richness in different domains. We also study the mutual influence between domains, which will affect the inference of domain expertise. Through leveraging the unique features of the multi-truth problem that sources may provide partially correct values of a data item, we assign more reasonable confidence scores to value sets. We propose an integrated Bayesian approach to incorporate the domain expertise of data sources and confidence scores of value sets, aiming to find multiple possible truths without any supervision.
future=
comment=
other=
---
id=255
title=Ease.ml: Towards Multi-tenant Resource Sharing for Machine Learning Workloads
author=Tian Li, Wentao Wu
journal=VLDB
year=2018
tags=Machine Learning Workloads, Bayesian, Azure ML Studio, Multi-tenant Resource Sharing, minimal regret, Multi-tenant model selection
star=****
problem=We present ease.ml, a declarative machine learning service platform.  With ease.ml, a user defines the high-level schema of an ML application and submits the task via a Web interface. The system then deals with the rest, such as model selection and data movement. The ultimate question we hope to understand is that, as a “service provider” that manages a shared cluster of machines running machine learning workloads, what is the resource sharing strategy that maximizes the global satisfaction of all our users?
interest=
hardness=This paper does not completely answer this general question, but focuses on solving the first technical challenge we were facing when trying to build ease.ml. We observe that resource sharing is a critical yet subtle issue in this multi-tenant scenario, as we have to balance between efficiency and fairness. We first formalize the problem that we call multi-tenant model selection, aiming for minimizing the total regret of all users running automatic model selection tasks.
idea=develop a novel algorithm that combines multi-armed bandits with Bayesian optimization and prove a regret bound under the multi-tenant setting.
future=
comment=
other=
---
id=256
title=Theoretically Optimal and Empirically Efficient R-trees with Strong Parallelizability
author=Jianzhong Qi
journal=VLDB
year=2018
tags=I/O complexity, R-tree, stong Parallelizability, worst-case workload analysis, bulk-loading, massively parallel communication model(MPC), MapReduce, Spark, distributed computing
star=****
problem=To address this need, we revisit a classic multi-dimensional access method the R-tree. 
interest=The massive amount of data and large variety of data distributions in the big data era call for access methods that are ecient in both query processing and index bulk-loading, and over both practical and worst-case workloads.
hardness=
idea=a novel R-tree packing strategy that produces R-trees with an asymptotically optimal I/O complexity for window queries in the worst case.
future=
comment=The proposed strategy is also simple to parallelize, since it relies only on sorting. We propose a parallel algorithm for R-tree bulk-loading based on the proposed packing strategy, and analyze its performance under the massively parallel communication model.
other=
---
id=257
title=FlexPS: Flexible Parallelism Control in Parameter Server Architecture
author=Yuzhen Huang
journal=VLDB
year=2018
tags=FlexPS, flexible Parallelism control, Parameter server Architecture, distributed machine learning, PS systems, Petuum, Multiverso, multi-stage abstraction
star=****
problem=
interest=As a general abstraction for coordinating the distributed storage and access of model parameters, the parameter server (PS) architecture enables distributed machine learning to handle large datasets and high dimensional models.  Many systems, such as Parameter Server and Petuum, have been developed based on the PS architecture and widely used in practice.
hardness=none of these systems supports changing parallelism during runtime, which is crucial for the efficient execution of machine learning tasks with dynamic workloads.
idea=FlexPS, which introduces a novel multi-stage abstraction to support flexible parallelism control. With the multi-stage abstraction, a machine learning task can be mapped to a series of stages and the parallelism for a stage can be set according to its workload. Optimizations such as stage scheduler, stageaware consistency controller, and direct model transfer are proposed for the efficiency of multi-stage machine learning in FlexPS. As a general and complete PS systems, FlexPS also incorporates many optimizations that are not limited to multi-stage machine learning
future=
comment=
other=
---
id=258
title=Table Union Search on Open Data
author=Fatemeh Nargesian
journal=VLDB
year=2018
tags=table union search, Open Data table(open-sourced a benchmark)
star=****
problem=
interest=We define the table union search problem and present a probabilistic solution for finding tables that are unionable with a query table within massive repositories. Two tables are unionable if they share attributes from the same domain
hardness=Our solution formalizes three statistical models that describe how unionable attributes are generated from set domains, semantic domains with values from an ontology, and natural language domains.
idea=a data-driven approach that automatically determines the best model to use for each pair of attributes. Through a distribution-aware algorithm, we are able to find the optimal number of attributes in two tables that can be unioned.
future=
comment=
other=
---
id=259
title=LA3: A Scalable Linkand LocalityAware Linear AlgebraBased Graph Analytics System
author=Yousuf Ahmad
journal=VLDB
year=2018
tags=LA3,distributed computing, link-aware, Locality-aware, linear Algebra, graph analytics system, SpMV, computation filtering, communication filtering, pseudo-asynchronous computation and communication
star=****
problem=LA3, a scalable distributed system for graph analytics. LA3 couples a vertex-based programming model with a highly optimized linear algebra-based engine.  It translates any vertex-centric program into an iteratively executed sparse matrix-vector multiplication (SpMV).
interest=
hardness=
idea=To reduce communication and enhance scalability, the adjacency matrix representing an input graph is partitioned into locality-aware 2D tiles distributed across multiple processes.  Alongside, three major optimizations are incorporated to preclude redundant computations and minimize communication.  First, the link-based structure of the input graph is exploited to classify vertices into dierent types. Afterwards, vertices of special types are factored out of the main loop of the graph application to avoid superuous computations.  We refer to this novel optimization as computation ltering. Second, a communication ltering mechanism is involved to optimize for the high sparsity of the input matrix due to power-law distributions, common in real-world graphs. This optimization ensures that each process receives only the messages that pertain to non-zero entries in its tiles, substantially reducing communication trac since most tiles are highly sparse. Lastly, a pseudo-asynchronous computa- tion and communication optimization is proposed, whereby processes progress and communicate asynchronously, consume messages as soon as they become available, and block otherwise.
future=
comment=We implemented and extensively tested LA3 on private and public clouds. Results show that LA3 outperforms six related state-of-the-art and popular distributed graph analytics systems by an average of 10.
other=
---
id=260
title=HD-Index: Pushing the Scalability-Accuracy Boundary for Approximate kNN Search in High-Dimensional Spaces
author=Akhil Arora
journal=VLDB
year=2018
tags=HD-Index, Scalability-Accuracy Boundary, Approximate KNN search, High-Dimensional spaces, Approximate k-nearest neighbor queries, Hierarchical structures, RDB-trees, Hilbert keys, database objects, triangular inequality, Ptolemaic inequality
star=****
problem=Nearest neighbor searching of large databases in high-dimensional spaces is inherently difficult due to the curse of dimensionality
interest=A flavor of approximation is, therefore, necessary to practically solve the problem of nearest neighbor search.
hardness=
idea=a novel yet simple indexing scheme, HD-Index, to solve the problem of approximate k-nearest neighbor queries in massive highdimensional databases. HD-Index consists of a set of novel hierarchical structures called RDB-trees built on Hilbert keys of database objects. The leaves of the RDB-trees store distances of database objects to reference objects, thereby allowing efficient pruning using distance filters. In addition to triangular inequality, we also use Ptolemaic inequality to produce better lower bounds
future=
comment=Experiments on massive (up to billion scale) high-dimensional (up to 1000+) datasets show that HD-Index is effective, efficient, and scalable.
other=
---
id=261
title=Effective Temporal Dependence Discovery in Time Series Data
author=Qingchao Cai
journal=VLDB
year=2018
tags=Temporal Dependence Discovery, time series data, recurrent cohort analysis, distributed environments
star=****
problem=
interest=To analyze user behavior over time, it is useful to group users into cohorts, giving rise to cohort analysis.
hardness=We identify several crucial limitations of current cohort analysis, motivated by the unmet need for temporal dependence discovery.
idea=To address these limitations, we propose a generalization that we call recurrent cohort analysis. We introduce a set of operators for recurrent cohort analysis and design access methods specic to these operators in both single-node and distributed environments.
future=
comment=
other=
---
id=262
title=Exact Processing of Uncertain Top-k Queries in Multi-criteria Settings
author=Kyriakos Mouratidis, Bo Tang
journal=VLDB
year=2018
tags=Uncertain top-k query(UTK), rank-aware, multi-criteria settings
star=****
problem=
interest=Traditional rank-aware processing assumes a dataset that contains available options to cover a specic need (e.g., restaurants, hotels, etc) and users who browse that dataset via top-k queries with linear scoring functions, i.e., by ranking the options according to the weighted sum of their attributes, for a set of given weights.
hardness=user preferences (weights) may only be estimated with bounded accuracy, or may be inherently uncertain due to the inability of a human user to specify exact weight values with absolute accuracy.
idea=uncertain top-k query (UTK). Given uncertain preferences, that is, an approximate description of the weight values, the UTK query reports all options that may belong to the top-k set.  A second version of the problem additionally reports the exact top-k set for each of the possible weight settings.
future=
comment=We develop a scalable processing framework for both UTK versions, and demonstrate its eciency using standard benchmark datasets.
other=
---
id=263
title=Scaling Up Subgraph Query Processing with Efficient Subgraph Matching  (CFQL)
author=Shixuan Sun (Hong Kong University of science and Technology)
journal=ICDE
year=2019
tags=subgraph query processing, efficient subgraph matching, sequential subgraph isomorphism, graph database, indexing-filtering-verification(IFV), subgraph Containment, graph index, vertex connectivity based filtering-verification(vcFV), IvcFV
star=****
problem=A subgraph query finds all data graphs in a graph database each of which contains the given query graph; how to utilize efficient subgraph matching to improve subgraph query processing
interest=Existing work takes the indexing-filtering-verification (IFV) approach to first index all data graphs, then filter out some of them based on the index, and finally test subgraph isomorphism on each of the remaining data graphs.
hardness=This final test of subgraph isomorphism is a sub-problem of subgraph matching, which finds all subgraph isomorphisms from a query graph to a data graph.
idea=Specifically, we modify leading subgraph matching algorithms and integrate them with top-performing subgraph querying algorithms. Our results show that (1) the slow verification method in existing IFV algorithms can lead us to over-estimate the gain of filtering; and (2) our modified subgraph querying algorithms with efficient subgraph matching are competitive in time performance and can scale to hundreds of thousands of data graphs and graphs of thousands of vertices.
future=
comment=Our results show that working without an index, vcFV algorithms eliminate the problems of index scalability and index update cost, and outperform the IFV algorithms on both query time and scalability. Also, vcFV algorithms can work on the graphs that are frequently updated.
other=
---
id=264
title=Efficient Parallel Subgraph Enumeration on a Single Machine
author=Shixuan Sun (Hong Kong University of science and Technology)
journal=ICDE
year=2019
tags=subgraph matching, parallel subgraph Enumeration, single machine
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=265
title=BENU: Distributed Subgraph Enumeration with Backtracking-based Framework
author=Zhaokang Wang (Nanjing University)
journal=ICDE
year=2019
tags=BENU, subgraph matching, distributed subgraph Enumeration, Backtracking-based Framework
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=266
title=Efficiently computing Top-K shortest path join  (KPJ)
author=Lijun Chang, Jeffrey xu Yu
journal=EDBT
year=2015
tags=top-k shortest path join(KPJ), top-k shortets paths(KSP)
star=***
problem=computing the top-k shortest paths from one set of target nodes to another set of target nodes in a graph, namely the top-k shortest path join (KPJ) between two sets of target nodes
interest=
hardness=While KPJ is an extension of the problem of computing the top-k shortest paths (KSP) between two target nodes, the existing technique by converting KPJ to KSP has several deficiencies in conducting the computation.
idea=use the best-first paradigm to recursively divide search subspaces into smaller subspaces, and to compute the shortest path in each of the subspaces in a prioritized order based on their lower bounds. Consequently, we only compute shortest paths in subspaces whose lower bounds are larger than the length of the current k-th shortest path. To improve the efficiency, we further propose an iteratively bounding approach to tightening lower bounds of subspaces. Moreover, we propose two index structures which can be used to reduce the exploration area of a graph dramatically; these greatly speed up the computation. 
future=
comment=Furthermore, our approaches can be immediately used to compute KSP
other=
---
id=267
title=Column-oriented Database Acceleration using FPGAs
author=Satoru Watanabe
journal=ICDE
year=2019
tags=Column-oriented database Acceleration, FPGA, new hardware
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=268
title=Hardware-conscious Hash-Joins on GPUs
author=Panagiotis Sioulas
journal=ICDE
year=2019
tags=new hardware,Hardware-conscious, hash-join, GPU
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=269
title=TuFast: A Lightweight Parallelization Library for Graph Analytics
author=Zechao Shang, Jeffrey Xu Yu
journal=ICDE
year=2019
tags=new hardware,TuFast, Lightweight Parallelization library, graph analytics
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=270
title=LDC: A Lower-Level Driven Compaction Method to Optimize SSD-Oriented Key-Value Stores
author=yunpeng chai (renmin University of China)
journal=ICDE
year=2019
tags=new hardware,LDC, lower-level driven Compaction method, SSD-Oriented key-value stores
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=271
title=No False Negatives: Accepting All Useful Schedules in a Fast Serializable Many-Core System
author=Dominik Durner (Technical University of Munich)
journal=ICDE
year=2019
tags=new hardware,schedule, fast Serializable many-core system
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=272
title=Leveraging Similarity Joins for Signal Reconstruction
author=Abolfazl Asudeh
journal=VLDB
year=2018
tags=Similarity join, signal Reconstruction problem(SRP), linear equations, network traffic engineering, medical image Reconstruction
star=****
problem=Signal reconstruction problem (SRP) is an important optimization problem where the objective is to identify a solution to an under-determined system of linear equations that is closest to a given prior
interest=It has a substantial number of applications in diverse areas in- cluding network traffic engineering, medical image reconstruction, acoustics, astronomy and many more.
hardness=Most common approaches for SRP do not scale to large problem sizes.
idea=a dual formulation of this problem and show how adapt- ing database techniques developed for scalable similarity joins provides a significant speedup.
future=
comment=
other=
---
id=273
title=Chi: A Scalable and Programmable Control Plane for Distributed Stream Processing Systems
author=Luo Mai
journal=VLDB
year=2018
tags=Distributed stream processing systems, Stream-processing workloads, user SLOs
star=****
problem=Chi, Stream-processing workloads and modern shared cluster environments exhibit high variability and unpredictability
interest=
hardness=Combined with the large parameter space and the diverse set of user SLOs, this makes modern streaming systems very challenging to statically configure and tune.
idea=a novel control-plane design, Chi, which supports continuous monitoring and feedback, and enables dynamic re-configuration. Chi leverages the key insight of embedding control-plane messages in the data-plane channels to achieve a low-latency and flexible control plane for stream-processing systems.  Chi introduces a new reactive programming model and design mechanisms to asynchronously execute control policies, thus avoiding global synchronization.
future=
comment=We show how this allows us to easily implement a wide spectrum of control policies targeting different use cases observed in production. Large-scale experiments using production workloads from a popular cloud provider demonstrate the flexibility and efficiency of our approach.
other=
---
id=274
title=Sundial: Harmonizing Concurrency Control and Caching in a Distributed OLTP Database Management System
author=Xiangyao Yu
journal=VLDB
year=2018
tags=Sundial, Concurrency control, logical leases, cache coherence, Distributed OLTP Database Management system, Distributed transactions
star=****
problem=Distributed transactions suffer from poor performance due to two major limiting factors. First, distributed transactions suffer from high latency because each of their accesses to remote data incurs a long network delay. Second, this high latency increases the likelihood of contention among distributed transactions, leading to high abort rates and low performance.
interest=
hardness=
idea=Sundial, an in-memory distributed optimistic concurrency control protocol that addresses these two limitations. First, to reduce the transaction abort rate, Sundial dynamically determines the logical order among transactions at runtime, based on their data access patterns. Sundial achieves this by applying logical leases to each data element, which allows the database to dynamically calculate a transaction’s logical commit timestamp. Second, to reduce the overhead of remote data accesses, Sundial allows the database to cache remote data in a server’s local main memory and maintains cache coherence
future=
comment=With logical leases, Sundial integrates concurrency control and cache coherence into a simple unified protocol.
other=
---
id=275
title=Maximum Co-located Community Search in Large Scale Social Networks
author=Lu Chen
journal=VLDB
year=2018
tags=maximum Co-located Community search, large scale social networks, spatial information
star=****
problem=The problem of k-truss search has been well dened and investigated to nd the highly correlated user groups in social networks.
interest=The co-located community can serve many real applications.
hardness=But there is no previous study to consider the constraint of users' spatial information in k-truss search, denoted as co-located community search in this paper.
idea=To search the maximum co-located communities eciently, we rst develop an ecient exact algorithm with several pruning techniques. After that, we further develop an approximation algorithm with adjustable accuracy guarantees and explore more eective pruning rules, which can reduce the computational cost signicantly. To accelerate the real-time eciency, we also devise a novel quadtree based index to support the ecient retrieval of users in a region and optimise the search regions with regards to the given query region
future=
comment=
other=
---
id=276
title=MLBench: Benchmarking Machine Learning Services Against Human Experts
author=Yu Liu, Hantian Zhang
journal=VLDB
year=2018
tags=MLBench, Machine Learning Services, Human Experts, AI, Kaggle competition
star=****
problem=Providing different levels of system supports for different functionalities, such as automatic feature engineering, model selection and ensemble, and hyperparameter tuning, could improve the quality, but also introduce additional cost and system complexity
interest=Modern machine learning services and systems are complicated data systems — the process of designing such systems is an art of compromising between functionality, performance, and quality.
hardness=In this paper, we try to facilitate the process of asking the following type of questions: How much will the users lose if we remove the support of functionality x from a machine learning service?
idea=Unlike existing datasets, MLBench contains not only the raw features for a machine learning task, but also those used by the winning teams of Kaggle competitions. The winning features serve as a baseline of best human effort that enables multiple ways to measure the quality of machine learning services that cannot be supported by existing datasets, such as relative ranking on Kaggle and relative accuracy compared with best-effort systems.  We then conduct an empirical study using MLBench to understand example machine learning services from Amazon and Microsoft Azure, and showcase how MLBench enables a comparative study revealing the strength and weakness of these existing machine learning services quantitatively and systematically.
future=
comment=
other=
---
id=277
title=Experimental Analysis of Distributed Graph Systems  (survey, Experimental paper)
author=Khaled Ammar, M. Tamer Ozsu
journal=VLDB
year=2018
tags=survey, Experimental paper, Experimental analysis, Distributed graph Systems, Hadoop, HaLoop, Vertica, Giraph, GraphLab(PowerGraph), Blogel, Flink Gelly, GraphX(Spark)
star=****
problem=This paper evaluates eight parallel graph processing systems: Hadoop, HaLoop, Vertica, Giraph, GraphLab (PowerGraph), Blogel, Flink Gelly, and GraphX (SPARK) over four very large datasets (Twitter, World Road Network, UK 200705, and ClueWeb) using four workloads (PageRank, WCC, SSSP and K-hop).
interest=
hardness=
idea=The main objective is to perform an independent scale-out study by experimentally analyzing the performance, usability, and scalability (using up to 128 machines) of these systems.
future=
comment=In addition to performance results, we discuss our experiences in using these systems and suggest some system tuning heuristics that lead to better performance.
other=
---
id=278
title=Set Similarity Joins on MapReduce: An Experimental Survey
author=Fabian Fier
journal=VLDB
year=2018
tags=distributed set Similarity join, MapReduce, Experimental paper, survey
star=****
problem=
interest=Set similarity joins, which compute pairs of similar sets, constitute an important operator primitive in a variety of applications, including applications that must process large amounts of data.
hardness=To handle these data volumes, several distributed set similarity join algorithms have been proposed. Unfortunately, little is known about the relative performance, strengths and weaknesses of these techniques.  Previous comparisons are limited to a small subset of relevant algorithms, and the large differences in the various test setups make it hard to draw overall conclusions.
idea=we survey ten recent, distributed set similarity join algorithms, all based on the MapReduce paradigm. We empirically compare the algorithms in a uniform test environment on twelve datasets that expose different characteristics and represent a broad range of applications. Our experiments yield a surprising result: All algorithms in our test fail to scale for at least one dataset and are sensitive to long sets, frequent set elements, low similarity thresholds, or a combination thereof. Interestingly, some algorithms even fail to handle the small datasets that can easily be processed in a non-distributed setting
future=
comment=Our analytic investigation of the algorithms pinpoints the reasons for the poor performance and targeted experiments confirm our analytic findings. Based on our investigation, we suggest directions for future research in the area.
other=
---
id=279
title=Data Synthesis based on Generative Adversarial Networks  (table-GAN)
author=Noseong Park
journal=VLDB
year=2018
tags=table-GAN,data Synthesis, Generative Adversarial Networks(GAN), machien learning
star=****
problem=
interest=Privacy is an important concern for our society where sharing data with partners or releasing data to the public is a frequent occurrence.  Some of the techniques that are being used to achieve privacy are to remove identifiers, alter quasi-identifiers, and perturb values.
hardness=these approaches suffer from two limitations.  First, it has been shown that private information can still be leaked if attackers possess some background knowledge or other information sources. Second, they do not take into account the adverse impact these methods will have on the utility of the released data.
idea=table-GAN, uses generative adversarial networks (GANs) to synthesize fake tables that are statistically similar to the original table yet do not incur information leakage. We show that the machine learning models trained using our synthetic tables exhibit performance that is similar to that of models trained using the original table for unknown testing cases. We call this property model compatibility
future=
comment=We believe that anonymization/perturbation/synthesis methods without model compatibility are of little value. We used four real-world datasets from four different domains for our experiments and conducted indepth comparisons with state-of-the-art anonymization, perturbation, and generation techniques. Throughout our experiments, only our method consistently shows balance between privacy level and model compatibility.
other=
---
id=280
title=Morton Filters: Faster, Space-Efficient Cuckoo Filters via Biasing, Compression, and Decoupled Logical Sparsity
author=Alex D. Breslow
journal=VLDB
year=2018
tags=Morton Filters(MF), Cuckoo Filters(CF), Biasing, Compression, Decoupled Logical Sparsity, approximate set membership data structures(ASMDSs), Bloom Filter, hash
star=****
problem=Approximate set membership data structures (ASMDSs) are ubiquitous in computing. They trade a tunable, often small, error rate (epison) for large space savings.
interest=The canonical ASMDS is the Bloom lter, which supports lookups and insertions but not deletions in its simplest form. Cuckoo lters (CFs), a recently proposed class of ASMDSs, add deletion support and often use fewer bits per item for equal epison.
hardness=
idea=MFs achieve these improvements by (1) introducing a compressed format that permits a logically sparse lter to be stored compactly in memory, (2) leveraging succinct embedded metadata to prune unnecessary memory accesses, and (3) heavily biasing insertions to use a single hash function. With these optimizations, lookups, insertions, and deletions often only require accessing a single hardware cache line from the lter.
future=
comment=Morton lter (MF), a novel ASMDS that introduces several key improvements to CFs. Like CFs, MFs support lookups, insertions, and deletions, but improve their respective throughputs by 1.3 to 2.5, 0.9 to 15.5, and 1.3 to 1.6;   These improvements are not at a loss in space eciency, as MFs typically use comparable to slightly less space than CFs for the same epison.
other=
---
id=281
title=Efficient Algorithms for Adaptive Influence Maximization
author=Kai Han
journal=VLDB
year=2018
tags=social network analysis, Influence Maximization(IM), Adaptive IM, AdaptGreedy, EPIC
star=****
problem=Given a social network G, the influence maximization (IM) problem seeks a set S of k seed nodes in G to maximize the expected number of nodes activated via an influence cascade starting from S.
interest=the adaptive IM problem, where we select the k seed nodes in batches of equal size b, such that the choice of the i-th batch can be made after the influence results of the first i-1 batches are observed.
hardness=Although a lot of algorithms have been proposed for IM, most of them only work under the non-adaptive setting, i.e., when all k seed nodes are selected before we observe how they influence other users.
idea=Our approach is based on a novel AdaptGreedy framework instantiated by non-adaptive IM algorithms, and its performance can be substantially improved if the non-adaptive IM algorithm has a small expected approximation error.  However, no current non-adaptive IM algorithms provide such a desired property. Therefore, we further propose a non-adaptive IM algorithm called EPIC, which not only has the same worst-case performance bounds with that of the state-of-the-art non-adaptive IM algorithms, but also has a reduced expected approximation error.
future=
comment=We also provide a theoretical analysis to quantify the performance gain brought by instantiating AdaptGreedy using EPIC, compared with a naive approach using the existing IM algorithms.  Finally, we use real social networks to evaluate the performance of our approach through extensive experiments, and the experimental experiments strongly corroborate the superiorities of our approach.
other=
---
id=282
title=Errata for "Analysis of two existing and one new dynamic programming algorithm for the generation of optimal bushy join trees without cross products"
author=Andreas Meister, Guido Moerkotte
journal=VLDB
year=2018
tags=errata
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=the original paper is in VLDB 2006, [id:284]
---
id=283
title=Analysis of two existing and one new dynamic programming algorithm for the generation of optimal bushy join trees without cross products
author=Guido Moerkotte, Thomas Neumann
journal=VLDB
year=2006
tags=analysis, dynamic programming(DP), optimal bushy join trees, cross products, algorithm
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=an errata is in [id:283]
---
id=284
title=Scalable Similarity Joins of Tokenized Strings
author=Ahmed H Metwally (LinkedIn), Chun-Heng Huang (Google)
journal=ICDE
year=2019
tags=Scalable Similarity join, Tokenized strings
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=285
title=Presto: SQL on Everything
author=Raghav Sethi (Facebook, Inc.)
journal=ICDE
year=2019
tags=Presto, SQL on Everything
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=286
title=Improving RDF Query Performance using In-Memory Virtual Columns in Oracle Database (short)
author=Eugene I Chong (Oracle)
journal=ICDE
year=2019
tags=RDF query optimization, In-Memory virtual columns, Oracle Database
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=287
title=Answering Why-Questions for Subgraph Queries in Multi-Attributed Graphs
author=Qi Song (Washington State University)
journal=ICDE
year=2019
tags=Subgraph query, Subgraph matching, Multi-Attributed graphs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=288
title=Enumerating k-Vertex Connected Components in Large Graphs
author=Dong Wen (UTS), Qin Lu(UTS)
journal=ICDE
year=2019
tags=large graphs, k-Vertex Connected Components
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=289
title=Index-based Optimal Algorithm for Computing K-Cores in Large Uncertain Graphs
author=Bohua Yang(UTS)
journal=ICDE
year=2019
tags=index-based optimal Algorithm, K-cores, large Uncertain graphs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=290
title=Computing A Near-Maximum Independent Set In Dynamic Graphs
author=Weiguo Zheng (The Chinese University of Hong Kong)
journal=ICDE
year=2019
tags=Near-Maximum Independent Set, Dynamic Graphs
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=291
title=Contextual Community Search over Large Social Networks
author=Lu Chen (Swinburne University of Technology)
journal=ICDE
year=2019
tags=Contextual Community search, large social Network analysis 
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=292
title=Time Constrained Continuous Subgraph Search over Streaming Graphs
author=Youhuan Li, Lei Zou, M. Tamer Ozsu
journal=ICDE
year=2019
tags=dynamic graphs, Time Constrained Continuous Subgraph search, graph stream,Streaming Graphs, Subgraph, Timing Order constraints, US communications company Verizon, concurrent computing framework, match-store tree, Trie-like data structure, fine-granularity locking technique, time-based sliding window model, consistency guarantee, streaming consistency, degree of concurrency(DOC), social network
star=****
problem=exact subgraph (isomorphism) search over streaming graph data that obeys timing order constraints over the occurrence of edges in the stream
interest=The growing popularity of dynamic applications such as social networks provides a promising way to detect valuable information in real time. These applications create highspeed data that can be easily modeled as streaming graph.  Efficient analysis over these data is of great significance.
hardness=
idea=maintain partial matchings in previous snapshots; a solution to efficiently answer subgraph search, introduce optimizations to greatly reduce the space cost, and design concurrency management to improve system throughput.
future=
comment=strict partial order of time stamps is supported, let alone the full order
other=
---
id=293
title=Utilizing Dynamic Properties of Sharing Bits and Registers to Estimate User Cardinalities over Time
author=Pinghui Wang
journal=ICDE
year=2019
tags=dynamic Properties, sharing bits and registers, user Cardinalities
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=294
title=Tracking Influential Nodes in Time-Decaying Dynamic Interaction Networks
author=Junzhou Zhao (King Abdullah University of Science and Technology)
journal=ICDE
year=2019
tags=social Network analysis, Influential nodes, Time-Decaying dynamic Interaction Networks
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=295
title=Fast and Accurate Graph Stream Summarization
author=Xiangyang Gou, Lei Zou, Chenxingyu Zhao, Tong Yang
journal=ICDE
year=2019
tags=graph stream, Summarization, fast and accurate data structures, sketch
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=296
title=Mining Periodic Cliques in Temporal Networks
author=Hongchao Qin (Northeastern University)
journal=ICDE
year=2019
tags=graph mining, Periodic cliques, Temporal networks
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=297
title=MPMatch: A Multi-core Parallel Subgraph Matching Algorithm
author=Xin Jin, Longbin Lai
journal=ICDE
year=2019
tags=MPMatch, multi-core, parallel Subgraph matching
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=298
title=G*-Tree: An Efficient Spatial Index on Road Networks
author=Zijian Li, Lei Chen
journal=ICDE
year=2019
tags=G*-tree, tree index, data structure, Spatial Index, Road Networks
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=299
title=Performance and scalability of indexed subgraph query processing methods
author=Foteini Katsarou
journal=VLDB
year=2015
tags=subgraph query processing, survey, experimental paper, graph database, Performance and scalability
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=300
title=A selectivity based approach to continuous pattern detection in streaming graph
author=sutanay Choudhury
journal=EDBT
year=2015
tags=
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=301
title=Incremental graph pattern matching  (IncisoMat)
author=Wenfei Fan
journal=SIGMOD
year=2011
tags=Incremental graph pattern matching, graph stream, IncisoMat, graph simulation, relaxed pattern matching
star=***
problem=
interest=
hardness=
idea=identify the subgraph affected by each update operation, executes subgraph matching on it with updates and computes the set difference between them; the affected subgraph consists of nodes within the diameter of q from two vertices of the update; the diameter of q is defined as the length of the longest of all pairs' shortest paths in q by regarding q as an undirected graph
future=
comment=
other=a later version is in TODS 2013 which solves relaxed pattern matching(graph simulation)
---
id=302
title=Continuous subgraph pattern search over certain and uncertain graph streams
author=Lei Chen
journal=TKDE
year=2010
tags=inexact matching, Continuous subgraph pattern search, certain and uncertain graph stream
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=303
title=Continuous pattern detection over billion-edge graph using distributed framework
author=Jun Gao, Chang Zhou, Jiashuai Zhou, Jeffrey Xu Yu
journal=ICDE
year=2014
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=304
title=Toward continuous pattern detection over evolving large graph with snapshot isolation
author=Jun Gao, Chang Zhou, Jeffrey Xu Yu
journal=VLDBJ
year=2016
tags=continuous pattern detection, evolving large graph, graph stream, snapshot isolation, Pregel-like graph engine, query Decomposition, message transformation, distributed computing
star=****
problem=
interest=
hardness=
idea=how to decompose a query so that it can reduce the message transformation in a distributed environment
future=
comment=
other=the journal version of [id:303]
---
id=305
title=A Selectivity based approach to Continuous Pattern Detection in Streaming Graphs
author=sutanay Choudhury
journal=EDBT
year=2015
tags=SJ-Tree(subgraph join tree), graph stream, continuous pattern detection, Selectivity based approach
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=306
title=StreamWorks: a system for dynamic graph search
author=sutanay Choudhury
journal=SIGMOD
year=2013
tags=StreamWorks, dynamic graph search, graph stream, graph system
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=307
title=Skew strikes back: New developments in the theory of join algorithms
author=Hung Q. Ngo
journal=Sigmod Record (a journal, not the sigmod conference)
year=2013
tags=data skew, join algorithms, join optimizations, Generic Join
star=****
problem=
interest=
hardness=
idea=worst-case optimal join algorithm called Generic Join
future=
comment=
other=same as [id:68]
---
id=308
title=Graphflow: An Active Graph Database
author=Chathura Kankanamge
journal=SIGMOD
year=2017
tags=Graphflow, Generic Join, graph database
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=use Generic Join strategy in [id:307]
---
id=309
title=The anatomy of the facebook social graph
author=
journal=
year=2011
tags=facebook social graph, small world model
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=310
title=RDF-3X: a RISC-style engine for RDF (RDF/3x)
author=Thomas Neumann
journal=VLDB
year=2008
tags=RDF-3X, RDF/3X, RISC-style engine, RDF system
star=****
problem=
interest=
hardness=
idea=executes graph homomorphism by using merge-based join; model RDF triples as big three-attribute tabular structures and build six clustered clustered B+-trees as indexes for each permutation of subject, predicate and object
future=
comment=
other=
---
id=311
title=Incremental Frequent Subgraph Mining on Large Evolving Graphs (IncGM+)
author=Ehab Abdelhamid
journal=TKDE
year=2017
tags=Incremental Frequent Subgraph mining, data mining, large Evolving graphs, dynamic graphs, graph stream, IncGM+
star=****
problem=
interest=
hardness=
idea=an incremental frequent subgraph mining algorithm for a dynamic graph. IncGM+ uses a concept called fringe which is a set of patterns on the border between frequent and infrequent ones.  When an edge is inserted or deleted, IncGM+ finds positive/negative matches for patterns in fringe to find patterns that are changed from frequent to infrequent or vice versa.
future=It would be interesting future work to apply techniques of TurboFlux to this problem to speed up incremental frequent subgraph mining.
comment=IncGM+ uses a simple method of continuous subgraph matching that finds positive matches by applying subgraph isomorphism starting from the inserted edge, since the continuous subgraph isomorphism method itself is not the focus of the paper.
other=there is a poster on ICDE 2018
---
id=312
title=A critique of ANSI SQL isolation levels
author=Hal Berenson
journal=Sigmod 
year=1995
tags=ANSI SQL, snapshot isolation
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=313
title=Efficient multiview maintenance under insertion in huge social networks
author=Andrea Pugliese
journal=ACM Transactions on the Web (TWEB)
year=2014
tags=
star=
problem=
interest=
hardness=
idea=regards a query as a view and presents a view maintenance algorithm over a dynamic graph when a set of queries is registered; how to merge several views into a merged view in a distributed environment using a variant of the maximal common subgraph
future=
comment=
other=
---
id=314
title=Hybrid Garbage Collection for Multi-Version Concurrency Control in SAP HANA
author=Juchang Lee, Wook-Shin Han(*)
journal=SIGMOD
year=2016
tags=multi-version Concurrency control(MVCC), distributed computing, hybrid garbage collection, SAP HANA
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=315
title=event pattern matching over graph streams
author=Chunyao Song
journal=PVLDB
year=2014
tags=event pattern matching, graph stream
star=****
problem=
interest=
hardness=
idea=incrementally builds connected components for a query graph according to graph simulation semantics
future=
comment=
other=
---
id=316
title=Real-time Constrained Cycle Detection in Large Dynamic Graphs
author=Xiafei Qiu, Xuemin Lin
journal=PVLDB
year=2018
tags=Real-time Constrained cycle detection, large dynamic graphs, continuous pattern matching, time order
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=317
title=Answering graph pattern queries using views
author=Wenfei Fan, Xin Wang, Yinghui Wu
journal=ICDE
year=2014
tags=graph pattern query, view
star=****
problem=This paper investigates this issue for graph pattern queries based on (bounded) simulation, which have been increasingly used in, e.g., social network analysis.
interest=Answering queries using views has proven an effective technique for querying relational and semistructured data.
hardness=We show that these problems range from quadratic-time to NP-complete, and provide efficient algorithms for containment checking (approximation when the problem is intractable).
idea=propose a notion of pattern containment to characterize graph pattern matching using graph pattern views. We show that a graph pattern query can be answered using a set of views if and only if the query is contained in the views. Based on this characterization we develop efficient algorithms to answer graph pattern queries. In addition, we identify three problems associated with graph pattern containment.
future=
comment=
other=
---
id=318
title=Making pattern queries bounded in big graphs
author=Yang Cao, Wenfei Fan, Jinpeng Huai, Ruizhe Huang
journal=ICDE
year=2015
tags=subgraph matching, graph isomorphism, graph simulation, big graph, bounded pattern query, real-life constraints
star=****
problem=It is cost-prohibitive to find matches Q(G) of a pattern query Q in a big graph G.
interest=We approach this by fetching a small subgraph GQ of G such that Q(GQ) = Q(G). We show that many practical patterns are effectively bounded under access constraints A commonly found in real life, such that GQ can be identified in time determined by Q and A only, independent of the size |G| of G.
hardness=This holds no matter whether pattern queries are localized (e.g., via subgraph isomorphism) or non-localized (graph simulation).
idea=We provide algorithms to decide whether a pattern Q is effectively bounded, and if so, to generate a query plan that computes Q(G) by accessing GQ, in time independent of |G|. When Q is not effectively bounded, we give an algorithm to extend access constraints and make Q bounded in G.
future=
comment=Using real-life data, we experimentally verify the effectiveness of the approach, e.g., about 60% of queries are effectively bounded for subgraph isomorphism
other=
---
id=319
title=Smart RDF Data storage in Graph Databases
author=Roberto De Virgilio
journal=CCGrid (IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing)
year=2017
tags=Graph Database Management Systems (GDBMs), embedding technique, smart rdf data storage, graph database, rdf data model, property graph model
star=***
problem=
interest=the conversion of the persistent layer of an application from a RDF to a graph data store can be convenient but it is usually an hard task for database administrators.
hardness=
idea=convert a RDF data store to a graph database by exploiting the ontology and the constraints of the source; embed triple to vertex attribute, rdf to property graph
future=
comment=
other=embedding technique is similar as [id:206]
---
id=320
title=Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud
author= Yucheng Low, Danny Bickson, Joseph Gonzalez, Carlos Guestrin, Aapo Kyrola
journal=VLDB
year=2012
tags=Distributed computing, GraphLab, Machine Learning, Data Mining, MLDM, cloud computing, parallel graph computing, ASynchronous Parallel Model, stream computing, GAS(Gather-Apply-Scatter), 1-hop neighbors, 2-hop neighbors
star=****
problem=
interest=
hardness=在海量数据盛行的今天，大规模并行计算已经随处可见，尤其是MapReduce框架的出现，促进了并行计算在互联网海量数据处理中的广泛应用。而针对海量数据的机器学习对并行计算的性能、开发复杂度等提出了新的挑战。 机器学习的算法具有下面两个特点：数据依赖性强，运算过程各个机器之间要进行频繁的数据交换；流处理复杂，整个处理过程需要多次迭代，数据的处理条件分支多。 而MapReduce是典型的SIMD模型，Map阶段集群的各台机器各自完成负载较重的计算过程，数据并行度高，适合完成类似矩阵运算、数据统计等数据独立性强的计算，而对于机器学习类算法并行性能不高。 另一个并行实现方案就是采用纯MPI（Native MPI）的方式。纯MPI实现通过精细的设计将并行任务按照MPI协议分配到集群机器上，并根据具体应用，在计算过程中进行机器间的数据通信和同步。纯MPI的优点是，可以针对具体的应用，进行深度优化，从而达到很高的并行性能。但纯MPI存在的问题是，针对不同的机器学习算法，需要重写其数据分配、通信等实现细节，代码重用率低，机器拓展性能差，对编程开发人员的要求高，而且优化和调试成本高。因而，纯MPI不适合敏捷的互联网应用。 为解决机器学习的流处理，Google提出了Pregel框架，Pregel是严格的BSP模型，采用“计算-通信-同步”的模式完成机器学习的数据同步和算法迭代。Goolge曾称其80%的程序使用MapReduce完成，20%的程序使用Pregel实现。因而，Pregel是很成熟的机器学习流处理框架，但Google一直没有将Pregel的具体实现开源，外界对Pregel的模仿实现在性能和稳定性方面都未能达到工业级应用的标准。 2010年，CMU的Select实验室提出了GraphLab框架，GraphLab是面向机器学习的流处理并行框架
idea=需要完成对V0邻接顶点的求和计算，串行实现中，V0对其所有的邻接点进行遍历，累加求和。而GraphLab中，将顶点V0进行切分，将V0的边关系以及对应的邻接点部署在两台处理器上，各台机器上并行进行部分求和运算，然后通过master顶点和mirror顶点的通信完成最终的计算。
future=
comment=GraphLab can not handle updates, but it supports ASynchronous running. For parallel computing, to lock a vertex, it will lock all its 1-hop neighbors by write lock, and lock all its 2-jop neighbors by read lock.
other=https://blog.csdn.net/qq_21125183/article/details/80678187
---
id=321
title=pLock: A Fast Lock for Architectures with Explicit Inter-core Message Passing
author=Xiongchao Tang (Tsinghua University)
journal=ASPLOS (CCF A conference of architecture area)
year=2019
tags=pLock, architecture, Explicit Inter-core Message Passing
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=322
title=An Efficient In-Memory Checkpoint Method and its Practice on Fault-Tolerant HPL
author=Xiongchao Tang, Keqin Li
journal=TPDS
year=2018
tags=In-Memory Checkpoint, Fault-Tolerant HPL, fault tolerance, memory consumption, SKT-HPL
star=****
problem=Fault tolerance is increasingly important in high-performance computing due to the substantial growth of system scale and decreasing system reliability
interest=In-memory/diskless checkpoint has gained extensive attention as a solution to avoid the IO bottleneck of traditional disk-based checkpoint methods.
hardness=applications using previous in-memory checkpoint suffer from little available memory space. To provide high reliability, previous in-memory checkpoint methods either need to keep two copies of checkpoints to tolerate failures while updating old checkpoints or trade performance for space by flushing in-memory checkpoints into disk.
idea=a novel in-memory checkpoint method, called self-checkpoint, which can not only achieve the same reliability of previous in-memory checkpoint methods, but also increase the available memory space for applications by almost 50 percent. To validate our method, we apply self-checkpoint method to an important problem: High-Performance Linpack (HPL) with fault tolerance.  We implement a scalable and fault tolerant HPL based on this new method, called SKT-HPL, and validate it on two large-scale systems.
future=
comment=
other=the journal version of conference paper [id:324], add some improvements
---
id=323
title=vSensor: leveraging fixed-workload snippets of programs for performance variance detection
author=Xiongchao Tang, Bingsheng He
journal=PPoPP
year=2018
tags=vSensor, fixed-workload snippets, performance variance detection
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=324
title=Self-Checkpoint: An In-Memory Checkpoint Method Using Less Space and Its Practice on Fault-Tolerant HPL
author=Xiongchao Tang
journal=PPoPP
year=2017
tags=Self-Checkpoint, In-Memory Checkpoint, Fault-Tolerant HPL
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=HPL (High-Performance Linpack Benchmark in [id:325])
---
id=325
title=High Performance Linpack Benchmark: A Fault Tolerant Implementation without Checkpointing
author=Teresa Davies
journal=ICS  (CCF B conference of architecture area)
year=2011
tags=Fault-Tolerant HPL Benchmark, High Performance Linpack
star=***
problem=The probability that a failure will occur before the end of the computation increases as the number of processors used in a high performance computing application increases.
interest=For long running applications using a large number of processors, it is essential that fault tolerance be used to prevent a total loss of all finished computations after a failure.
hardness=While checkpointing has been very useful to tolerate failures for a long time, it often introduces a considerable overhead especially when applications modify a large amount of memory between checkpoints and the number of processors is large.
idea=an algorithm-based recovery scheme for the High Performance Linpack benchmark (which modifies a large amount of memory in each iteration) to tolerate fail-stop failures without checkpointing. It was proved by Huang and Abraham that a checksum added to a matrix will be maintained after the matrix is factored. We demonstrate that, for the right-looking LU factorization algorithm, the checksum is maintained at each step of the computation.  Based on this checksum relationship maintained at each step in the middle of the computation, we demonstrate that fail-stop process failures in High Performance Linpack can be tolerated without checkpointing. Because no periodical checkpoint is necessary during computation and no roll-back is necessary during recovery, the proposed recovery scheme is highly scalable and has a good potential to scale to extreme scale computing and beyond.
future=
comment=
other=
---
id=326
title=A novel spectral coding in a large graph database
author=Lei Zou, Lei Chen, Jeffrey Xu Yu, Yansheng Liu
journal=EDBT
year=2008
tags=gCode, graph indexing, graph database, spectral coding
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=327
title=Sw-store: a vertically partitioned DBMS for semantic web data management
author=
journal=VLDB
year=2009
tags=SW-store, vertically partitioned DBMS, semantic web data management
star=****
problem=
interest=
hardness=
idea=uses a column-oriented store as its underlying store, triples are stored as sorted by the subject column
future=
comment=
other=
---
id=328
title=Jena: implementing the semantic web recommendations
author=
journal=WWW
year=2004
tags=Jena, semantic web recommendation, RDF reasoning, inference, rdf system
star=****
problem=
interest=
hardness=
idea=exploits multiple-property tables, and reduces the number of joins by clustering several properties accessed together in a single property table.
future=
comment=
other=
---
id=329
title=Hexastore: sextuple indexing for semantic web data management
author=
journal=VLDB
year=2008
tags=Hexastore, sextuple indexing, semantic web data management
star=****
problem=
interest=
hardness=
idea=model RDF triples as big three-attribute tabular structures and build six clustered clustered B+-trees as indexes for each permutation of subject, predicate and object
future=
comment=
other=
---
id=330
title=Scalable SPARQL querying of large RDF graphs
author=
journal=VLDB
year=2011
tags=H-RDF-3X, sparql querying, large RDF graph
star=****
problem=
interest=
hardness=
idea=a distributed RDF processing engine where RDF-3X is installed in each cluster node.
future=
comment=
other=
---
id=331
title=GRIN: A graph based RDF index
author=
journal=AAAI
year=2007
tags=GRIN, graph based RDF index
star=****
problem=
interest=
hardness=
idea= uses graph partitioning and distance information to construct the index for graph queries. Its index is a balanced binary tree with each of its nodes containing a set of triples
future=
comment=
other=
---
id=332
title=Grass: An efficient method for RDF subgraph matching
author=
journal=web information systems engineering (WISE, CCF C conference of Information Retrieval)
year=2015
tags=Grass, RDF subgraph matching
star=***
problem=
interest=
hardness=
idea=performs graph pattern matching by the concept of fingerprint for star subgraph, which can describe a subgraph and be used as a filter to help to prune search space.
future=
comment=
other=
---
id=333
title=3store: Efficient bulk RDF storage
author=
journal=PSSS
year=2003
tags=3store, bulk RDF storage
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=334
title=OWLIM: A family of scalable semantic repositories
author=
journal=Semantic Web
year=2011
tags=OWLIM, scalable semantic repositories
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=335
title=Sesame: A generic architecture for storing and querying RDF and RDF schema
author=
journal=ISWC (CCF B conference of Information Retrieval)
year=2002
tags=Sesame, rdf system, rdf schema
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=336
title=RDF Support in the Virtuoso DBMS
author=Orri Erling
journal=CSSW
year=2007
tags=RDF system, virtuoso DBMS
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=337
title=Virtuoso: RDF Support in a Native RDBMS
author=Orri Erling
journal=semantic web Information management
year=2009
tags=RDF system, virtuoso DBMS
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=338
title=Virtuoso, a Hybrid RDBMS/Graph Column Store
author=
journal=IEEE Data Eng. Bull.
year=2012
tags=Virtuoso dbms, rdf system, hybrid RDBMS/Graph column store
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=339
title=HetExchange: Encapsulating heterogeneous CPU-GPU parallelism in JIT compiled engines
author=Periklis Chrysogelos
journal=VLDB
year=2019
tags=HetExchange, heterogeneous CPU-GPU parallelism, (Just-in-Time)JIT compilation
star=****
problem=query parallelization techniques used by analytical database engines are designed for homogeneous multicore servers, where query plans are parallelized across CPUs to process data stored in cache coherent shared memory.
interest=Modern server hardware is increasingly heterogeneous as hardware accelerators, such as GPUs, are used together with multicore CPUs to meet the computational demands of modern data analytics workloads.
hardness=these techniques are unable to fully exploit available heterogeneous hardware, where one needs to exploit task-parallelism of CPUs and data-parallelism of GPUs for processing data stored in a deep, non-cache-coherent memory hierarchy with widely varying access latencies and bandwidth.
idea=introduce HetExchange-a parallel query execution framework that encapsulates the heterogeneous parallelism of modern multi-CPU-multi-GPU servers and enables the parallelization of (pre-)existing sequential relational operators. In contrast to the interpreted nature of traditional Exchange, HetExchange is designed to be used in conjunction with JIT compiled engines in order to allow a tight integration with the proposed operators and generation of efficient code for heterogeneous hardware
future=
comment=We validate the applicability and efficiency of our design by building a prototype that can operate over both CPUs and GPUs, and enables its operators to be parallelism- and data-location-agnostic. In doing so, we show that efficiently exploiting CPU-GPU parallelism can provide 2.8x and 6.4x improvement in performance compared to state-of-the-art CPU-based and GPU-based DBMS.
other=
---
id=340
title=HELIX: Holistic Optimization for Accelerating Iterative Machine Learning
author=Doris Xin
journal=VLDB
year=2019
tags=HELIX, Holistic Optimization, Iterative Machine Learning Acceleration, machine Learning system, Scala DSL, DeepDive, KeystoneML
star=****
problem=accelerate machine learning 
interest=Machine learning workflow development is a process of trial-and-error: developers iterate on workflows by testing out small modifications until the desired accuracy is achieved
hardness=existing machine learning systems focus narrowly on model training—a small fraction of the overall development time—and neglect to address iterative development.
idea=propose HELIX, a machine learning system that optimizes the execution across iterations—intelligently caching and reusing, or recomputing intermediates as appropriate.  HELIX captures a wide variety of application needs within its Scala DSL, with succinct syntax defining unified processes for data preprocessing, model specification, and learning. We demonstrate that the reuse problem can be cast as a MAX-FLOW problem, while the caching problem is NP-HARD. We develop effective lightweight heuristics for the latter.
future=
comment=
other=
---
id=341
title=Analyzing Efficient Stream Processing on Modern Hardware
author=Steffen Zeuch
journal=VLDB
year=2019
tags=stream processing, modern Hardware, Stream Processing Engines (SPEs), multi-core processors, Java Virtual Machine(JVM), high-speed networks
star=****
problem=
interest=Modern Stream Processing Engines (SPEs) process large data volumes under tight latency constraints. Many SPEs execute processing pipelines using message passing on sharednothing architectures and apply a partition-based scale-out strategy to handle high-velocity input streams.
hardness=Furthermore, many state-of-the-art SPEs rely on a Java Virtual Machine to achieve platform independence and speed up system development by abstracting from the underlying hardware.
idea=we show that taking the underlying hardware into account is essential to exploit modern hardware eciently. To this end, we conduct an extensive experimental analysis of current SPEs and SPE design alternatives optimized for modern hardware. Our analysis highlights potential bottlenecks and reveals that state-of-the-art SPEs are not capable of fully exploiting current and emerging hardware trends, such as multi-core processors and high-speed networks. Based on our analysis, we describe a set of design changes to the common architecture of SPEs to scale-up on modern hardware.
future=
comment=We show that the single-node throughput can be increased by up to two orders of magnitude compared to state-of-the-art SPEs by applying specialized code generation, fusing operators, batch-style parallelization strategies, and optimized windowing. This speedup allows for deploying typical streaming applications on a single or a few nodes instead of large clusters.
other=While JVMs provide a high level of abstraction from the underlying hardware, they cannot easily provide ecient data access due to processing overheads induced by data (de-)serialization, objects scattering in main memory, virtual functions, and garbage collection.  As a result, the overall performance of scale-out SPEs building on top of a JVM are severely limited in throughput and latency.
---
id=342
title=a survey of graph processing on graphics processing units (experimental paper)
author=Ha-Nguyen Tran
journal=The journal of SuperComputing
year=2018
tags=survey, experimental paper, gpu, graph processing
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=343
title=Accelerating graph isomorphism queries in a graph database using the GPU
author=
journal=
year=2016
tags=graph isomorphism, graph database, GPU
star=*
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=344
title=An Efficient Implementation of a Subgraph Isomorphism Algorithm for GPUs
author=Vincenzo Bonnici
journal=BIBM  (CCF B conference of Interdisciplinary area)
year=2018
tags=Subgraph Isomorphism, GPU, graph search, parallel computing, CUDA, GRASS
star=***
problem=
interest=The subgraph isomorphism problem is a computational task that applies to a wide range of today’s applications, ranging from the understanding of biological networks to the analysis of social networks.
hardness=Even though different implementations for CPUs have been proposed to improve the efficiency of such a graph search algorithm, they have shown to be bounded by the intrinsic sequential nature of the algorithm.  More recently, graphics processing units (GPUs) have become widespread platforms that provide massive parallelism at low cost. Nevertheless, parallelizing any efficient and optimized sequential algorithm for subgraph isomorphism on many-core architectures is a very challenging task.
idea=This article presents GRASS, a parallel implementation of the subgraph isomorphism algorithm for GPUs. Different strategies are implemented in GRASS to deal with the space complexity of the graph searching algorithm, the potential workload imbalance, and the thread divergence involved by the non-homogeneity of actual graphs. ; use pruning techniques in [id:416]
future=
comment=only compare with sequential CPU algorithms(TurboISO, RI) because other gpu si algorithms do not share code, implemented STwig on GPU [id:13] is worse than sequential TurboISO and RI;  the filtering strategy of GRASS is naive and sequential(dfs), the verification is done by flooding phase(overall BFS expansion) and hypersearch phase(BFS of each subtree is done by a block)
other=code provided in http://profs.scienze.univr.it/bombieri/GRASS/ but no reply of requests; the idea is similar to hulin's undergraduate thesis
---
id=345
title=Parallel Searching on Biological Networks
author=
journal=PDP (Euromicro International Conference on Parallel, Distributed and Network-Based Processing)
year=2019
tags=manycore, multi-core, GPU, Subgraph Isomorphism, Biological Networks
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=346
title=Relational consistency algorithms and their application in finding subgraph and graph isomorphisms
author=
journal=Inf. Sci.
year=1979
tags=relational consistency, subgraph Isomorphism, graph Isomorphism, pruning technique
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=recursively pruning technique, which ignores low-connected vertices to reduce the number of intermediate results
---
id=347
title=A Batched GPU Algorithm for Set Intersection
author=Di Wu
journal=ISPAN
year=2009
tags=batched queries, set Intersection, gpu
star=***
problem=
interest=
hardness=traditional algorithms deal with two large sets
idea=combine many small queries into a batch
future=
comment=
other=
---
id=348
title=AliGraph: A Comprehensive Graph Neural Network Platform
author=Rong Zhu
journal=VLDB  (industry track)
year=2019
tags=AliGraph, GCN, Graph Neural Network Platform
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=349
title=PALM: Parallel Architecture-Friendly LatchFree Modifications to B+ Trees on ManyCore Processors
author=Jason Sewall
journal=VLDB
year=2011
tags=PALM, parallel Architecture-Friendly Latch-Free Modifications, B+-tree, many-core Processors
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=350
title=persistent B+-tree in NON-volatile main memory
author=Shimin Chen, Qin Jin
journal=VLDB
year=2015
tags=B+-tree, data structure, non-volatile memory(NVM)
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=351
title=Sampling Time-Based Sliding Windows in Bounded Space  (BPS algorithm)
author=Rainer Gemulla
journal=sigmod
year=2008
tags=BPS algorithm, Sampling time-based sliding window, bounded space, data stream, test item, double expire
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=not include edge duplicates
---
id=352
title=Approximately Counting Triangles in Large Graph Streams Including Edge Duplicates with a Fixed Memory Usage
author=Pinghui Wang
journal=VLDB
year=2017
tags=Approximately counting Triangles, large graph streams, edge Duplicates, fixed memory usage, partitionCT, hash function
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=can also be extended to sliding window, if combined with [id:351]; the window of data stream can be defined by time or space, because the data stream speed may vary; Estimating the Number of Distinct Edges by HyperLogLog [id:353]
---
id=353
title=Hyperloglog: The analysis of a near-optimal cardinality estimation algorithm
author=
journal=Discrete Mathematics and Theoretical Computer Science
year=2007
tags=Hyperloglog, near-optimal cardinality estimation, estimating the Number of distinct edges
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=354
title=THE REDUCTION OF A GRAPH TO CANONICAL FORM AND THE ALGEBRA WHICH APPEARS THEREIN
author=B.YU. Weisfeiler, A.A. Lehmann
journal=NTI Series
year=1968
tags=canonical form, reduction,  algebra graph theory, finite multigraph
star=****
problem=an algorithm for the reduction of a given nite multigraph G to canonical form
interest=some conjectures on the relation between properties of the algebra A(G) and the automorphism group Aut(G) of a graph G
hardness=
idea=
future=
comment=
other=a high-precision approximately graph isomorphism algorithm
---
id=355
title=The Weisfeiler-Lehman Method and Graph Isomorphism Testing
author=Brendan L. Douglas
journal=arXiv
year=2011
tags=Weisfeiler-Lehman method, Graph Isomorphism Testing, graph theory
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=356
title=SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS
author=Thomas N. Kipf, Max Welling
journal=ICLR
year=2017
tags=SEMI-SUPERVISED node CLASSIFICATION, graph CONVOLUTIONAL networks, GNN, GCN, machine learning, localized first-order approximation, spectral graph convolutions, FAST APPROXIMATE CONVOLUTIONS ON GRAPHS
star=****
problem=We consider the problem of classifying nodes (such as documents) in a graph (such as a citation network), where labels are only available for a small subset of nodes. This problem can be framed as graph-based semi-supervised learning, where label information is smoothed over the graph via some form of explicit graph-based regularization(e.g. by using a graph Laplacian regularization term in the loss function)
interest=
hardness=
idea=encode the graph structure directly using a neural network model f(X,A) and train on a supervised target L0 for all nodes with labels, thereby avoiding explicit graph-based regularization in the loss function. Conditioning f() on the adjacency matrix of the graph will allow the model to distribute gradient information from the supervised loss L0 and will enable it to learn representations of nodes both with and without labels.
future=
comment=Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.
other=
---
id=357
title=Fast Suboptimal Algorithms for the Computation of Graph Edit Distance (Astar-BeamSearch)
author=Michel Neuhaus
journal=SSPR/SPR
year=2006
tags=fast Suboptimal Algorithm, Graph Edit Distance, Astar, beam search, Astar-BeamSearch, graph similarity, approximate graph matching
star=***
problem=efficient computation of graph edit Distance
interest=Graph edit distance is one of the most flexible mechanisms for error-tolerant graph matching. Its key advantage is that edit distance is applicable to unconstrained attributed graphs and can be tailored to a wide variety of applications by means of specific edit cost functions.
hardness=Its computational complexity, however, is exponential in the number of vertices, which means that edit distance is feasible for small graphs only.
idea=propose two simple, but effective modifications of a standard edit distance algorithm that allow us to suboptimally compute edit distance in a faster way;     We exploit the fact that exact edit distance algorithms typically explore large areas of the search space that are not relevant for certain classification tasks. We propose simple variants of a standard edit distance algorithm that make the computation substantially faster, but keep the resulting suboptimal distances sufficiently accurate.
future=
comment=In experiments on real data, we demonstrate the resulting speedup and show that classification accuracy is mostly not affected. The suboptimality of our methods mainly results in larger inter-class distances, while intra-class distances remain low, which makes the proposed methods very well applicable to distance-based graph classification.
other=
---
id=358
title=SimGNN: A Neural Network Approach to Fast Graph Similarity Computation
author=Yunsheng Bai
journal=WSDM  (CCF B Conference of database area)
year=2019
tags=Graph edit distance(GED), maximum common subgraph(MCS), SimGNN, Neural network, fast graph Similarity Computation, network embedding, neural networks
star=***
problem=Inspired by the recent success of neural network approaches to several graph applications, such as node or graph classification, we propose a novel neural network based approach to address this classic yet challenging graph problem, aiming to alleviate the computational burden while preserving a good performance.
interest=Graph similarity search is among the most important graph-based applications, e.g. finding the chemical compounds that are most similar to a query compound. Graph similarity/distance computation, such as Graph Edit Distance (GED) and Maximum Common Subgraph (MCS), is the core operation of graph similarity search and many other applications, but very costly to compute in practice.
hardness=
idea=The proposed approach, called SimGNN, combines two strategies.  First, we design a learnable embedding function that maps every graph into an embedding vector, which provides a global summary of a graph. A novel attention mechanism is proposed to emphasize the important nodes with respect to a specific similarity metric.  Second, we design a pairwise node comparison method to supplement the graph-level embeddings with fine-grained node-level information.
future=
comment=Our model achieves better generalization on unseen graphs, and in the worst case runs in quadratic time with respect to the number of nodes in two graphs. Taking GED computation as an example, experimental results on three real graph datasets demonstrate the effectiveness and efficiency of our approach. Specifically, our model achieves smaller error rate and great time reduction compared against a series of baselines, including several approximation algorithms on GED computation, and many existing graph neural network based models. Our study suggests SimGNN provides a new direction for future research on graph similarity computation and graph similarity search
other=
---
id=359
title=A formal basis for the heuristic determination of minimum cost paths (A*)
author=Peter E. Hart
journal=IEEE Trans. Systems Science and Cybernetics
year=1968
tags=A*, heuristic determination of minimum cost paths, optimization problem
star=****
problem=
interest=
hardness=
idea=for a node of the search tree p, we use g(p) to denote the costs of the optimal path from the root node to the current node p found by A* so far and h(p) to denote the estimated costs from p to a leaf node.  The sum g(p) + h(p) gives the heuristic assessment of node p. If the estimated costs h(p) are always lower than, or equal to, the real costs, the algorithm is known to be admissible, that is, an optimal path from the root node to a leaf node is guaranteed to be found by this procedure
future=
comment=
other=
---
id=360
title=Correction to "A Formal Basis for the Heuristic Determination of Minimum Cost Paths" (A*)
author=Peter E. Hart
journal=SIGART Newsletter
year=1972
tags=A*
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=correction of [id:359]
---
id=361
title=A theoretical basis for the reduction of polynomials to canonical forms
author=B. Buchberger
journal=ACM SIGSAM Bulletin
year=1976
tags=theorectical basis, CANONICAL forms, reduction of polynomials
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=362
title=TESTING ISOMORPHISM OF COMBINATORIAL AND ALGEBRAIC STRUCTURES
author=PAOLO CODENOTTI
journal=A DISSERTATION SUBMITTED TO THE FACULTY OF THE DIVISION OF THE PHYSICAL SCIENCES IN CANDIDACY FOR THE DEGREE OF DOCTOR OF PHILOSOPHY   (phd paper)
year=2011
tags=phd paper, ISOMORPHISM test, COMBINATORIAL and ALGEBRAIC STRUCTURES
star=***
problem=introduction of graph theory and definition
interest=
hardness=
idea=
future=
comment=
other=
---
id=363
title=Beyond Shortest Paths: Route Recommendations for Ride-sharing
author=
journal=World Wide Web (WWW, CCF A conference of Interdisciplinary area)
year=2019
tags=shortest path, data mining, route recommendation, ride-sharing
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=364
title=CommunityGAN: Community Detection with Generative Adversarial Nets
author=Yuting Jia
journal=WWW
year=2019
tags=Community Detection, Graph Representation Learning, Generative Adversarial Nets(GAN), overlapped community, CommunityGAN
star=****
problem=Community detection refers to the task of discovering groups of vertices sharing similar properties or functions so as to understand the network data.
interest=With the recent development of deep learning, graph representation learning techniques are also utilized for community detection.
hardness=However, the communities can only be inferred by applying clustering algorithms based on learned vertex embeddings.  These general cluster algorithms like K-means and Gaussian Mixture Model cannot output much overlapped communities, which have been proved to be very common in many real-world networks.
idea=CommunityGAN, a novel community detection framework that jointly solves overlapping community detection and graph representation learning. First, unlike the embedding of conventional graph representation learning algorithms where the vector entry values have no specific meanings, the embedding of CommunityGAN indicates the membership strength of vertices to communities. Second, a specifically designed Generative Adversarial Net (GAN) is adopted to optimize such embedding. Through the minimax competition between the motif-level generator and discriminator, both of them can alternatively and iteratively boost their performance and finally output a better community structure.
future=
comment=
other=
---
id=365
title=No Place to Hide: Catching Fraudulent Entities in Tensors
author=Yikun Ban
journal=WWW
year=2019
tags=fradulent entity, Tensors
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=366
title=Personalized Bundle List Recommendation
author=Jinze Bai
journal=WWW
year=2019
tags=Personalized bundle list Recommendation
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=367
title=Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=368
title=RealGraph: A Graph Engine Leveraging the Power-Law Distribution of Real-World Graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=369
title=Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender System
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=370
title=Dressing as a Whole: Outfit Compatibility Learning Based on Node-wise Graph Neural Networks
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=371
title=RAQ: Relationship-Aware Graph Querying in Large Networks
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=372
title=Semi-Supervised Graph Classification: A Hierarchical Graph Perspective
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=373
title=Neural IR Meets Graph Embedding: A Ranking Model for Product Search
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=374
title=Learning Resolution Parameters for Graph Clustering
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=375
title=Learning Resolution Parameters for Graph Clustering
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=376
title=Graphy: A High Performance CPU-GPU Hybrid System for Node Embedding  (GraphVite)
author=Zhaocheng Zhu
journal=WWW
year=2019
tags=Graphy, GraphVite, high Performance computing, cpu-gpu hybrid system, node embedding, parallel algorithm, machine Learning, Unsupervised node embedding, parallel processing, scalability, graphics processing unit
star=****
problem=
interest=Learning continuous representations of nodes is attracting growing interest in both academia and industry recently, due to their simplicity and effectiveness in a variety of applications.
hardness=Most of existing node embedding algorithms and systems are capable of processing networks with hundreds of thousands or a few millions of nodes.  However, how to scale them to networks that have tens of millions or even hundreds of millions of nodes remains a challenging problem.
idea=GraphVite, a high-performance CPUGPU hybrid system for training node embeddings, by co-optimizing the algorithm and the system. On the CPU end, augmented edge samples are parallelly generated by random walks in an online fashion on the network, and serve as the training data. On the GPU end, a novel parallel negative sampling is proposed to leverage multiple GPUs to train node embeddings simultaneously, without much data transfer and synchronization. Moreover, an efficient collaboration strategy is proposed to further reduce the synchronization cost between CPUs and GPUs.
future=
comment=
other=
---
id=377
title=Distributed Algorithms for Fully Personalized PageRank on Large Graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=378
title=Heterogeneous Graph Attention Network 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=379
title=Jointly Learning Explainable Rules for Recommendation with Knowledge Graph 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=380
title=Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=381
title=ActiveLink: Deep Active Learning for Link Prediction in Knowledge Graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=382
title=Generative Graph Models based on Laplacian Spectra 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=383
title=Revisiting User Mobility and Social Relationships in LBSNs: A Hypergraph Embedding Approach
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=384
title=Choosing to grow a graph: modeling network formation as discrete choice 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=385
title=DDGK: Learning Graph Representations via Deep Divergence Graph Kernels 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=386
title=Learning Edge Properties in Graphs from Path Aggregations 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=387
title=Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preference 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=388
title=Pruning based Distance Sketches with Provable Guarantees on Random Graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=389
title=Learning Semantic Models of Data Sources using Probabilistic Graphical Models 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=390
title=Constrained Local Graph Clustering by Colored Random Walk 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=391
title=Decoupled smoothing on graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=392
title=Learning Graph Pooling and Hybrid Convolutional Operations for Text Representations
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=393
title=A Graph is Worth a Thousand Words: Telling Event Stories using Timeline Summarization Graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=394
title=Knowledge Graph Convolutional Networks for Recommender Systems 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=395
title=Sampled in Pairs and Driven by Text: A New Graph Embedding Framework 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=396
title=Triple Trustworthiness Measurement for Knowledge Graph 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=397
title=Fine-grained Type Inference in Knowledge Graphs via Probabilistic and Tensor Factorization Methods 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=398
title=Semi-Supervised Entity Alignment via Knowledge Graph Embedding with Awareness of Degree Difference 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=399
title=Inferring Search Queries from Web Documents via a Graph-Augmented Sequence to Attention Network 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=400
title=SWeG: Lossless and Lossy Summarization of Tera-Scale Graphs 
author=
journal=WWW
year=2019
tags=
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=401
title=Spectral Properties of Hypergraph Laplacian and Approximation Algorithms
author=T.-H. HUBERT CHAN
journal=J. ACM
year=2018
tags=spectrum theory, spectral property, Hypergraph Laplacian matrix, Approximation algorithm, discrete Mathematics, graph theory, graph algorithms, Cheeger's inequality, eigenvalues and eigenvectors of the adjacency matrix
star=****
problem=
interest=The celebrated Cheeger’s Inequality (Alon and Milman 1985; Alon 1986) establishes a bound on the edge expansion of a graph via its spectrum. This inequality is central to a rich spectral theory of graphs, based on studying the eigenvalues and eigenvectors of the adjacency matrix (and other related matrices) of graphs. It has remained open to define a suitable spectral model for hypergraphs whose spectra can be used to estimate various combinatorial properties of the hypergraph.
hardness=
idea=a new hypergraph Laplacian operator generalizing the Laplacian matrix of graphs. In particular, the operator is induced by a diffusion process on the hypergraph, such that within each hyperedge,measure flows fromvertices having maximum weightedmeasure to those having minimum. Since the operator is nonlinear, we have to exploit other properties of the diffusion process to recover the Cheeger’s Inequality that relates hyperedge expansionwith the “second eigenvalue” of the resulting Laplacian. However, we show that higher-order spectral properties cannot hold in general using the current framework.  Since higher-order spectral properties do not hold for the Laplacian operator, we instead use the concept of procedural minimizers to consider higher-order Cheeger-like inequalities.
future=
comment=
other=
---
id=402
title=hash collision analysis
author=
journal=
year=
tags=hash collision analysis, probability, one-to-one hash, upper bound of expectation
star=****
problem=
interest=
hardness=
idea=https://math.dartmouth.edu/archive/m19w03/public_html/Section6-5.pdf  ;    http://www.cs.fsu.edu/~lacher/courses/COP4531/notes/hashanalysis.pdf  
future=
comment=
other=the upper bound is the bound of expectation, in the worst case, all items are hashed into one bucket
---
id=403
title=nvGraph
author=Nvidia Corporation
journal=
year=
tags=nvGraph, Graph Library, GPU, SSSP, Page Rank, Single Source widest Path
star=***
problem=
interest=
hardness=
idea=included in CUDA Toolkit, https://developer.nvidia.com/nvgraph
future=
comment=
other=all graph algorithms can be implemented by Linear Algebra, but the performance is limited.
---
id=404
title=A Hub-Based Labeling Algorithm for Shortest Paths in Road Networks
author=Ittai Abraham
journal=SEA
year=2011
tags=OPSP, point-to-point shortest path, single-pair shortest path, continent-sized road Networks, query time, Compression scheme, space usage, sublinear time, hub-based labeling Algorithm
star=***
problem=Motivated by computing driving directions, the problem of finding point-topoint shortest paths in road networks has received significant attention in recent years.
interest=Preprocessing makes sublinear-time algorithms possible; see [407] for a survey of existing methods.
hardness=Even though Dijkstra’s algorithm [408] solves it in almost linear time [id:406], continent-sized road networks require something faster.
idea=
future=
comment=
other=technical version is  [id:405], an practical implementation of theory [id:410] which is prohibitive due to slow speed and large space cost.
---
id=405
title=A Hub-Based Labeling Algorithm for Shortest Paths on Road Networks
author=Ittai Abraham
journal=Technical Report of Microsoft Research
year=2010
tags=
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=406
title= A Practical Shortest Path Algorithm with Linear Expected Time
author=A. V. Goldberg
journal=SIAM Journal on Computing
year=2008
tags=linear time
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=407
title=Combining Hierarchical and Goal-Directed Speed-Up Techniques for Dijkstra’s Algorithm (experimental paper)
author=R. Bauer
journal= ACM Journal of Experimental Algorithmics
year=2010
tags=Experimental paper, survey, techniques of Shortest path, dijkstra algorithm, sssp
star=***
problem=
interest= In [id:409], basic speed-up techniques for Dijkstra’s algorithm have been combined. The key observation in their work was that it is most promising to combine hierarchical and goal-directed speed-up techniques. 
hardness= However, since its publication, impressive progress has been made in the field of speed-up techniques for Dijkstra’s algorithm and huge data sets have been made available.
idea= revisit the systematic combination of speed-up techniques in this work, which leads to the fastest known algorithms for various scenar- ios. Even for road networks, which have been worked on heavily during the last years, we are able to present an improvement in performance.  Moreover, we gain interesting insights into the behavior of speed-up techniques when combining them;     we focus on the most promising ones: adding goal- direction to hierarchical speed-up techniques.
future=
comment=
other=extension of [id:409], arc flags(AF) of goal-directed methods, contraction hierarchies(CH), Transit node routing (TNR), High-Performance Multi-Level Routing (HPML), TNR+AF (combining TNR, CH, and arc ags)
---
id=408
title=A Note on Two Problems in Connexion with Graphs
author=E. W. Dijkstra
journal=Numerische Mathematik
year=1959
tags=Dijkstra, sssp, shortest path, fit for General graphs(low-degree and high-degree), serial, hard to be parallelized
star=****
problem=
interest=
hardness=
idea=
future=
comment=O(vlgv+e) complexity with Fibonacci heap or relaxed heap; These heap methods reduce the cost of setting vertex values at the cost of added code complexity [id:38] of literature.list. However, Fibonacci heaps have large constant factors in practice, so using simpler binary heaps can be more efficient. 
other=
---
id=409
title=Combining Speed-up Techniques for Shortest-Path Computations
author=Martin Holzer
journal=ACM Journal of Experimental Algorithmics 10
year=2005
tags=Experimental paper, survey, techniques of single-pair shortest path(OPSP)
star=***
problem=Computing a shortest path from one node to another in a directed graph is a very common task in practice;  combination of speed-up techniques for Dijkstra’s algorithm;   The focus of this paper are variants of Dijkstra’s algorithm—also denoted as speed-up techniques in the following—that further exploit the fact that a target is given
interest=This problem is classically solved by Dijkstra’s algorithm.  Many techniques are known to speed up this algorithm heuristically, while optimality of the solution can still be guaranteed.
hardness=
idea= consider all possible combinations of four known techniques, namely goal-directed search, bidirectional search, multi-level approach(also called Hierarchical Approaches, require preprocessing), and shortest-path containers(require preprocessing) and show how these can be implemented.
future=
comment=
other=Typically, such technique improvements of Dijkstra’s algorithm cannot be proven to be asymptotically faster than the original algorithm, and are heuristics in this sense. However, it can be empirically shown that they indeed improve the running time drastically for many realistic data sets. Now  it is affordable, and applied by most of these new techniques, to precompute and store additional information on shortest paths(offline), which is used in the on-line phase to reduce the running time for solving a shortest-path query.
---
id=410
title=Highway Dimension, Shortest Paths, and Provably Efficient Algorithms
author=Ittai Abraham
journal=SODA
year=2010
tags=theorectical analysis, best time bound, labeling algorithm
star=***
problem=
interest=
hardness=
idea=two sets for each vertex: in and out, other vertices' distance
future=
comment=hard to implement, large cost of preprocessing and space
other=
---
id=411
title=Similarity Search in Sets and Categorical Data Using the Signature Tree  (S-Tree)
author=Nikos Mamoulis
journal=ICDE
year=2003
tags=Similarity search, S-Tree, signature tree, sets and Categorical data
star=****
problem=Search on these data types is not restricted to the classic problems of mining association rules and classification, but similarity search is also a frequently applied operation.
interest=Data mining applications analyze large collections of set data and high dimensional categorical data.
hardness=Access methods for multidimensional numerical data are inappropriate for this problem and specialized indexes are needed.
idea=propose a method that represents set data as bitmaps (signatures) and organizes them into a hierarchical index, suitable for similarity search and other related query types. In contrast to a previous technique, the signature tree is dynamic and does not rely on hardwired constants.
future=
comment=Experiments with synthetic and real datasets show that it is robust to different data characteristics, scalable to the database size and efficient for various queries. ; a dynamic balanced signature index for office retrieval
other=
---
id=412
title=Scalable Katz Ranking Computation in Large Dynamic Graphs
author=A. van der Grinten, E. Bergamini, O. Green
journal=European Symposium on Algorithms (ESA, CCF B conference of computer science area)
year=2018
tags=Katz Ranking Computation, large Dynamic graphs, katz centrality
star=***
problem=Network analysis defines a number of centrality measures to identify the most central nodes in a network. Fast computation of those measures is a major challenge in algorithmic network analysis. Aside from closeness and betweenness, Katz centrality is one of the established centrality measures. 
interest=
hardness=
idea=
future=
comment=
other=
---
id=413
title=Quickly Finding a Truss in a Haystack
author=Oded Green
journal=IEEE/Amazon/DARPA Graph Challenge
year=2017
tags=k-truss, Haystack
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=414
title=Exact and Parallel Triangle Counting in Streaming Graphs
author=Devavret Makkar, David A. Bader, Oded Green
journal=IEEE Conference on High Performance Computing, Data, and Analytics (HiPC)
year=2017
tags=exact, parallel, triangle counting(TC), graph stream
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=415
title=Trusses: Cohesive Subgraphs for Social Network Analysis
author=J. Cohen
journal=National Security Agency Technical Report
year=2008
tags=k-truss, Cohesive subgraph, social network analysis
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=416
title=A subgraph isomorphism algorithm and its application to biochemical data
author=Vincenzo Bonnici
journal=BMC Bioinformatics
year=2013
tags=subgraph isomorphism, biochemical data, subgraph match
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=417
title=gSpan: Graph-Based Substructure Pattern Mining
author=Xifeng Yan, Jiawei Han
journal=ICDM
year=2002
tags=gSpan, Graph-Based Substructure pattern mining, frequent pattern mining, social network analysis
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=418
title=Efficient Skew Handling for Outer Joins in a Cloud Computing Environment
author=Long Cheng
journal= IEEE Trans. Cloud Computing
year=2018
tags=skew handling, outer join, cloud Computing Environment
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=419
title=The Boost Graph Library: User Guide and Reference Manual (BGL)
author=Jeremy G. Siek
journal=C++ in-depth series, Pearson / Prentice Hall 
year=2002
tags=BGL, Boost Graph Library, user guide, Reference manual, Parallel BGL, shortets path(SSSP)
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=include the best implementation of Dijkstra's algorithm for SSSP(based on relaxed heap [id:420]), O(vlgv+e); this paper has citation on DBLP; also contain Bellman-Ford implementation, based on queue
---
id=420
title=Relaxed Heaps: An Alternative to Fibonacci Heaps with Applications to Parallel Computation
author=James R. Driscoll
journal=Commun. ACM 31
year=1988
tags=Relaxed Heap, Fibonacci Heap, SSSP, Parallel Computation
star=****
problem=
interest=The relaxed heap is a priority queue data structure that achieves the same amortized time bounds as the Fibonacci heap-a sequence of m decrease-key and n delete-n& operations takes time O(m + n log n).
hardness=
idea=A variant of relaxed heaps achieves similar bounds in the worst case-O(l) time for decrease-key and O(log n) for delete-min. Relaxed heaps give a processor-efficient parallel implementation of Dijkstra’s shortest path algorithm, and hence other algorithms in network optimization. A relaxed heap is a type of binomial queue that allows heap order to be violated.
future=
comment=in order to speed up Dijkstra using parallel computing, the heap must be parallelize. However, the original binary heap or Fibonacci heap is not easy for parallelism, so this work designes the Relaxed Heap.
other=
---
id=421
title=Matrix Decomposition Based Conjugate Gradient Solver for Poisson Equation
author=Hang Liu
journal=SC (short paper)
year=2012
tags=Matrix Decomposition, Conjugate Gradient Solver, Poisson Equation
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=422
title=Graphene: Fine-Grained IO Management for Graph Computing
author=Hang Liu, H. Howie Huang
journal=FAST
year=2017
tags=Graphene, Fine-Grained IO Management, Graph Computing, external memory processing, disk, SSD, new hardware, direct huge page(DHP), TLB miss, IO Request Centric Graph Processing, Bitmap based, asynchronous IO, Balanced data and workload partition, small block size of IO, IO deduplication and IO merging
star=****
problem=As graphs continue to grow, external memory graph processing systems serve as a promising alternative to inmemory solutions for low cost and high scalability.
interest=
hardness=Unfortunately, not only does this approach require considerable efforts in programming and IO management, but its performance also lags behind, in some cases by an order of magnitude.
idea=we strive to achieve an ambitious goal of achieving ease of programming and high IO performance (as in-memory processing) while maintaining graph data on disks (as external memory processing).  To this end, we have designed and developed Graphene that consists of four new techniques: an IO request centric programming model, bitmap based asynchronous IO, direct hugepage support, and data and workload balancing.
future=
comment=The evaluation shows that Graphene can not only run several times faster than several external-memory processing systems, but also performs comparably with in-memory processing on large graphs.
other=
---
id=423
title=CECI: Compact Embedding Cluster Index for Scalable Subgraph Matching
author=Bibek Bhattarai, Hang Liu, H. Howie Huang
journal=sigmod
year=2019
tags=CECI, compact Embedding cluster index, scalable Subgraph matching, Massively parallel systems, subgraph listing, subgraph matching, graph pattern matching, subgraph isomorphism, extreme cluster, BFS-based filtering, reverse-BFS-based refinement, openmp, mpi, distributed computing, PARALLEL EMBEDDING ENUMERATION, extreme cluster
star=****
problem=Subgraph matching finds all distinct isomorphic embeddings of a query graph on a data graph
interest=
hardness=For large graphs, current solutions face the scalability challenge due to expensive joins, excessive false candidates, and workload imbalance.
idea=a novel framework for subgraph listing based on Compact Embedding Cluster Index (CECI), which divides the data graph into multiple embedding clusters for parallel processing;   The CECI system has three unique techniques: utilizing the BFS-based filtering and reverse-BFS-based refinement to prune the unpromising candidates early on, replacing the edge verification with set intersection to speed up the candidate verification, and using search cardinality based cost estimation for detecting and dividing large embedding clusters in advance.
future=
comment=The experiments performed on several real and synthetic datasets show that the CECI system outperforms state-of-the-art solutions on average by 20.4× for listing all embeddings and by 2.6× for enumerating the first 1,024 embeddings.
other=the embedding is similar to candidate region of TurboISO but less size; larger size compared to CFL-match, but non-tree edges candidates are added and faster
---
id=424
title=Algorithms and heuristics for scalable betweenness centrality computation on multi-GPU systems
author=F Vella
journal=arXiv
year=2016
tags=betweenness centrality, multi-GPU, cuda
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=425
title=Multilevel parallelism for the exploration of large-scale graphs (Bfs2d, mgbc)
author=Massimo Bernaschi
journal=IEEE Trans. Multi-Scale Computing Systems
year=2018
tags=Multilevel parallelism, large-scale graphs, sssp, apsp, BFS, MPI, CUDA, GPU, distributed programming, GPUDirect Async, MGBC, Bfs2D, distributed computing
star=***
problem=We present the most recent release of our parallel implementation of the BFS and BC algorithms for the study of large scale graphs
interest=Although our reference platform is a high-end cluster of new generation Nvidia GPUs and some of our optimizations are CUDA specific, most of our ideas can be applied to other platforms offering multiple levels of parallelism.
hardness=
idea= We exploit multi level parallel processing through a hybrid programming paradigm that combines highly tuned CUDA kernels, for the computations performed by each node, and explicit data exchange through the Message Passing Interface (MPI), for the communications among nodes. The results of the numerical experiments show that the performance of our code is comparable or better with respect to other state-of-the-art solutions.
future=for the BFS we would like to improve the heuristic to switch between the top-down and the bottom-up variant and to evaluate the advantages that technologies like GPUDirect Async can provide for reducing the overhead of the communication among GPUs; As to the BC, we are already adapting MGBC to the evaluation of approximated BC [id:426] for extremely-large-scale graphs. Finally, we are going to explore the chance of using our BFS as a building block for the solution of other graphs problems.
comment=For the BFS, for instance, we reach a peak performance of 200 Giga Teps on a single GPU and 5.5 Terateps on 1024 Pascal GPUs. We release our source codes both for reproducing the results and for facilitating their usage as a building block for the implementation of other algorithms.   ; good related work about BFS and BC
other=https://gitlab.com/maurob/Bfs2D      https://bitbucket.org/fvella/mgbc/src/master/
---
id=426
title=Approximating betweenness centrality
author=
journal=
year=2007
tags=Approximate, betweenness centrality(BC)
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=another paper is Better approximation of betweenness centrality    2008
---
id=427
title=KLA: A New Algorithmic Paradigm for Parallel Graph Computations
author=Harshvardhan
journal=PACT
year=2014
tags=level-synchronous, asynchronous, KLA, parallel graph computation, global synchronization, stapl Graph Library, multi-core, distributed
star=***
problem=This paper proposes a new algorithmic paradigm  k-level asynchronous (KLA)  that bridges level-synchronous and asynchronous paradigms for processing graphs.
interest=The KLA paradigm enables the level of asynchrony in parallel graph algorithms to be parametrically varied from none (level- synchronous) to full (asynchronous).
hardness=
idea=The motivation is to improve execution times through an appropriate trade-o between the use of fewer, but more expensive global synchronizations, as in level-synchronous algorithms, and more, but less expensive local synchronizations (and perhaps also redundant work), as in asynchronous algorithms.  ;     We show how common patterns in graph algorithms can be expressed in the KLA pardigm and provide techniques for determining k, the number of asynchronous steps allowed between global synchronizations.
future=
comment=
other=The delta-stepping algorithm differs from KLA in that it centers around using edge-weights as the metric to prioritize the processing of edges, which has no impact on non-SSSP based algorithms.
---
id=428
title=Performance characterization of high-level programming models for GPU graph analytics
author=Yuduo Wu
journal=IEEE International Symposium on Workload Characterization(IISWC)
year=2015
tags=GPU Graph Analytics, Gunrock, MapGraph, VertexAPI2, load balance, memory access pattern, performance Characterization, Experimental paper, high-level programming model
star=***
problem=We identify several factors that are critical to high-performance GPU graph analytics: efficient building block operators, synchronization and data movement, workload distribution and load balancing, and memory access patterns.
interest=
hardness=
idea=We analyze the impact of these critical factors through three GPU graph analytic frameworks, Gunrock, MapGraph, and VertexAPI2. We also examine their effect on different workloads: four common graph primitives from multiple graph application domains, evaluated through real-world and synthetic graphs. 
future=
comment=We show that efficient building block operators enable more powerful operations for fast information propagation and result in fewer device kernel invocations, less data movement, and fewer global synchronizations, and thus are key focus areas for efficient large-scale graph analytics on the GPU.
other=
---
id=429
title=
author=
journal=
year=
tags=
star=
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=430
title=Utilizing Dynamic Properties of Sharing Bits and Registers to Estimate User Cardinalities over Time
author=Pinghui Wang
journal=
year=2018
tags=data stream, graph stream, dyanmic property, sharing bits, user cardinality
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=431
title=Graph stream algorithms: a survey
author=ndrew McGregor
journal=sigmod record
year=2014
tags=survey, data stream, graph stream algorithms
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=the graph stream area is an intersection of data stream area and graph area, so it can borrow ideas from these two.
---
id=432
title=A Survey on Streaming Algorithms for Massive Graphs
author=Jian Zhang
journal=Managing and Mining Graph Data
year=2010
tags=survey, graph stream
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=433
title=Monitoring Streams – A New Class of Data Management Applications   (Aurora)
author=Don Carney
journal=VLDB
year=2002
tags=batch compute, stream compute, stream processing, data stream, graph stream, Aurora system Architecture, DBMS, sensors, continual inputs, data mining, stream-oriented set of operators, Real-time
star=****
problem=This paper introduces monitoring applications, which we will show differ substantially from conventional business data processing.
interest=The fact that a software system must process and react to continual inputs from many sources (e.g., sensors) rather than from human operators requires one to rethink the fundamental architecture of a DBMS for this application area.
hardness=
idea=Aurora, a new DBMS that is currently under construction at Brandeis University, Brown University, and M.I.T. We describe the basic system architecture, a stream-oriented set of operators, optimization tactics, and support for real-time operation.
future=
comment=
other=MR也有自己的实时计算方案，比如说HOP。流式处理的模式决定了要和批处理使用非常不同的架构，试图搭建一个既适合流式计算又适合批处理计算的通用平台，结果可能会是一个高度复杂的系统，并且最终系统可能对两种计算都不理想。    ;   IBM System S,     比较著名的流计算开源框架有 Apache Storm(Twitter) and the second generation Heron ，Apache Samza，Apache Spark Streaming，Apache Flink, Apache Kafka(LinkedIn), S4(Yahoo!)等 ; 流式计算研究在互联网领域持续升温。不过流式计算并非最近几年才开始研究，传统行业像金融领域等很早就已经在使用流式计算系统，比较知名的有StreamBase、Borealis等。  ;   https://blog.csdn.net/iteye_11067/article/details/81658930
---
id=434
title=Efficient Algorithms for Path Problems in Weighted Graphs
author=Virginia Vassilevska
journal=phd dissertation, School of Computer Science, Carnegie Mellon University(CMU)
year=2008
tags=s-t shortest path, single-pair shortest path, weighted graphs, one-pair shortest path(OPSP)
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=435
title=fast algorithms for shortest paths
author=Alistair Moffat
journal=phd dissertation, University of Canterbury
year=1985
tags=all shortest paths(APSP), non-negatively weighted directed graph, Floyd, Dijkstra, theorectical bound, distance matrix multiplication
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=436
title=A simple shortest path algorithm with linear average time.
author=A. V. Goldberg
journal= Proc.  9th Ann. European Symposium on Algorithms (ESA)
year=2001
tags=shortest path, sssp, linear average time, O(nlogC+m), in-criterion, positive weight, uniformly distributed, priority queue, shortest path tree, labeling algorithm
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=O(nlogC+m) time complexity,   C is the ratio of the largest and the smallest nonzero arc length  (require the weight is positive and uniformly distributed)
---
id=437
title=Single-Source Shortest Paths on Arbitrary Directed Graphs in Linear Average Time
author=U. Meyer
journal=Proc. 12th ACM-SIAM Symposium on Discrete Algorithms
year=2001
tags=shortest path, SSSP, arbitary directed graph, Linear average time
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=438
title=Undirected Single-Source Shortest Paths with Positive Integer Weights in Linear Time.
author=M. Thorup
journal=J. Assoc. Comput. Mach.
year=1999
tags=Undirected graph, sssp, shortest path, positive integer weights, linear time
star=****
problem=
interest=
hardness=
idea=
future=
comment=the first to give linear-time RAM algorithm for sssp on undirected Graphs with nonnegative floating-point or integer weights fitting into words of length .
other=
---
id=439
title=Computing Point-to-Point Shortest Paths from External Memory.
author=A. V. Goldberg
journal= ALENEX/ANALCO
year=2005
tags=Point-to-Point shortest path, single-pair shortets path, s-t shortest path, External memory
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=440
title=Reach for A*: Efficient Point-to-Point Shortest Path Algorithms
author=A. V. Goldberg
journal=SIAM
year=2006
tags=A*(A-star), Point-to-Point Shortest path, single-pair shortest path, s-t shortest path
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=441
title=Computing the shortest path: A* search meets graph theory
author=A. V. Goldberg
journal=SODA (ACM/SIAM Symposium on Discrete Algorithms)
year=2005
tags=shortest path, graph theory
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=442
title=Trans-dichotomous algorithms for minimum spanning trees and shortest paths
author=M. L. Fredman
journal= J. Comput. System Sci.
year=1994
tags=spanning tree, shortest path, atomic heap, SSSP
star=****
problem=
interest=
hardness=
idea=
future=
comment=for sssp the time bound is O(m+nlogn/loglogn);  but the atomic heap is only defined for n>=2^12^20
other=
---
id=443
title=Recent results on the single-source shortest paths problem
author= R. Raman
journal=ACM SIGACT News
year=1997
tags=sssp, shortest path, Dijkstra's algorithm with bucket based priority queues, arbitary directed graphs, nonnegative integer edge-weights, RAM model
star=****
problem=
interest=
hardness=
idea=
future=
comment=So far, the best bound for SSSP on arbitrary directed graphs with nonnegative integer edge-weights in {1,...,C} is O(m+n(logC)^(0.25+epison)) expected time for any fixed epison>0
other=Alternative bucket approaches include nested (multiple levels) buckets and/or buckets of different widths
---
id=444
title= Implementation and efficiency of Moore-algorithms for the shortest route problem.
author=U. Pape
journal=math programming
year=1974
tags=Moore-algorithms, shortest path, shortest route, SSSP, exponential wort-case time, striking performance on real-world data, sequential algorithm
star=****
problem=
interest=
hardness=
idea=maintain a queue(or frontier) of active vertices in Bellman-Ford instead of all edges;   each node processing is independent from others and including non-active nodes in the processing phase of any Propagation step does not change the result(next frontier)
future=
comment=some recent label-correcting approaches run considerably faster than the original Bellman–Ford algorithm and even outperform label-setting algorithms on certain data sets.    So far, no profound average-case analysis has been given to explain the observed effects. A striking example in this respect is the shortest-paths algorithm of Pape [118]; in spite of exponential worst-case time it performs very well on real-world data like road graphs.
other=
---
id=445
title=Shortest paths in digraphs of small treewidth
author= S.Chaudhuri
journal= Part I : Sequential algorithms. Algorithmica
year=2000
tags=Shortest path, small treewidth, linear-time, SSSP
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=Another example for a “well-behaved” input class are graphs with constant tree width; they allow for a linear-time SSSP algorithm as well
---
id=446
title=Shortest path algorithms: Theory and experimental evaluation
author=B. V. Cherkassky
journal=Math. programming
year=1996
tags=experimental paper, theorectical analysis, upper bound, shortest path, Dijkstra's algorithm, SSSP, Approximate Bucket Implementation(ABI-Dijkstra)
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=447
title= The degree sequence of a random graph, I: The models
author=B. D. Mckay
journal=Random Structures and Algorithms
year=1997
tags=degree sequence, random graph, graph algorithm, shortest path
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=448
title= On the all-pairs shortest-path algorithm of Moffat and Takaoka
author= K. Mehlhorn
journal=Random Structures and Algorithms
year=1997
tags=APSP, shortest path, graph algorithm
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=449
title=Graphmat: High performance graph analytics made productive
author=N. sundaram
journal=VLDB
year=2015
tags=Graphmat, hpc, graph analytics, system, library, multi-core, vertex programming, distributed parallel and Cluster computing
star=****
problem=improve the performance of graph analysis frameworks without compromising on productivity
interest=GraphMat is our solution to bridge this gap between a user-friendly graph analytics framework and native, hand-optimized code.
hardness=
idea= GraphMat functions by taking vertex programs and mapping them to high performance sparse matrix operations in the backend. We get the productivity benefits of a vertex programming framework without sacrificing performance. GraphMat is in C++, and we have been able to write a diverse set of graph algorithms in this framework with the same effort compared to other vertex programming frameworks. GraphMat performs 1.2-7X faster than high performance frameworks such as GraphLab, CombBLAS and Galois. It achieves better multicore scalability (13-15X on 24 cores) than other frameworks and is 1.2X off native, hand-optimized code on a variety of different graph algorithms.
future=
comment=
other=
---
id=450
title=Groute: An asynchronous multi-GPU programming model for irregular computations
author=T. Ben-Nun
journal=ACM sigplan notices
year=2017
tags=Groute, multi-gpu programming model, irregular computations, asynchronous graph traversal, SSSP with atomic operations
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=no workload imbalance in asynchronous graph traversal
---
id=451
title=GraphTuner: An input dependence aware loop perforation scheme for efficient execution of approximated graph algorithms
author=H. Omar
journal=ICCD(CCF B Conference of architecture area)
year=2017
tags=GraphTuner, input dependence, loop perforation scheme, approximate graph algorithms
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=452
title=On the Complexity of Optimal Lottery Pricing and Randomized Mechanisms
author=Xi Chen, Ilias Diakonikolas, Anthi Orfanou, Dimitris Paparas, Xiaorui Sun, Mihalis Yannakakis
journal=FOCS
year=2015
tags=theory of computer science, Complexity, optimal Lottery Pricing, Randomized Mechanism
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=453
title=Settling the Complexity of 2-Player Nash-Equilibrium
author=Xi Chen, Xiaotie Deng
journal=FOCS (best paper), Electronic Colloquium on Computational Complexity (ECCC) 2005
year=2006
tags=Complexity, 2-Player Nash-Equilibrium
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=454
title=On the Complexity of Nash Equilibria in Anonymous Games
author=Xi Chen, David Durfee, Anthi Orfanou
journal=STOC
year=2015
tags=theory of computer science, Complexity, Nash Equilibria, Anonymous game
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=455
title=Learning Arbitrary Statistical Mixtures of Discrete Distributions.
author=Jian Li
journal=STOC
year=2015
tags=arbitary Statistical mixture, discrete Distributions
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=456
title=Boolean Function Monotonicity Testing Requires (Almost) n^(1/2) Non-adaptive Queries
author=Xi Chen
journal=STOC
year=2015
tags=Boolean Function, Monotonicity testing, Non-adaptive query
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=457
title=Nearly-Linear Time Positive LP Solver with Faster Convergence Rate.
author=Zeyuan Allen-Zhu
journal=STOC
year=2015
tags=Nearly-Linear time Positive LP Solver, faster Convergence rate
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=458
title=Spectral Sparsification and Regret Minimization Beyond Matrix Multiplicative Updates
author=Zeyuan Allen-Zhu
journal=STOC
year=2015
tags=Spectral Sparsification, Regret Minimization, matrix Multiplicative updates
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=459
title=On the Complexity of Simple and Optimal Deterministic Mechanisms for an Additive Buyer
author=Xi Chen
journal=SODA (best of algorithm)
year=2018
tags=Complexity, optimal Deterministic Mechanism, Additive buyer
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=460
title=Tight Bounds for the Distribution-Free Testing of Monotone Conjunctions
author=Xi Chen
journal=SODA
year=2016
tags=tight bound, Distribution-Free testing, Monoton Conjunctions
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=461
title=The Complexity of Optimal Multidimensional Pricing
author=Xi Chen
journal=SODA
year=2014
tags=Complexity, optimal Multidimensional pricing
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=462
title=The approximation complexity of win-lose games
author=Xi Chen
journal=SODA
year=2007
tags=approximation complexity, win-lose game
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=463
title=Wuji: Automatic Online Combat Game Testing Using Evolutionary Deep Reinforcement Learning
author=Yan Zheng, Xiaofei Xie, Ting Su, Lei Ma
journal= best paper of International Conference on Automated Software Engineering (ASE, CCF A Conference of Software Engineering)
year=2019
tags=Wuji, Automatic Online Combat game testing, Evolutionary deep Reinforcement Learning (DRL)
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=464
title=A Probabilistic Divide and Conquer Algorithm for the Minimum Tollbooth Problem
author=Julian Nickerl 
journal=CSoNet (Computational Data and Social Networks)
year=2019
tags=computing social network, Probabilistic, divide and Conquer, Minimum Tollbooth Problem
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=465
title=Hop-based Sketch for Large-scale Infuence Analysis
author= Phuc Thai , Thang Dinh 
journal=CSoNet
year=2019
tags=Hop-based Sketch, Large-scale, influence Analysis, social network
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=466
title=Subgraph-based Adversarial Examples Against Graph-based IoT Malware Detection Systems
author=Ahmed Abusnaina
journal=CSoNet
year=2019
tags=social network, Subgraph-based Adversarial example, IoT Malware Detection
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=467
title=Blockchain Queue Theory
author=Quan-Lin Li, Jing-Yu Ma, Yan-Xia Chang
journal=CSoNet
year=2018
tags=social network, Blockchain queue Theory
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=468
title=Minimizing Influence of Rumors by Blockers on Social Networks
author=Ruidong Yan, Deying Li, Weili Wu, Ding-Zhu Du
journal=CSoNet
year=2018
tags=Minimizing Influence of Rumors, Blockers, social Network
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=469
title= Graph Convolutional Networks: Algorithms, Applications and Open Challenges
author=Si Zhang, Hanghang Tong, Jiejun Xu, Ross Maciejewski
journal=CSoNet
year=2018
tags=social Network, Graph Convolutional Network (GCN), survey, Algorithm, Applications, open Challenges
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=470
title= A Path Planning Approach with Maximum Traffic Flow and Minimum Breakdown Probability in Complex Road Network
author=Mengran Xu, Demin Li, Guanglin Zhang, Mengqi Cao, Shuya Liao
journal=CSoNet
year=2018
tags=social Network,path Planning, Maximum Traffic flow, Minimum Breakdown Probability, complex road Network
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=471
title= Towards a New Evolutionary Algorithm for the Minimum Tollbooth Problem
author=Pavel Krömer, Jana Nowaková, Martin Hasal
journal=CSoNet
year=2018
tags=social Network, Evolutionary Algorithm, Minimum Tollbooth problem
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=472
title=Operator-aware approach for boosting performance in RDF stream processing
author=Danh Le-Phuoc
journal=Journal of web semantics (JWS, CCF B Journal of database)
year=2017
tags=Operator-aware data Structures, RDF stream processing, graph stream, incremental computing, sliding window, relational stream processing system
star=***
problem=To enable efficiency in stream processing, the evaluation of a query is usually performed over bounded parts of (potentially) unbounded streams, i.e., processing windows “slide” over the streams. 
interest=To avoid inefficient re-evaluations of already evaluated parts of a stream in respect to a query, incremental evaluation strategies are applied, i.e., the query results are obtained incrementally from the result set of the preceding processing state without having to re-evaluate all input buffers.
hardness=This method is highly efficient but it comes at the cost of having to maintain processing state, which is not trivial, and may defeat performance advantages of the incremental evaluation strategy. In the context of RDF streams the problem is further aggravated by the hard-to-predict evolution of the structure of RDF graphs over time and the application of sub-optimal implementation approaches, e.g., using relational technologies for storing data and processing states which incur significant performance drawbacks for graph-based query patterns. 
idea= To address these performance problems, this paper proposes a set of novel operator-aware data structures coupled with incremental evaluation algorithms which outperform the counterparts of relational stream processing systems. This claim is demonstrated through extensive experimental results on both simulated and real datasets.
future=
comment=
other=
---
id=473
title=C-SPARQL: A CONTINUOUS QUERY LANGUAGE FOR RDF DATA STREAMS
author=D. F. barbieri 
journal=International journal of Semantic Computing
year=2010
tags=C-SPARQL, Continuous query language, RDF data stream, graph stream
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=474
title=Efficient RDF Interchange (ERI) Format for RDF Data Streams
author=Javier D. Fernández, Alejandro Llaves, Oscar Corcho
journal=International semantic web Conference
year=2014
tags=RDF Interchange format, ERI, RDF data stream, graph stream
star=**
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=475
title=THE Pros AND Cons OF RDF STRUCTURE INDEXES
author=Balazs Pinczel, David Nagy, Attila Kiss
journal=
year=2014
tags=pros and cons, experimental analysis, bisimulation, RDF structure indexes, performance measurement, Semantic Web, RDF, SPARQL, structural property
star=**
problem=During recent years, BigData trends resulted in an increasing number of large datasets. As a result, Semantic Web technologies not only have to face the diculties stemming from sheer data size, but { arising from its intentions of interconnecting all relevant pieces of knowledge { other problems can appear because of the increased structural complexity of the data }}
interest=there are several approaches to support the technologies by utilizing structure indexes in order to increase the eciency of query evaluation.
hardness=However, in our experience, the benets of these methods depend largely on the structural properties of the data.
idea=summarize our experiments conducted on a parameterizable dataset, with the intention of characterizing the relationship between the structural complexity of the data and the possible benets of using a structure index.
future=
comment=
other=
---
id=476
title=managing structured and semistructured RDF data using structure indexes
author=T. Tran, G. Ladwig, S. Rudolph
journal=TKDE
year=2013
tags=structured and semistructured RDF data, structure index
star=****
problem=use structure index to query RDF data whose schema is incomplete or not available
interest=
hardness=
idea=we leverage it for a structure-oriented approach to RDF data partitioning and query processing. Based on information captured by the structure index, similarly structured data elements are physically grouped and stored contiguously on disk. At querying time, the index is used for "structure-level" processing to identify the groups of data that match the query structure. Structure-level processing is then combined with standard "data-level" operations that involve retrieval and join procedures executed against the data.
future=
comment= In the experiment, our solution provides several times faster performance than a state-of-the-art technique for data partitioning and query processing, and compares favorably with full-fledged RDF stores.
other=
---
id=477
title=Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation 
author=Shaohua Fan (Beijing University of Posts and Telecommunications)
journal=SIGKDD
year=2019
tags=Graph neural network (GNN), Metapath-guided Heterogeneous, Intent Recommendation, Metapath-guided Embedding method for Intent Recommendation（MEIRec）
star=****
problem=本文研究了电商场景下的一种新型推荐服务：意图推荐。不同于传统的商品推荐，意图推荐希望在用户打开 APP 并没有任何输入的情况下来预测用户的意图
interest=
hardness=现在工业界针对意图推荐的解决方案主要是基于特征工程的算法来挖掘属性信息。这样就导致推荐场景里的丰富的交互信息没有充分挖掘
idea=针对上述问题，本文将意图推荐场景建模为异质图并设计了一种 Metapath-guided Embedding method for Intent Recommendation（MEIRec）来进行用户意图推荐。  MEIRec 的核心思想是：设计一个异质图神经网络来学习 user 和 query 的表示。
future=
comment=本文首先研究了一个很重要且富有挑战的的问题：意图推荐。针对意图推荐的场景特点，作者首先建立了大规模异质图并设计了相应的异质图神经网络来进行意图推荐。大量充分的实验结果也证明了 MEIRec 的有效性。 过去一年，基于图神经网络的推荐算法在各大顶会层出不穷。在实际工业应用时，数据交互更为复杂。因此，基于异质图神经网络的推荐有更好的使用价值。
other=https://github.com/googlebaba/KDD2019-MEIRec        https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247500588&idx=2&sn=81cadf691a31c9caba094748b6642f18&chksm=96ea1caca19d95ba96c4059c5c06105e4fb652a7e0c2f332eb9648f380ad0dd277bc1cecc60d&mpshare=1&scene=1&srcid=&sharer_sharetime=1572712675177&sharer_shareid=fde7a6b959e1e246d8c1b59ef3145103&key=69f28381a3e17e7070a15cbd4f455fdf4dd6ade7a15ff1f2de9b6c829235ce930d5efa3d7b687831255b6a52bae53cce133c33a044883ab4a8a4e0656b39d2ad4e0218b5b689225047d8c7c2baa9ebdf&ascene=1&uin=MzQzNjUxNjM0NA%3D%3D&devicetype=Windows+10&version=62070152&lang=zh_CN&pass_ticket=34Ba4%2FWKqs1plTfi8obSk5Fv2E60pamEurduThZ%2BQimWDyB5yFGUy0yY0%2B3S1yWi
---
id=478
title=Bitcoin: A Peer-to-Peer Electronic Cash System
author=Satoshi Nakamoto   (中本聪)
journal=
year=2008
tags=Bitcoin, Peer-to-Peer (P2P), Electronic cash system, Blockchain, double-spending, 比特币白皮书 (bitcoin white paper), hash-based, proof-of-work
star=*****
problem=A  purely   peer-to-peer   version   of   electronic   cash   would   allow   onlinepayments   to   be   sent   directly   from   one   party   to   another   without   going   through   afinancial institution. 
interest=
hardness=Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending.
idea=We propose a solution to the double-spending problem using a peer-to-peer network.  The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. 
future=
comment=As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.
other=https://bitcoin.org/bitcoin.pdf    https://www.jianshu.com/p/6b67c87777ce
---
id=479
title=THIRTY YEARS OF GRAPH MATCHING IN PATTERN RECOGNITION
author=D. CONTE, et al.
journal=International Journal of Pattern Recognition and Artificial Intelligence  (IJPRAI, CCF C Journal of AI area)
year=2004
tags=survey, graph matching, Monomorphism, pattern Recognition, Subgraph isomorphism, induced subgraph, homomorphism, definition, variant, algorithm
star=***
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=480
title=Weaver: a high-performance, transactional graph database based on refinable timestamps 
author= Ayush Dubey, Greg D. Hill, Robert Escriva, Emin Gün Sirer
journal=VLDB
year=2016
tags=Weaver, vector clock, high performance, transaction, graph database, refinable timestamp, distributed protocol, lock, parallel, ACID, consistency, read-write conflict, multi-version Concurrency control (MVCC), weak consistency, strong consistency, serialization, Serializability, scalability, graph traversal, distributed computing, data mining
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=https://github.com/thinkaurelius/titan/
---
id=481
title=TAO: Facebook's distributed data store for the social graph 
author= Nathan Bronson, Zach Amsden, George Cabrera, Prasad Chakka, Peter Dimov
journal=USENIX ATC
year=2013
tags=TAO, Facebook, distributed data store, social graph, social network, data model, API, workload, petabyte, database
star=****
problem=We introduce a simple data model and API tailored for serving the social graph, and TAO, an implementation of this model. 
interest=
hardness=
idea=TAO is a geographically distributed data store that provides efficient and timely access to the social graph for Facebook's demanding workload using a fixed set of queries. It is deployed at Facebook, replacing memcache for many data types that fit its model. 
future=
comment=The system runs on thousands of machines, is widely distributed, and provides access to many petabytes of data. TAO can process a billion reads and millions of writes each second.
other=
---
id=482
title=Efficient Progressive Minimum k-core Search  (PSA)
author=Conggai Li, Fan Zhang, Ying Zhang, Lu Qin, Wenjie Zhang, Xuemin Lin
journal=vldb
year=2020
tags=PSA, Minimum k-core search, Progressive, NP-hard
star=****
problem=given a graph G, an integer k and a set of query vertices Q, we aim to find the smallest k-core subgraph containing every query vertex
interest=
hardness=It has been shown that this problem is NP-hard with a huge search space, and it is very challenging to nd the optimal solution. There are several heuristic algorithms for this problem, but they rely on simple scoring functions and there is no guarantee as to the size of the resulting subgraph, compared with the optimal solution.   Our empirical study also indicates that the size of their resulting subgraphs may be large in practice.
idea=we develop an effective and ecient progressive algorithm, namely PSA, to provide a good trade-off between the quality of the result and the search time. Novel lower and upper bound techniques for the minimum k-core search are designed.
future=
comment=
other=
---
id=483
title=Database Processing-in-Memory: An Experimental Study
author=Tiago Kepe, Eduardo Cunha De Almeida, Marco Alves
journal=vldb
year=2020
tags=Experimental study, database, Processing-in-Memory (PIM) hardware, memory computation, SIMD operators, AVX512, hybrid query scheduling, x86, trade-off of execution time and energy consumption, materialized, vectorized, pipelined
star=****
problem=Large amounts of data need to move through the memory up to the CPU before any computation takes place
interest=Processing-in-Memory (PIM) inverts the traditional data processing by pushing computation to memory with an impact on performance and energy efficiency
hardness=
idea=an experimental study on processing database SIMD operators in PIM compared to current x86 processor (i.e., using AVX512 instructions).  We discuss the execution time gap between those architectures.  However, this is the first experimental study, in the database community, to discuss the trade-offs of execution time and energy consumption between PIM and x86 in the main query execution systems: materialized, vectorized, and pipelined.
future=
comment=We also discuss the results of a hybrid query scheduling when interleaving the execution of the SIMD operators between PIM and x86 processing hardware. In our results, the hybrid query plan reduced the execution time by 45%. It also drastically reduced energy consumption by more than 2 compared to hardware-specific query plans.
other=this paper introduces the background of 3D-stacked memory and PIM architecture
---
id=484
title=AJoin: Ad-hoc Stream Joins at Scale
author=Jeyhun Karimov, Tilmann Rabl, Volker Markl
journal=vldb
year=2020
tags=stream processing engine (SPE), multi-tenant systems, cloud, AJoin, Ad-hoc stream join, optimization of join operator, pipeline-parallel join architecture, query execution plan (QEP), finite time duration, join result sharing (share), scale up and scale out
star=****
problem=The processing model of state-of-the-art stream processing engines is designed to execute long-running queries one at a time.
interest=However, with the advance of cloud technologies and multi-tenant systems, multiple users share the same cloud for stream query processing. This results in many ad-hoc stream queries sharing common stream sources. Many of these queries include joins.
hardness=There are two main limitations that hinder performing ad-hoc stream join processing. The first limitation is missed optimization potential both in stream data processing and query optimization layers. The second limitation is the lack of dynamicity in query execution plans.
idea=AJoin, a dynamic and incremental ad-hoc stream join framework. AJoin consists of an optimization layer and a stream data processing layer. The optimization layer periodically reoptimizes the query execution plan, performing join reordering and vertical and horizontal scaling at run-time without stopping the execution. The data processing layer implements pipeline-parallel join architecture. This layer enables incremental and consistent query processing supporting all the actions triggered by the optimizer.
future=
comment=We implement AJoin on top of Apache Flink, an open-source data processing framework. AJoin outperforms Flink not only at ad-hoc multi-query workloads but also at single-query workloads.
other=Scale out is a growth architecture or method that focuses on horizontal growth, or the addition of new resources instead of increasing the capacity of current resources (known as scaling up).
---
id=485
title=On Performance Stability in LSM-based Storage Systems
author=Chen Luo, Michael J. Carey
journal=vldb
year=2020
tags=Log-Structured Merge-Tree (LSM-tree), LSM-based storage system, Performance Stability, NoSQL, write Performance, write stall, Performance variance, I/O operation, LSM merge schedulers, experimental analysis
star=****
problem=
interest=The Log-Structured Merge-Tree (LSM-tree) has been widely adopted for use in modern NoSQL systems for its superior write performance.
hardness=Despite the popularity of LSM-trees, they have been criticized for suering from write stalls and large performance variances due to the inherent mismatch between their fast in-memory writes and slow background I/O operations.
idea=a simple yet effective two-phase experimental approach to evaluate write stalls for various LSM-tree designs. We further identify and explore the design choices of LSM merge schedulers to minimize write stalls given an I/O bandwidth budget.
future=
comment=We have conducted extensive experiments in the context of the Apache AsterixDB system and we present the results here.
other=
---
id=486
title=Mining an “Anti-Knowledge Base” from Wikipedia Updates with Applications to Fact Checking and Beyond (AKB)
author=Georgios Karagiannis, et al.
journal=vldb
year=2020
tags=AKB, Anti-Knowledge mining, Anti-Knowledge base, Wikipedia update, fact checking, Unsupervised
star=****
problem=create an "anti-knowledge base" that contains factual mistakes
interest=The resulting data can be used for analysis, training, and benchmarking in the research domain of automated fact checking. Prior data sets feature manually generated fact checks of famous misclaims. Instead, we focus on the long tail of factual mistakes made by Web authors, ranging from erroneous sports results to incorrect capitals.
hardness=We mine mistakes automatically, by an unsupervised approach, from Wikipedia updates that correct factual mistakes. Identifying such updates (only a small fraction of the total number of updates) is one of the primary challenges.
idea=We mine anti-knowledge by a multi-step pipeline. First, we lter out candidate updates via several simple heuris- tics. Next, we correlate Wikipedia updates with other state- ments made on the Web. Using claim occurrence frequen- cies as input to a probabilistic model, we infer the likelihood of corrections via an iterative expectation-maximization ap- proach. Finally, we extract mistakes in the form of subject- predicate-object triples and rank them according to several criteria.
future=
comment=Our end result is a data set containing over 110,000 ranked mistakes with a precision of 85% in the top 1% and a precision of over 60% in the top 25%. We demonstrate that baselines achieve signicantly lower precision. Also, we exploit our data to verify several hypothesis on why users make mistakes. We nally show that the AKB can be used to nd mistakes on the entire Web.
other=
---
id=487
title=Joins on Samples: A Theoretical Guide for Practitioners
author=Dawei Huang , Dong Young Yoon , Seth Pettie , Barzan Mozafari
journal=vldb
year=2020
tags=join on sample, Theoretical guide, Practitioners, sample-based join, AQP (approximate query processing), output size, estimator variance
star=****
problem=Is sampling for joins still futile in all of these settings? If not, what is the best sampling strategy in each case?
interest=this early result has little applicability to the key questions practitioners face.  For example, the success metric is often the final approximation’s accuracy, rather than output cardinality. Moreover, there are many non-uniform sampling strategies that one can employ.
hardness=Despite decades of research on AQP (approximate query processing), our understanding of sample-based joins has remained limited and, to some extent, even superficial. The common belief in the community is that joining random samples is futile. This belief is largely based on an early result showing that the join of two uniform samples is not an independent sample of the original join, and that it leads to quadratically fewer output tuples.
idea=improve our understanding of sample-based joins and offer a guideline for practitioners building and using realworld AQP systems. We study limitations of offline samples in approximating join queries: given an offline sampling budget, how well can one approximate the join of two tables? We answer this question for two success metrics: output size and estimator variance.  We show that maximizing output size is easy, while there is an information-theoretical lower bound on the lowest variance achievable by any sampling strategy. We then define a hybrid sampling scheme that captures all combinations of stratified, universe, and Bernoulli sampling, and show that this scheme with our optimal parameters achieves the theoretical lower bound within a constant factor. Since computing these optimal parameters requires shuffling statistics across the network, we also propose a decentralized variant in which each node acts autonomously using minimal statistics.
future=
comment=We also empirically validate our findings on popular SQL and AQP engines.
other=
---
id=488
title=Hop-constrained s-t Simple Path Enumeration: Towards Bridging Theory and Practice
author=You Peng, et al.
journal=vldb
year=2020
tags=Hop-constrained s-t Simple path Enumeration, theory and Practice, vertex similarity, vertex influence, BC-DFS, JOIN
star=****
problem=list all simple paths from a source vertex s to a target vertex t with hop-constraint k.
interest=One of the fundamental tasks in graph analytics is to investigate the relations between two vertices (e.g., users, items and enti- ties) such as how a vertex A influences another vertex B, or to what extent A and B are similar to each other, based on the graph topology structure.
hardness=
idea=a polynomial delay algorithm, namely BC-DFS, based on barrier-based pruning technique. Then a join-oriented algorithm, namely JOIN, is designed to further enhance the query response time. On the theoretical side, BC-DFS is a polynomial delay algorithm with O(km) time per output where m is the number of edges in the graph.  This time complexity is the same as the best known theoretical result for the polynomial delay algorithms of this problem.
future=
comment=On the practical side, our comprehensive experiments on 15 real-life networks demonstrate the superior performance of the BC-DFS algorithm compared to the state-of-the-art techniques. It is also reported that the JOIN algo- rithm can further significantly enhance the query response time.
other=
---
id=489
title=Optimizing Databases by Learning Hidden Parameters of Solid State Drives
author=Aarati Kakaraparthy, et al.
journal=vldb
year=2020
tags=Solid State Drives (SSDs), database optimization, Learning hidden Parameters, I/O behavior,ssd-s, ssd-t, request size profile, location profile, use-hot-locations, write-aligned-stripes, contain-write-in-flash-page
star=****
problem=how a database engine can be optimized for a particular de- vice by learning its hidden parameters.
interest=This can not only improve an application's performance, but also potentially increase the lifetime of the SSD.
hardness=Solid State Drives (SSDs) are complex devices with varying internal implementations, resulting in subtle dierences in behavior between devices.
idea=Our approach for optimizing a database for a given SSD consists of three steps: learning the hidden parameters of the device, proposing rules to analyze the I/O behavior of the database, and optimizing the database by eliminating violations of these rules.
future=
comment=We obtain two dierent characteristics of an SSD, namely the request size prole and the location prole, from which we learn multiple internal parameters. Based on these pa- rameters, we propose rules to analyze the I/O behavior of a database engine. Using these rules, we uncover sub-optimal I/O patterns in SQLite3 and MariaDB when running on our experimental SSDs. Finally, we present three techniques to optimize these database engines: (1) use-hot-locations on SSD-S, which improves the SELECT operation throughput of SQLite3 and MariaDB by 29% and 27% respectively; it also improves the performance of YCSB on MariaDB by 1%-22% depending on the workload mix, (2) write-aligned-stripes on SSD-T, reduces the wear-out caused by SQLite3 write-ahead log (WAL) le by 3.1%, and (3) contain-write-in-flash-page on SSD-T, which reduces the wear-out caused by the MariaDB binary log le by 6.7%.
other=
---
id=490
title=Evaluating Persistent Memory Range Indexes
author=Lucas Lersch, et al.
journal=vldb
year=2020
tags=experimental analysis, Persistent memory range index, Persistent memory (PM), volatile DRAM, real PM hardware, PM-based index structure, Intel Optane DC Persistent Memory, B+-tree, wBTree, NV-Tree, BzTree, FPTree, PiBench benchmark
star=****
problem=
interest=Persistent memory (PM) is fundamentally changing the way database index structures are built by enabling persistence, high performance, and (near) instant recovery all on the memory bus.
hardness=Prior work has proposed many techniques to tailor index structure designs for PM, but they were mostly based on volatile DRAM with simulation due to the lack of real PM hardware. Until today is it unclear how these techniques will actually perform on real PM hardware.
idea=With the recent released Intel Optane DC Persistent Memory, for the first time, this paper provides a comprehensive evaluation of recent persistent index structures. We focus on B+-Tree-based range indexes and carefully choose four representative index structures for evaluation: wBTree, NV-Tree, BzTree and FPTree. These four tree structures cover a wide, representative range of techniques that are essential building blocks of PM-based index structures. For fair comparison, we used an unified programming model for all trees and developed PiBench, a benchmarking framework which targets PM-based indexes.
future=
comment=Through empirical evaluation using representative workloads, we identify key, effective techniques, insights and caveats to guide the making of future PM-based index structures.
other=https://www.storagereview.com/intel_optane_dc_persistent_memory_module_pmm
---
id=491
title=DPTree: Differential Indexing for Persistent Memory
author=Xinjing Zhou, et al.
journal=vldb
year=2020
tags=DPTree (Dierential Persistent tree), differential index, Persistent memory, expensive PM writes, crash-consistency, multi-core, concurrent DPTree, batch multiple writes
star=****
problem=One crucial component studied by researchers is persistent indices. (especially write performance)
interest=The emergence of persistent memory (PM) spurs on redesigns of database system components to gain full exploitation of the persistence and speed of the hardware.
hardness=However, such studies to date are unsatisfactory in terms of the number of expensive PM writes required for crash-consistency.
idea=a new persistent index called DPTree (Dierential Persistent Tree) to address this.  DPTree's core idea is to batch multiple writes in DRAM persistently and later merge them into a PM component to amortize persistence overhead. DPTree includes several techniques and algorithms to achieve crash-consistency, reduce PM writes signicantly, and maintain excellent read performance. To embrace multi-core processors, we present the design of concurrent DPTree.
future=
comment=Our experiments on Intel's Optane DIMMs show that DPTree reduces PM writes by a factor of 1.7x-3x compare to state-of-the-art counterparts.  Besides, DPTree has a competitive or better read performance and scales well in multi-core environment.
other=
---
id=492
title=The Space Complexity of Approximating the Frequency Moments
author=Noga Alon, Yossi Matias, Mario Szegedy
journal=stoc  1996,  Journal of computer and system sciences 1999
year=1996, 1999
tags=stream processing, space Complexity, Approximating the Frequency moments, theory
star=****
problem=
interest=
hardness=
idea=
future=
comment=
other=
---
id=493
title=A Theoretician's Guide to the Experimental Analysis of Algorithms
author=David S. Johnson
journal=Data Structures, Near Neighbor Searches, and Methodology
year=1999
tags=Theoretician, guide, Methodology,  worst-case analysis, average-case analysis, Experimental analysis, empirical study, survey, algorithms, a list of Principles, pitfalls, suggestions, Pet Peeves, controversial points
star=****
problem=an informal discussion of issues that arise when one attempts to analyze algorithms experimentally   ;     How can a background in theoretical analysis of Algorithms help experimentation?
interest=It is based on lessons learned by the author over the course of more than a decade of experimentation, survey paper writing, refereeing, and lively discussions with other experimentalists. Although written from the perspective of a theoretical computer scientist, it is intended to be of use to researchers from all elds who want to study algorithms experimentally.
hardness=
idea=It has two goals: first, to provide a useful guide to new experimentalists about how such work can best be performed and written up, and second, to challenge current researchers to think about whether their own work might be improved from a scientic point of view.
future=
comment=With the latter purpose in mind, the author hopes that at least a few of his recommendations will be considered controversial
other=
---
