This file is used to collect useful phrases in English Papers.

---

CTA (Cooperative Thread Array)

w.r.t.

a.k.a.

hereafter

is oblivious to

commensurate with

one remedy fits all

judiciously alternates among these designs at runtime to arrive at the best performance

taken together

self-descriptive

it is worth noting that

drastic increase

auto-indexing service

industrial-strength

revamp

unveil

the most noteworthy part

strided memory access

coalesced memory access

an array of efforts

has surged to be

unless otherwise specified

When the context is not ambiguous 

when the context is clear

hang together

it is too dense

now we have a paper

exposes the traits of underlying GPU architectures to users

We are passionate about performance.

in ordre to facilitate easy exposition

the so-called xxx

exhibit less potential for parallelizations

streamline some processes

advantageous

trigger the switch of direction

how the techniques harmonize when applied jointly

its structure is interesting in its own right.

alternatively    

serve a dual purpose

meet all criteria

it suffices to show 

with the advent of GPU

to underline the efficiency of the
proposed solution

use a hash function to probe this position

achieve substantial speedup 

employ the power of massive parallelism

We present in this paper several improvements for computing shortest path maps using OpenGL shaders. 

is annotated with +

while the rest of the lines are retained as is

An embedded DSL exists as a library in the host language (Scala in our case), leading to seamless integration.

Additional details can be found in our technical report [70].  (on arXiv)

aiming to alleviate the computational burden while preserving a good performance


Graphs are ubiquitous nowadays and have a wide range of applications in bioinformatics, chemistry, recommender systems, social network study, program static analysis, etc. Among these, one of the fundamental problems is to retrieve a set of similar graphs from a database given a user query.

semi-artificial line drawings

The A* search algorithm is characterized by a heuristic function

In this paper, we address the issue of efficient edit distance computation in a different way

consider for simplicity

conceive

Section 2 formulates the problem, and an overview of the proposed framework follows in Section 3.

fully-fledged system

to our best knowledge

putting all these together

strike a balance  between

This makes it algorithm agnostic and thus applicable to a broader set of algorithms.

center around using the edge weights

considering the properties of GPU architecture

optimization tactics

exhibit a highly irregular structure

exhibit up to 9x speedup over previous algorithms

nevertheless=however

mitigate all these diculties

progreesively decrease v.d

prevailing wisdom

they are at the epicenter of the renewed interest in graph processing

note the distinction between ...

this idea is hardly covered in the literature

address the deficit described above by providing xxx

with high probability (whp)

    maintains eligible nodes with tentative distances in an array of buckets each of which represents a distance range of size theta

We thank in particular xxx formanyfruitful discussions and suggestions.

is valuable to highlight the main ideas of a parallel algorithm without tedious details caused by a particular architecture

theoretical justification for the actually observed performance is largely missing.

in between

In the following we will provide an outline of previous and related work. Then we will give an overview of our new algorithms, interpret the theoretical results, and sketch the organization of the article.

a comparable worst-case result

nonfinal distance value

emanate from some special nodes

The football contest is competition that always nudges dark horses into the top tier. 

the performance may deteriorate on scale-free graphs.

load balance is used to prevent a single processor from being overloaded.

 We now proceed to the next item on the agenda

this idea can be augmented to deal with random weights.

achieving rates up to 14x higher on low-degree graphs

see significant speedups (20–60x) when compared against a serial implementation on graphs with adequately high degree

address these deficits

dense graphs that are more amenable for parallel SSSP computation

we are aware of one previous work

a three-pronged approach

Due to its ability to handle pathological cases

Efficient GPU implementations require exploiting the GPU’s three-layer memory hierarchy (global DRAM, per-block shared memory, and per-thread registers), but such a memory hierarchy is absent from the traditional deltastepping formulation.

This method most closely resembles delta stepping.

These two classic algorithms span a parallel vs. efficiency spectrum. Neither is ideal: Dijkstra exposes no parallelism across vertices, while Bellman-Ford is expensive.

despite intensive research during the last decades

Evaluating the performance of shortest-paths algorithms on the basis of real-world data is both desirable and problematic

depicts the relation between parallel models of computation

in a nutshell

While this is interesting in its own right it also stresses the advantages of our new algorithms.

such inputs are quite atypical

dist(s,v), abbreviated dist(v)

deduce that a tentative distance of a node is final

Large yields may be advantageous in several ways

Even more obviously

aforementioned

indispensible

deviates significantly from

is refilled with

despite

in spite of

a striking example

type-aware transformation

tailored optimization techniques

For ease of explanation

to address the problems caused by

auxiliary 

robust

prioritize

These approaches achieved impressive speedups over the direct-enumeration algorithms such as VF2.

reveal

brevity

improving the filtering precision is justified only when the verification phase is the bottleneck of the query.

representatives

exhaustively

methodology

develop

hence

thus

hence

 an abundance of related work

 counter-example

 be determined on diverse criteria

 is enriched with

 end-nodes

the worst-case memory usage is prohibitive.

the poor performance is an artifact of a discrepancy between the GPU programming model and the underlying GPU architecture

the huge space cost marks it inefficient

exposes the traits of underlying GPU architectures to users

afterwards

low-end GPU devices

sensibly reduce the search space

to understand the correlation between performance and graph characteristics as well as advantages and limitations of the proposed approach

graph motif discovery

For the sake of clarity and without loss of generality

obviates the need for the substantial work to verify the topology constraint

lead to significant performance gains

As graphs continue to grow, external memory graph processing systems serve as a promising alternative to inmemory solutions for low cost and high scalability.

use the terms node and vertex interchangeably

tackle the bottleneck

has good scalability with graph size scaling to hundreds of millions of vertices and edges, which are 100 times than the data graph size used in the state-of-the-art work.

technique, mechanism, methodology

our proposed accelerative solution


turn more challenging

conform to the constraints of both ...

conform to X constraints 

For simplicity, when the context is clear, we always use “match” to mean “timeconstrained match”.

to first check the structure constraint followed by a check of

For the sake of presentation, we assume that

Without loss of generality, we assume that

let X be the result produced by ...

Assuming that ...

Finding the most appropriate cost function is a major research issue in itself and outside the scope of this paper.

To the best of our knowledge

The proliferation of high throughput, dynamic graphstructured data raises challenges for traditional graph data management techniques.

we verify answers from SJ-tree posteriorly with the timing order constraints.

Thus, we propose a simple yet effective heuristic rule.

dummy instructions

an artifact of a discrepancy between the GPU programming model and the underlying GPU architecture





